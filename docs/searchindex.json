[{"section":"Life","slug":"/life/reading/unemployment/","title":"何为失业？何为工作","description":"2020年毕业经济开始下行，到现在为止从业几年后对it从业者，与工作有些许感悟","date":"December 2, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"失业","tags":"失业","content":"最近在看博客，翻阅到一个博主聊失业所提及的观点，觉得挺有道理，分享给大家。\nNote\n在人口红利、技术红利消失之后，政策红利必然会消失，互联网行业已经步入成熟稳定的发展阶段。短期往长期发展的过程，是我们能进行调整的窗口期。我个人的做法是： 1）努力工作，保证稳定的现金流入； 2）多读书，尤其是历史和宏观经济，从更大尺度看问题有助于保持内心平静； 3）保持心身健康，做好长线发展准备； 4）保持与各行各业的交流，关注大的趋势，避免落入信息孤岛； 5）控制负债，保证现金流正常，做一些投资规划；\n身处27岁节点的我，刚刚工作满4年，在2023年也经历了一次裁员，可能因为那时候的我比较年轻然后工资要求没有那么高，没有动辄30+k的要求，所以找工作还算比较容易，两个月不到的时间就找到了，但是未来等我到哪位博主一样35+之后，我可能就不会这么容易了；\n好在我现在这份工作，整体不是很忙，每天干1-2个小时，有很多时间可以拿来学习与看书，同时也可以研究一些新的技术，比如最近在研究webgl然后同时在公司内部我还在开发基础的可视化图表；\n"},{"section":"Blog","slug":"/blog/computer-technology/web/react/usesign/","title":"useSignal() 是Web框架的未来","description":"JavaScript 作为一门在 Web 开发中的主流语言，常常涉及到交互事件方面的应用，这不可避免的用到了异步编程的方法，而它本身则是单线程运行的。在以往的开发中，异步编程正变得越来越难管理，新的 Promise 标准 API 将使得异步编程更加方便、安全。","date":"November 11, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, React, JavaScript","tags":"","content":"Angular、Qwik的作者 MIŠKO HEVERY 在文章中盛赞了 useSignal() 这种数据流方案， 表示 useSignal() 是前端框架的未来，并考虑在Angular中实现它。我们在这里不评价文章的观点，我们来看看 useSignal 这个方案的前世今生。\n什么是 useSignal 一个简单的 react 组件是下面这样的：它使用了useState这个hooks钩子函数\nuseSignal()就是 state 和 setState 的改良版本，它写起来是这样的：\n虽然看起来没什么特别的，只是省略了一个 setState，但是两者的原理其实完全不同。Signals 和 State 之间的主要区别在于 Signals 返回一个 getter 和一个 setter ，而非响应式系统返回其值（和一个 setter ）。\nSignals 是可响应的！就意味着它们会追踪对状态感兴趣的（订阅）人，如果状态发生了变化，就通知订阅者状态发生了变化。要具有响应性，Signals 必须收集谁对 Signals 的值感兴趣（订阅）。他们通过观察在哪些上下文中调用 state-getter 来获得这些信息。通过从 getter 获取值的行为，可以告诉 Signals 这个地方对其值感兴趣。如果值发生更改，则需要使该位置发生重新计算。换句话说，调用 getter 将创建订阅。\n综上所述 Signals 其实是一个订阅发布系统，只是订阅这个步骤是自动实现的，这样的好处是不需要diff，也不需要死去活来的不断调用 App，减少开销。\n它其实有点像vue的ref或者react的useRef；但是实际上：useRef（） 的使用与 useSignal（） 完全相同，用于传递对 state 的引用，而不是 state 本身。useRef（） 缺少的是订阅跟踪和通知。\n"},{"section":"Life","slug":"/life/phone/","title":"那些年之电子产品","description":"","date":"November 7, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"","tags":"电子消费品, 手机","content":"把这几年工作上学买过的电子产品整理下；\n大学开始至今年代久远，整理的时间不一定对的上，简单整理一下当手帐册供日后做纪念：\n2016年 大一时购入的华为p9，陪伴了我大学四年除了电池不耐用，其他在当时用起来还是很不错的，\n2018年 大二购买的ipad2018 16g\n2020年疫情过后，工作购入iphone 11 128g\n2021年 ipad pro 2021 11寸 128g\n2022年 罗技Master3\n2023年 iphone14pro 256g\n2024年 罗技Master3s\n"},{"section":"Life","slug":"/life/travel/traveling/","title":"2022年至2023年徒步记录","description":"从22年年末接触徒步，记录一下走过的路。","date":"November 6, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"徒步, 旅行","tags":"徒步, 旅行","content":"我在22年的夏天来到北京，然后接触到北京的徒步团体非常多，所以参加了很多次徒步，记录一下走过的路。\n2022年 2022年7月 2022年7月30日和朋友一起去了一下河北张家口的小山坡，山下非常炎热，山上却凉快很多，非常舒服。 https://leezchuan.github.io/images/zhangjiakou.png does not exist\r2023年2月 "},{"section":"Blog","slug":"/blog/computer-technology/git/publish-gitlab/","title":"git依赖包发布","description":"自己开发的npm包如何发布到公网与内网","date":"October 26, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"git, gitlab, npm, 内网部署","tags":"","content":" 最近在开发npm包，需要发布到内网或者公网，便于是乎调研有多少种方案\n方案一：使用gitlab构建平台 1. 如何发布 首先去gitlab平台对应你要发布的平台勾选对应的权限，然后创建你所需要的token， 在这里我创建了本次项目所需要的zcharts_token, 然后在windows配置全局token：\nset NPM_TOKEN=xxxxxx; 确保你的token配置成功： sh echo $NPM_TOKEN # Unix/macOS echo %NPM_TOKEN% # Windows 就可以正常发布了：npm publish --registry=http://192.168.86.82/api/v4/projects/3606/packages/npm/\n2. 如何在新项目中引入私有仓库 首先在项目中创建.npmrc文件\n#@scope:registry=https://your_domain_name/api/v4/projects/your_project_id/packages/npm/ #//your_domain_name/api/v4/projects/your_project_id/packages/npm/:_authToken=\u0026#34;${NPM_TOKEN}\u0026#34; # 格式: # - scope：你的scopename # - your_domain_name：你的gitlab域名或ip # - your_project_id：你的仓库id # - NPM_TOKEN：用户发布的用户token # 示例 @znz:registry=http://192.168.86.82/api/v4/projects/3606/packages/npm/ # 你可以直接将token写在这里(token需要写入你的环境变量) //192.168.86.82/api/v4/projects/3606/packages/npm/:_authToken=${NPM_TOKEN} 然后通过npm i @znz/zcharts的形式就可以引入项目了，注意使用内网安装一定要@znz这是需要本地判断是否使用内网的依据，不然还是走本机配置的npm路径进行安装依赖\n从下方安装依赖的路径可以看到是从ip内网安装的该依赖：\n也可以使用该命令安装依赖：\nnpm install @znz/znz-chart@0.2.0 --registry=http://repositories.compass.com/api/v4/projects/3606/packages/npm/ --//repositories.compass.com/api/v4/projects/3606/packages/npm/:_authToken=xxxxxx\n方案二：使用内网搭建一个npmserver 具体其实就是使用：https://verdaccio.org/docs/what-is-verdaccio\n方案三：使用公网npm平台 最常用的就是在npm网站注册登陆自己的用户，然后使用npm publish发布自己的包，但是缺点就是需要公网ip，如果在内网的话，就需要使用内网穿透工具，比如frp等，但是这种方式需要额外配置，而且需要公网ip，所以不推荐使用。\n参考文档 https://docs.gitlab.com/ee/user/packages/package_registry/ https://docs.gitlab.com/ee/user/packages/npm_registry/ https://docs.gitlab.com/ee/user/packages/yarn_repository/\n"},{"section":"Blog","slug":"/blog/computer-technology/code/mouse-pointer/","title":"（转载）如何实现网站鼠标特效","description":"以下代码可以实现一个在画布上的鼠标炫酷特效","date":"October 24, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"特效, 计算机技术, canvas","tags":"计算机技术, Web前端, 特效, demo","content":"使用以下代码可以实现一个在画布上的鼠标特效\n\u0026#34;use strict\u0026#34;; const canvas = document.getElementsByTagName(\u0026#34;canvas\u0026#34;)[0]; canvas.width = canvas.clientWidth; canvas.height = canvas.clientHeight; Array.prototype.getRandom = function () { return this[Math.floor(Math.random() * this.length)]; }; let splatColors = [{ r: 0, g: 0.15, b: 0 }]; let idleSplats; function idleSplatsFunction() { multipleSplats( parseInt(Math.random() * config.RANDOM_AMOUNT) + config.RANDOM_AMOUNT / 2 + 1 ); } let config = { SIM_RESOLUTION: 256, DYE_RESOLUTION: 1024, DENSITY_DISSIPATION: 0.97, VELOCITY_DISSIPATION: 0.98, PRESSURE_DISSIPATION: 0.8, PRESSURE_ITERATIONS: 20, CURL: 30, SPLAT_RADIUS: 0.3, SHADING: true, COLORFUL: true, PAUSED: false, BACK_COLOR: { r: 0, g: 0, b: 0 }, TRANSPARENT: false, BLOOM: true, BLOOM_ITERATIONS: 8, BLOOM_RESOLUTION: 256, BLOOM_INTENSITY: 0.8, BLOOM_THRESHOLD: 0.6, BLOOM_SOFT_KNEE: 0.7, POINTER_COLOR: [{ r: 0, g: 0.15, b: 0 }], SOUND_SENSITIVITY: 0.25, AUDIO_RESPONSIVE: true, FREQ_RANGE: 8, FREQ_RANGE_START: 0, IDLE_SPLATS: false, RANDOM_AMOUNT: 10, RANDOM_INTERVAL: 1, SPLAT_ON_CLICK: true, SHOW_MOUSE_MOVEMENT: true, }; document.addEventListener(\u0026#34;DOMContentLoaded\u0026#34;, () =\u0026gt; { window.wallpaperPropertyListener = { applyUserProperties: (properties) =\u0026gt; { if (properties.bloom_intensity) config.BLOOM_INTENSITY = properties.bloom_intensity.value; if (properties.bloom_threshold) config.BLOOM_THRESHOLD = properties.bloom_threshold.value; if (properties.colorful) config.COLORFUL = properties.colorful.value; if (properties.density_diffusion) config.DENSITY_DISSIPATION = properties.density_diffusion.value; if (properties.enable_bloom) config.BLOOM = properties.enable_bloom.value; if (properties.paused) config.PAUSED = properties.paused.value; if (properties.pressure_diffusion) config.PRESSURE_DISSIPATION = properties.pressure_diffusion.value; if (properties.shading) config.SHADING = properties.shading.value; if (properties.splat_radius) config.SPLAT_RADIUS = properties.splat_radius.value; if (properties.velocity_diffusion) config.VELOCITY_DISSIPATION = properties.velocity_diffusion.value; if (properties.vorticity) config.CURL = properties.vorticity.value; if (properties.sound_sensitivity) config.SOUND_SENSITIVITY = properties.sound_sensitivity.value; if (properties.audio_responsive) config.AUDIO_RESPONSIVE = properties.audio_responsive.value; if (properties.simulation_resolution) { config.SIM_RESOLUTION = properties.simulation_resolution.value; initFramebuffers(); } if (properties.dye_resolution) { config.DYE_RESOLUTION = properties.dye_resolution.value; initFramebuffers(); } if (properties.splat_color) { splatColors[0] = rgbToPointerColor(properties.splat_color.value); if (!config.COLORFUL) config.POINTER_COLOR = [splatColors[0]]; } if (properties.splat_color_2) splatColors[1] = rgbToPointerColor(properties.splat_color_2.value); if (properties.splat_color_3) splatColors[2] = rgbToPointerColor(properties.splat_color_3.value); if (properties.splat_color_4) splatColors[3] = rgbToPointerColor(properties.splat_color_4.value); if (properties.splat_color_5) splatColors[4] = rgbToPointerColor(properties.splat_color_5.value); if (properties.background_color) { let c = properties.background_color.value.split(\u0026#34; \u0026#34;), r = Math.floor(c[0] * 255), g = Math.floor(c[1] * 255), b = Math.floor(c[2] * 255); document.body.style.backgroundColor = `rgb(${r}, ${g}, ${b})`; config.BACK_COLOR.r = r; config.BACK_COLOR.g = g; config.BACK_COLOR.b = b; } if (properties.more_colors \u0026amp;\u0026amp; !properties.more_colors.value) { config.POINTER_COLOR = [splatColors[0]]; } else if (properties.more_colors \u0026amp;\u0026amp; properties.more_colors.value) { config.POINTER_COLOR = splatColors; } if (properties.use_background_image) config.TRANSPARENT = properties.use_background_image.value; if (properties.background_image) canvas.style.backgroundImage = `url(\u0026#34;file:///${properties.background_image.value}\u0026#34;)`; if (properties.repeat_background) canvas.style.backgroundRepeat = properties.repeat_background.value ? \u0026#34;repeat\u0026#34; : \u0026#34;no-repeat\u0026#34;; if (properties.background_image_size) canvas.style.backgroundSize = properties.background_image_size.value; if (properties.frequency_range) { config.FREQ_RANGE = properties.frequency_range.value; if (config.FREQ_RANGE + config.FREQ_RANGE_START \u0026gt; 61) { config.FREQ_RANGE_START = 62 - config.FREQ_RANGE; } } if (properties.frequency_range_start) { if (config.FREQ_RANGE + properties.frequency_range_start.value \u0026gt; 61) { config.FREQ_RANGE_START = 62 - config.FREQ_RANGE; } else { config.FREQ_RANGE_START = properties.frequency_range_start.value; } } if (properties.idle_random_splats) { config.IDLE_SPLATS = properties.idle_random_splats.value; if (properties.idle_random_splats.value) { idleSplats = setInterval( idleSplatsFunction, config.RANDOM_INTERVAL * 1000 ); } else { clearInterval(idleSplats); } } if (properties.random_splat_interval) { config.RANDOM_INTERVAL = properties.random_splat_interval.value; if (config.IDLE_SPLATS) { clearInterval(idleSplats); idleSplats = setInterval( idleSplatsFunction, config.RANDOM_INTERVAL * 1000 ); } } if (properties.random_splat_amount) { config.RANDOM_AMOUNT = properties.random_splat_amount.value; if (config.IDLE_SPLATS) { clearInterval(idleSplats); idleSplats = setInterval( idleSplatsFunction, config.RANDOM_INTERVAL * 1000 ); } } if (properties.splat_on_click) config.SPLAT_ON_CLICK = properties.splat_on_click.value; if (properties.show_mouse_movement) config.SHOW_MOUSE_MOVEMENT = properties.show_mouse_movement.value; }, }; window.wallpaperRegisterAudioListener((audioArray) =\u0026gt; { if (!config.AUDIO_RESPONSIVE) return; if (audioArray[0] \u0026gt; 5) return; let bass = 0.0; let half = Math.floor(audioArray.length / 2); for (let i = 0; i \u0026lt;= config.FREQ_RANGE; i++) { bass += audioArray[i + config.FREQ_RANGE_START]; bass += audioArray[half + (i + config.FREQ_RANGE_START)]; } bass /= config.FREQ_RANGE * 2; multipleSplats(Math.floor(bass * config.SOUND_SENSITIVITY * 10)); }); }); function indexOfMax(arr) { if (arr.length === 0) { return -1; } var max = arr[0]; var maxIndex = 0; for (var i = 1; i \u0026lt; arr.length; i++) { if (arr[i] \u0026gt; max) { maxIndex = i; max = arr[i]; } } return maxIndex; } class pointerPrototype { constructor() { this.id = -1; this.x = 0; this.y = 0; this.dx = 0; this.dy = 0; this.down = false; this.moved = false; this.color = config.COLORFUL ? generateColor() : config.POINTER_COLOR.getRandom(); } } let pointers = []; let splatStack = []; let bloomFramebuffers = []; pointers.push(new pointerPrototype()); const { gl, ext } = getWebGLContext(canvas); if (isMobile()) config.SHADING = false; if (!ext.supportLinearFiltering) { config.SHADING = false; config.BLOOM = false; } function getWebGLContext(canvas) { const params = { alpha: true, depth: false, stencil: false, antialias: false, preserveDrawingBuffer: false, }; let gl = canvas.getContext(\u0026#34;webgl2\u0026#34;, params); const isWebGL2 = !!gl; if (!isWebGL2) gl = canvas.getContext(\u0026#34;webgl\u0026#34;, params) || canvas.getContext(\u0026#34;experimental-webgl\u0026#34;, params); let halfFloat; let supportLinearFiltering; if (isWebGL2) { gl.getExtension(\u0026#34;EXT_color_buffer_float\u0026#34;); supportLinearFiltering = gl.getExtension(\u0026#34;OES_texture_float_linear\u0026#34;); } else { halfFloat = gl.getExtension(\u0026#34;OES_texture_half_float\u0026#34;); supportLinearFiltering = gl.getExtension(\u0026#34;OES_texture_half_float_linear\u0026#34;); } gl.clearColor(0.0, 0.0, 0.0, 1.0); const halfFloatTexType = isWebGL2 ? gl.HALF_FLOAT : halfFloat.HALF_FLOAT_OES; let formatRGBA; let formatRG; let formatR; if (isWebGL2) { formatRGBA = getSupportedFormat(gl, gl.RGBA16F, gl.RGBA, halfFloatTexType); formatRG = getSupportedFormat(gl, gl.RG16F, gl.RG, halfFloatTexType); formatR = getSupportedFormat(gl, gl.R16F, gl.RED, halfFloatTexType); } else { formatRGBA = getSupportedFormat(gl, gl.RGBA, gl.RGBA, halfFloatTexType); formatRG = getSupportedFormat(gl, gl.RGBA, gl.RGBA, halfFloatTexType); formatR = getSupportedFormat(gl, gl.RGBA, gl.RGBA, halfFloatTexType); } return { gl, ext: { formatRGBA, formatRG, formatR, halfFloatTexType, supportLinearFiltering, }, }; } function getSupportedFormat(gl, internalFormat, format, type) { if (!supportRenderTextureFormat(gl, internalFormat, format, type)) { switch (internalFormat) { case gl.R16F: return getSupportedFormat(gl, gl.RG16F, gl.RG, type); case gl.RG16F: return getSupportedFormat(gl, gl.RGBA16F, gl.RGBA, type); default: return null; } } return { internalFormat, format, }; } function supportRenderTextureFormat(gl, internalFormat, format, type) { let texture = gl.createTexture(); gl.bindTexture(gl.TEXTURE_2D, texture); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, 4, 4, 0, format, type, null); let fbo = gl.createFramebuffer(); gl.bindFramebuffer(gl.FRAMEBUFFER, fbo); gl.framebufferTexture2D( gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0 ); const status = gl.checkFramebufferStatus(gl.FRAMEBUFFER); if (status != gl.FRAMEBUFFER_COMPLETE) return false; return true; } function isMobile() { return /Mobi|Android/i.test(navigator.userAgent); } class GLProgram { constructor(vertexShader, fragmentShader) { this.uniforms = {}; this.program = gl.createProgram(); gl.attachShader(this.program, vertexShader); gl.attachShader(this.program, fragmentShader); gl.linkProgram(this.program); if (!gl.getProgramParameter(this.program, gl.LINK_STATUS)) throw gl.getProgramInfoLog(this.program); const uniformCount = gl.getProgramParameter( this.program, gl.ACTIVE_UNIFORMS ); for (let i = 0; i \u0026lt; uniformCount; i++) { const uniformName = gl.getActiveUniform(this.program, i).name; this.uniforms[uniformName] = gl.getUniformLocation( this.program, uniformName ); } } bind() { gl.useProgram(this.program); } } function compileShader(type, source) { const shader = gl.createShader(type); gl.shaderSource(shader, source); gl.compileShader(shader); if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) throw gl.getShaderInfoLog(shader); return shader; } const baseVertexShader = compileShader( gl.VERTEX_SHADER, ` precision highp float; attribute vec2 aPosition; varying vec2 vUv; varying vec2 vL; varying vec2 vR; varying vec2 vT; varying vec2 vB; uniform vec2 texelSize; void main () { vUv = aPosition * 0.5 + 0.5; vL = vUv - vec2(texelSize.x, 0.0); vR = vUv + vec2(texelSize.x, 0.0); vT = vUv + vec2(0.0, texelSize.y); vB = vUv - vec2(0.0, texelSize.y); gl_Position = vec4(aPosition, 0.0, 1.0); } ` ); const clearShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying highp vec2 vUv; uniform sampler2D uTexture; uniform float value; void main () { gl_FragColor = value * texture2D(uTexture, vUv); } ` ); const colorShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; uniform vec4 color; void main () { gl_FragColor = color; } ` ); const backgroundShader = compileShader( gl.FRAGMENT_SHADER, ` void main () { gl_FragColor = vec4(0.0, 0.0, 0.0, 0.0); } ` ); const displayShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; uniform sampler2D uTexture; void main () { vec3 C = texture2D(uTexture, vUv).rgb; float a = max(C.r, max(C.g, C.b)); gl_FragColor = vec4(C, a); } ` ); const displayBloomShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; uniform sampler2D uTexture; uniform sampler2D uBloom; uniform sampler2D uDithering; uniform vec2 ditherScale; void main () { vec3 C = texture2D(uTexture, vUv).rgb; vec3 bloom = texture2D(uBloom, vUv).rgb; bloom = pow(bloom.rgb, vec3(1.0 / 2.2)); C += bloom; float a = max(C.r, max(C.g, C.b)); gl_FragColor = vec4(C, a); } ` ); const displayShadingShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; varying vec2 vL; varying vec2 vR; varying vec2 vT; varying vec2 vB; uniform sampler2D uTexture; uniform vec2 texelSize; void main () { vec3 L = texture2D(uTexture, vL).rgb; vec3 R = texture2D(uTexture, vR).rgb; vec3 T = texture2D(uTexture, vT).rgb; vec3 B = texture2D(uTexture, vB).rgb; vec3 C = texture2D(uTexture, vUv).rgb; float dx = length(R) - length(L); float dy = length(T) - length(B); vec3 n = normalize(vec3(dx, dy, length(texelSize))); vec3 l = vec3(0.0, 0.0, 1.0); float diffuse = clamp(dot(n, l) + 0.7, 0.7, 1.0); C.rgb *= diffuse; float a = max(C.r, max(C.g, C.b)); gl_FragColor = vec4(C, a); } ` ); const displayBloomShadingShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; varying vec2 vL; varying vec2 vR; varying vec2 vT; varying vec2 vB; uniform sampler2D uTexture; uniform sampler2D uBloom; uniform sampler2D uDithering; uniform vec2 ditherScale; uniform vec2 texelSize; void main () { vec3 L = texture2D(uTexture, vL).rgb; vec3 R = texture2D(uTexture, vR).rgb; vec3 T = texture2D(uTexture, vT).rgb; vec3 B = texture2D(uTexture, vB).rgb; vec3 C = texture2D(uTexture, vUv).rgb; float dx = length(R) - length(L); float dy = length(T) - length(B); vec3 n = normalize(vec3(dx, dy, length(texelSize))); vec3 l = vec3(0.0, 0.0, 1.0); float diffuse = clamp(dot(n, l) + 0.7, 0.7, 1.0); C *= diffuse; vec3 bloom = texture2D(uBloom, vUv).rgb; bloom = pow(bloom.rgb, vec3(1.0 / 2.2)); C += bloom; float a = max(C.r, max(C.g, C.b)); gl_FragColor = vec4(C, a); } ` ); const bloomPrefilterShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying vec2 vUv; uniform sampler2D uTexture; uniform vec3 curve; uniform float threshold; void main () { vec3 c = texture2D(uTexture, vUv).rgb; float br = max(c.r, max(c.g, c.b)); float rq = clamp(br - curve.x, 0.0, curve.y); rq = curve.z * rq * rq; c *= max(rq, br - threshold) / max(br, 0.0001); gl_FragColor = vec4(c, 0.0); } ` ); const bloomBlurShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying vec2 vL; varying vec2 vR; varying vec2 vT; varying vec2 vB; uniform sampler2D uTexture; void main () { vec4 sum = vec4(0.0); sum += texture2D(uTexture, vL); sum += texture2D(uTexture, vR); sum += texture2D(uTexture, vT); sum += texture2D(uTexture, vB); sum *= 0.25; gl_FragColor = sum; } ` ); const bloomFinalShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying vec2 vL; varying vec2 vR; varying vec2 vT; varying vec2 vB; uniform sampler2D uTexture; uniform float intensity; void main () { vec4 sum = vec4(0.0); sum += texture2D(uTexture, vL); sum += texture2D(uTexture, vR); sum += texture2D(uTexture, vT); sum += texture2D(uTexture, vB); sum *= 0.25; gl_FragColor = sum * intensity; } ` ); const splatShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; uniform sampler2D uTarget; uniform float aspectRatio; uniform vec3 color; uniform vec2 point; uniform float radius; void main () { vec2 p = vUv - point.xy; p.x *= aspectRatio; vec3 splat = exp(-dot(p, p) / radius) * color; vec3 base = texture2D(uTarget, vUv).xyz; gl_FragColor = vec4(base + splat, 1.0); } ` ); const advectionManualFilteringShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; uniform sampler2D uVelocity; uniform sampler2D uSource; uniform vec2 texelSize; uniform vec2 dyeTexelSize; uniform float dt; uniform float dissipation; vec4 bilerp (sampler2D sam, vec2 uv, vec2 tsize) { vec2 st = uv / tsize - 0.5; vec2 iuv = floor(st); vec2 fuv = fract(st); vec4 a = texture2D(sam, (iuv + vec2(0.5, 0.5)) * tsize); vec4 b = texture2D(sam, (iuv + vec2(1.5, 0.5)) * tsize); vec4 c = texture2D(sam, (iuv + vec2(0.5, 1.5)) * tsize); vec4 d = texture2D(sam, (iuv + vec2(1.5, 1.5)) * tsize); return mix(mix(a, b, fuv.x), mix(c, d, fuv.x), fuv.y); } void main () { vec2 coord = vUv - dt * bilerp(uVelocity, vUv, texelSize).xy * texelSize; gl_FragColor = dissipation * bilerp(uSource, coord, dyeTexelSize); gl_FragColor.a = 1.0; } ` ); const advectionShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; uniform sampler2D uVelocity; uniform sampler2D uSource; uniform vec2 texelSize; uniform float dt; uniform float dissipation; void main () { vec2 coord = vUv - dt * texture2D(uVelocity, vUv).xy * texelSize; gl_FragColor = dissipation * texture2D(uSource, coord); gl_FragColor.a = 1.0; } ` ); const divergenceShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying highp vec2 vUv; varying highp vec2 vL; varying highp vec2 vR; varying highp vec2 vT; varying highp vec2 vB; uniform sampler2D uVelocity; void main () { float L = texture2D(uVelocity, vL).x; float R = texture2D(uVelocity, vR).x; float T = texture2D(uVelocity, vT).y; float B = texture2D(uVelocity, vB).y; vec2 C = texture2D(uVelocity, vUv).xy; if (vL.x \u0026lt; 0.0) { L = -C.x; } if (vR.x \u0026gt; 1.0) { R = -C.x; } if (vT.y \u0026gt; 1.0) { T = -C.y; } if (vB.y \u0026lt; 0.0) { B = -C.y; } float div = 0.5 * (R - L + T - B); gl_FragColor = vec4(div, 0.0, 0.0, 1.0); } ` ); const curlShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying highp vec2 vUv; varying highp vec2 vL; varying highp vec2 vR; varying highp vec2 vT; varying highp vec2 vB; uniform sampler2D uVelocity; void main () { float L = texture2D(uVelocity, vL).y; float R = texture2D(uVelocity, vR).y; float T = texture2D(uVelocity, vT).x; float B = texture2D(uVelocity, vB).x; float vorticity = R - L - T + B; gl_FragColor = vec4(0.5 * vorticity, 0.0, 0.0, 1.0); } ` ); const vorticityShader = compileShader( gl.FRAGMENT_SHADER, ` precision highp float; precision highp sampler2D; varying vec2 vUv; varying vec2 vL; varying vec2 vR; varying vec2 vT; varying vec2 vB; uniform sampler2D uVelocity; uniform sampler2D uCurl; uniform float curl; uniform float dt; void main () { float L = texture2D(uCurl, vL).x; float R = texture2D(uCurl, vR).x; float T = texture2D(uCurl, vT).x; float B = texture2D(uCurl, vB).x; float C = texture2D(uCurl, vUv).x; vec2 force = 0.5 * vec2(abs(T) - abs(B), abs(R) - abs(L)); force /= length(force) + 0.0001; force *= curl * C; force.y *= -1.0; vec2 vel = texture2D(uVelocity, vUv).xy; gl_FragColor = vec4(vel + force * dt, 0.0, 1.0); } ` ); const pressureShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying highp vec2 vUv; varying highp vec2 vL; varying highp vec2 vR; varying highp vec2 vT; varying highp vec2 vB; uniform sampler2D uPressure; uniform sampler2D uDivergence; vec2 boundary (vec2 uv) { return uv; // uncomment if you use wrap or repeat texture mode // uv = min(max(uv, 0.0), 1.0); // return uv; } void main () { float L = texture2D(uPressure, boundary(vL)).x; float R = texture2D(uPressure, boundary(vR)).x; float T = texture2D(uPressure, boundary(vT)).x; float B = texture2D(uPressure, boundary(vB)).x; float C = texture2D(uPressure, vUv).x; float divergence = texture2D(uDivergence, vUv).x; float pressure = (L + R + B + T - divergence) * 0.25; gl_FragColor = vec4(pressure, 0.0, 0.0, 1.0); } ` ); const gradientSubtractShader = compileShader( gl.FRAGMENT_SHADER, ` precision mediump float; precision mediump sampler2D; varying highp vec2 vUv; varying highp vec2 vL; varying highp vec2 vR; varying highp vec2 vT; varying highp vec2 vB; uniform sampler2D uPressure; uniform sampler2D uVelocity; vec2 boundary (vec2 uv) { return uv; // uv = min(max(uv, 0.0), 1.0); // return uv; } void main () { float L = texture2D(uPressure, boundary(vL)).x; float R = texture2D(uPressure, boundary(vR)).x; float T = texture2D(uPressure, boundary(vT)).x; float B = texture2D(uPressure, boundary(vB)).x; vec2 velocity = texture2D(uVelocity, vUv).xy; velocity.xy -= vec2(R - L, T - B); gl_FragColor = vec4(velocity, 0.0, 1.0); } ` ); const blit = (() =\u0026gt; { gl.bindBuffer(gl.ARRAY_BUFFER, gl.createBuffer()); gl.bufferData( gl.ARRAY_BUFFER, new Float32Array([-1, -1, -1, 1, 1, 1, 1, -1]), gl.STATIC_DRAW ); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, gl.createBuffer()); gl.bufferData( gl.ELEMENT_ARRAY_BUFFER, new Uint16Array([0, 1, 2, 0, 2, 3]), gl.STATIC_DRAW ); gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(0); return (destination) =\u0026gt; { gl.bindFramebuffer(gl.FRAMEBUFFER, destination); gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0); }; })(); let simWidth; let simHeight; let dyeWidth; let dyeHeight; let density; let velocity; let divergence; let curl; let pressure; let bloom; let ditheringTexture = createTextureAsync(\u0026#34;LDR_RGB1_0.png\u0026#34;); const clearProgram = new GLProgram(baseVertexShader, clearShader); const colorProgram = new GLProgram(baseVertexShader, colorShader); const backgroundProgram = new GLProgram(baseVertexShader, backgroundShader); const displayProgram = new GLProgram(baseVertexShader, displayShader); const displayBloomProgram = new GLProgram(baseVertexShader, displayBloomShader); const displayShadingProgram = new GLProgram( baseVertexShader, displayShadingShader ); const displayBloomShadingProgram = new GLProgram( baseVertexShader, displayBloomShadingShader ); const bloomPrefilterProgram = new GLProgram( baseVertexShader, bloomPrefilterShader ); const bloomBlurProgram = new GLProgram(baseVertexShader, bloomBlurShader); const bloomFinalProgram = new GLProgram(baseVertexShader, bloomFinalShader); const splatProgram = new GLProgram(baseVertexShader, splatShader); const advectionProgram = new GLProgram( baseVertexShader, ext.supportLinearFiltering ? advectionShader : advectionManualFilteringShader ); const divergenceProgram = new GLProgram(baseVertexShader, divergenceShader); const curlProgram = new GLProgram(baseVertexShader, curlShader); const vorticityProgram = new GLProgram(baseVertexShader, vorticityShader); const pressureProgram = new GLProgram(baseVertexShader, pressureShader); const gradienSubtractProgram = new GLProgram( baseVertexShader, gradientSubtractShader ); function initFramebuffers() { let simRes = getResolution(config.SIM_RESOLUTION); let dyeRes = getResolution(config.DYE_RESOLUTION); simWidth = simRes.width; simHeight = simRes.height; dyeWidth = dyeRes.width; dyeHeight = dyeRes.height; const texType = ext.halfFloatTexType; const rgba = ext.formatRGBA; const rg = ext.formatRG; const r = ext.formatR; const filtering = ext.supportLinearFiltering ? gl.LINEAR : gl.NEAREST; if (density == null) density = createDoubleFBO( dyeWidth, dyeHeight, rgba.internalFormat, rgba.format, texType, filtering ); else density = resizeDoubleFBO( density, dyeWidth, dyeHeight, rgba.internalFormat, rgba.format, texType, filtering ); if (velocity == null) velocity = createDoubleFBO( simWidth, simHeight, rg.internalFormat, rg.format, texType, filtering ); else velocity = resizeDoubleFBO( velocity, simWidth, simHeight, rg.internalFormat, rg.format, texType, filtering ); divergence = createFBO( simWidth, simHeight, r.internalFormat, r.format, texType, gl.NEAREST ); curl = createFBO( simWidth, simHeight, r.internalFormat, r.format, texType, gl.NEAREST ); pressure = createDoubleFBO( simWidth, simHeight, r.internalFormat, r.format, texType, gl.NEAREST ); initBloomFramebuffers(); } function initBloomFramebuffers() { let res = getResolution(config.BLOOM_RESOLUTION); const texType = ext.halfFloatTexType; const rgba = ext.formatRGBA; const filtering = ext.supportLinearFiltering ? gl.LINEAR : gl.NEAREST; bloom = createFBO( res.width, res.height, rgba.internalFormat, rgba.format, texType, filtering ); bloomFramebuffers.length = 0; for (let i = 0; i \u0026lt; config.BLOOM_ITERATIONS; i++) { let width = res.width \u0026gt;\u0026gt; (i + 1); let height = res.height \u0026gt;\u0026gt; (i + 1); if (width \u0026lt; 2 || height \u0026lt; 2) break; let fbo = createFBO( width, height, rgba.internalFormat, rgba.format, texType, filtering ); bloomFramebuffers.push(fbo); } } function createFBO(w, h, internalFormat, format, type, param) { gl.activeTexture(gl.TEXTURE0); let texture = gl.createTexture(); gl.bindTexture(gl.TEXTURE_2D, texture); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, param); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, param); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, w, h, 0, format, type, null); let fbo = gl.createFramebuffer(); gl.bindFramebuffer(gl.FRAMEBUFFER, fbo); gl.framebufferTexture2D( gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0 ); gl.viewport(0, 0, w, h); gl.clear(gl.COLOR_BUFFER_BIT); return { texture, fbo, width: w, height: h, attach(id) { gl.activeTexture(gl.TEXTURE0 + id); gl.bindTexture(gl.TEXTURE_2D, texture); return id; }, }; } function createDoubleFBO(w, h, internalFormat, format, type, param) { let fbo1 = createFBO(w, h, internalFormat, format, type, param); let fbo2 = createFBO(w, h, internalFormat, format, type, param); return { get read() { return fbo1; }, set read(value) { fbo1 = value; }, get write() { return fbo2; }, set write(value) { fbo2 = value; }, swap() { let temp = fbo1; fbo1 = fbo2; fbo2 = temp; }, }; } function resizeFBO(target, w, h, internalFormat, format, type, param) { let newFBO = createFBO(w, h, internalFormat, format, type, param); clearProgram.bind(); gl.uniform1i(clearProgram.uniforms.uTexture, target.attach(0)); gl.uniform1f(clearProgram.uniforms.value, 1); blit(newFBO.fbo); return newFBO; } function resizeDoubleFBO(target, w, h, internalFormat, format, type, param) { target.read = resizeFBO( target.read, w, h, internalFormat, format, type, param ); target.write = createFBO(w, h, internalFormat, format, type, param); return target; } function createTextureAsync(url) { let texture = gl.createTexture(); gl.bindTexture(gl.TEXTURE_2D, texture); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.REPEAT); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.REPEAT); gl.texImage2D( gl.TEXTURE_2D, 0, gl.RGB, 1, 1, 0, gl.RGB, gl.UNSIGNED_BYTE, new Uint8Array([255, 255, 255]) ); let obj = { texture, width: 1, height: 1, attach(id) { gl.activeTexture(gl.TEXTURE0 + id); gl.bindTexture(gl.TEXTURE_2D, texture); return id; }, }; let image = new Image(); image.onload = () =\u0026gt; { obj.width = image.width; obj.height = image.height; gl.bindTexture(gl.TEXTURE_2D, texture); gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, image); }; image.src = url; return obj; } initFramebuffers(); multipleSplats(parseInt(Math.random() * 20) + 3); let lastColorChangeTime = Date.now(); update(); function update() { resizeCanvas(); input(); if (!config.PAUSED) step(0.016); render(null); requestAnimationFrame(update); } function input() { if (splatStack.length \u0026gt; 0) multipleSplats(splatStack.pop()); for (let i = 0; i \u0026lt; pointers.length; i++) { const p = pointers[i]; if (p.moved) { splat(p.x, p.y, p.dx, p.dy, p.color); p.moved = false; } } if (lastColorChangeTime + 100 \u0026lt; Date.now()) { lastColorChangeTime = Date.now(); for (let i = 0; i \u0026lt; pointers.length; i++) { const p = pointers[i]; p.color = config.COLORFUL ? generateColor() : config.POINTER_COLOR.getRandom(); } } } function step(dt) { gl.disable(gl.BLEND); gl.viewport(0, 0, simWidth, simHeight); curlProgram.bind(); gl.uniform2f(curlProgram.uniforms.texelSize, 1.0 / simWidth, 1.0 / simHeight); gl.uniform1i(curlProgram.uniforms.uVelocity, velocity.read.attach(0)); blit(curl.fbo); vorticityProgram.bind(); gl.uniform2f( vorticityProgram.uniforms.texelSize, 1.0 / simWidth, 1.0 / simHeight ); gl.uniform1i(vorticityProgram.uniforms.uVelocity, velocity.read.attach(0)); gl.uniform1i(vorticityProgram.uniforms.uCurl, curl.attach(1)); gl.uniform1f(vorticityProgram.uniforms.curl, config.CURL); gl.uniform1f(vorticityProgram.uniforms.dt, dt); blit(velocity.write.fbo); velocity.swap(); divergenceProgram.bind(); gl.uniform2f( divergenceProgram.uniforms.texelSize, 1.0 / simWidth, 1.0 / simHeight ); gl.uniform1i(divergenceProgram.uniforms.uVelocity, velocity.read.attach(0)); blit(divergence.fbo); clearProgram.bind(); gl.uniform1i(clearProgram.uniforms.uTexture, pressure.read.attach(0)); gl.uniform1f(clearProgram.uniforms.value, config.PRESSURE_DISSIPATION); blit(pressure.write.fbo); pressure.swap(); pressureProgram.bind(); gl.uniform2f( pressureProgram.uniforms.texelSize, 1.0 / simWidth, 1.0 / simHeight ); gl.uniform1i(pressureProgram.uniforms.uDivergence, divergence.attach(0)); for (let i = 0; i \u0026lt; config.PRESSURE_ITERATIONS; i++) { gl.uniform1i(pressureProgram.uniforms.uPressure, pressure.read.attach(1)); blit(pressure.write.fbo); pressure.swap(); } gradienSubtractProgram.bind(); gl.uniform2f( gradienSubtractProgram.uniforms.texelSize, 1.0 / simWidth, 1.0 / simHeight ); gl.uniform1i( gradienSubtractProgram.uniforms.uPressure, pressure.read.attach(0) ); gl.uniform1i( gradienSubtractProgram.uniforms.uVelocity, velocity.read.attach(1) ); blit(velocity.write.fbo); velocity.swap(); advectionProgram.bind(); gl.uniform2f( advectionProgram.uniforms.texelSize, 1.0 / simWidth, 1.0 / simHeight ); if (!ext.supportLinearFiltering) gl.uniform2f( advectionProgram.uniforms.dyeTexelSize, 1.0 / simWidth, 1.0 / simHeight ); let velocityId = velocity.read.attach(0); gl.uniform1i(advectionProgram.uniforms.uVelocity, velocityId); gl.uniform1i(advectionProgram.uniforms.uSource, velocityId); gl.uniform1f(advectionProgram.uniforms.dt, dt); gl.uniform1f( advectionProgram.uniforms.dissipation, config.VELOCITY_DISSIPATION ); blit(velocity.write.fbo); velocity.swap(); gl.viewport(0, 0, dyeWidth, dyeHeight); if (!ext.supportLinearFiltering) gl.uniform2f( advectionProgram.uniforms.dyeTexelSize, 1.0 / dyeWidth, 1.0 / dyeHeight ); gl.uniform1i(advectionProgram.uniforms.uVelocity, velocity.read.attach(0)); gl.uniform1i(advectionProgram.uniforms.uSource, density.read.attach(1)); gl.uniform1f( advectionProgram.uniforms.dissipation, config.DENSITY_DISSIPATION ); blit(density.write.fbo); density.swap(); } function render(target) { if (config.BLOOM) applyBloom(density.read, bloom); if (target == null || !config.TRANSPARENT) { gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_ALPHA); gl.enable(gl.BLEND); } else { gl.disable(gl.BLEND); } let width = target == null ? gl.drawingBufferWidth : dyeWidth; let height = target == null ? gl.drawingBufferHeight : dyeHeight; gl.viewport(0, 0, width, height); if (!config.TRANSPARENT) { colorProgram.bind(); let bc = config.BACK_COLOR; gl.uniform4f( colorProgram.uniforms.color, bc.r / 255, bc.g / 255, bc.b / 255, 1 ); blit(target); } if (target == null \u0026amp;\u0026amp; config.TRANSPARENT) { backgroundProgram.bind(); gl.uniform1f( backgroundProgram.uniforms.aspectRatio, canvas.width / canvas.height ); blit(null); } if (config.SHADING) { let program = config.BLOOM ? displayBloomShadingProgram : displayShadingProgram; program.bind(); gl.uniform2f(program.uniforms.texelSize, 1.0 / width, 1.0 / height); gl.uniform1i(program.uniforms.uTexture, density.read.attach(0)); if (config.BLOOM) { gl.uniform1i(program.uniforms.uBloom, bloom.attach(1)); gl.uniform1i(program.uniforms.uDithering, ditheringTexture.attach(2)); let scale = getTextureScale(ditheringTexture, width, height); gl.uniform2f(program.uniforms.ditherScale, scale.x, scale.y); } } else { let program = config.BLOOM ? displayBloomProgram : displayProgram; program.bind(); gl.uniform1i(program.uniforms.uTexture, density.read.attach(0)); if (config.BLOOM) { gl.uniform1i(program.uniforms.uBloom, bloom.attach(1)); gl.uniform1i(program.uniforms.uDithering, ditheringTexture.attach(2)); let scale = getTextureScale(ditheringTexture, width, height); gl.uniform2f(program.uniforms.ditherScale, scale.x, scale.y); } } blit(target); } function applyBloom(source, destination) { if (bloomFramebuffers.length \u0026lt; 2) return; let last = destination; gl.disable(gl.BLEND); bloomPrefilterProgram.bind(); let knee = config.BLOOM_THRESHOLD * config.BLOOM_SOFT_KNEE + 0.0001; let curve0 = config.BLOOM_THRESHOLD - knee; let curve1 = knee * 2; let curve2 = 0.25 / knee; gl.uniform3f(bloomPrefilterProgram.uniforms.curve, curve0, curve1, curve2); gl.uniform1f( bloomPrefilterProgram.uniforms.threshold, config.BLOOM_THRESHOLD ); gl.uniform1i(bloomPrefilterProgram.uniforms.uTexture, source.attach(0)); gl.viewport(0, 0, last.width, last.height); blit(last.fbo); bloomBlurProgram.bind(); for (let i = 0; i \u0026lt; bloomFramebuffers.length; i++) { let dest = bloomFramebuffers[i]; gl.uniform2f( bloomBlurProgram.uniforms.texelSize, 1.0 / last.width, 1.0 / last.height ); gl.uniform1i(bloomBlurProgram.uniforms.uTexture, last.attach(0)); gl.viewport(0, 0, dest.width, dest.height); blit(dest.fbo); last = dest; } gl.blendFunc(gl.ONE, gl.ONE); gl.enable(gl.BLEND); for (let i = bloomFramebuffers.length - 2; i \u0026gt;= 0; i--) { let baseTex = bloomFramebuffers[i]; gl.uniform2f( bloomBlurProgram.uniforms.texelSize, 1.0 / last.width, 1.0 / last.height ); gl.uniform1i(bloomBlurProgram.uniforms.uTexture, last.attach(0)); gl.viewport(0, 0, baseTex.width, baseTex.height); blit(baseTex.fbo); last = baseTex; } gl.disable(gl.BLEND); bloomFinalProgram.bind(); gl.uniform2f( bloomFinalProgram.uniforms.texelSize, 1.0 / last.width, 1.0 / last.height ); gl.uniform1i(bloomFinalProgram.uniforms.uTexture, last.attach(0)); gl.uniform1f(bloomFinalProgram.uniforms.intensity, config.BLOOM_INTENSITY); gl.viewport(0, 0, destination.width, destination.height); blit(destination.fbo); } function splat(x, y, dx, dy, color) { gl.viewport(0, 0, simWidth, simHeight); splatProgram.bind(); gl.uniform1i(splatProgram.uniforms.uTarget, velocity.read.attach(0)); gl.uniform1f(splatProgram.uniforms.aspectRatio, canvas.width / canvas.height); gl.uniform2f( splatProgram.uniforms.point, x / canvas.width, 1.0 - y / canvas.height ); gl.uniform3f(splatProgram.uniforms.color, dx, -dy, 1.0); gl.uniform1f(splatProgram.uniforms.radius, config.SPLAT_RADIUS / 100.0); blit(velocity.write.fbo); velocity.swap(); gl.viewport(0, 0, dyeWidth, dyeHeight); gl.uniform1i(splatProgram.uniforms.uTarget, density.read.attach(0)); gl.uniform3f(splatProgram.uniforms.color, color.r, color.g, color.b); blit(density.write.fbo); density.swap(); } function multipleSplats(amount) { for (let i = 0; i \u0026lt; amount; i++) { const color = config.COLORFUL ? generateColor() : Object.assign({}, config.POINTER_COLOR.getRandom()); color.r *= 10.0; color.g *= 10.0; color.b *= 10.0; const x = canvas.width * Math.random(); const y = canvas.height * Math.random(); const dx = 1000 * (Math.random() - 0.5); const dy = 1000 * (Math.random() - 0.5); splat(x, y, dx, dy, color); } } function resizeCanvas() { if ( canvas.width != canvas.clientWidth || canvas.height != canvas.clientHeight ) { canvas.width = canvas.clientWidth; canvas.height = canvas.clientHeight; initFramebuffers(); } } canvas.addEventListener(\u0026#34;mousemove\u0026#34;, (e) =\u0026gt; { if (!config.SHOW_MOUSE_MOVEMENT) return; pointers[0].moved = true; pointers[0].dx = (e.offsetX - pointers[0].x) * 5.0; pointers[0].dy = (e.offsetY - pointers[0].y) * 5.0; pointers[0].x = e.offsetX; pointers[0].y = e.offsetY; }); canvas.addEventListener( \u0026#34;touchmove\u0026#34;, (e) =\u0026gt; { e.preventDefault(); const touches = e.targetTouches; for (let i = 0; i \u0026lt; touches.length; i++) { let pointer = pointers[i]; pointer.moved = pointer.down; pointer.dx = (touches[i].pageX - pointer.x) * 8.0; pointer.dy = (touches[i].pageY - pointer.y) * 8.0; pointer.x = touches[i].pageX; pointer.y = touches[i].pageY; } }, false ); canvas.addEventListener(\u0026#34;mouseenter\u0026#34;, () =\u0026gt; { pointers[0].down = true; pointers[0].color = config.POINTER_COLOR.getRandom(); }); canvas.addEventListener(\u0026#34;touchstart\u0026#34;, (e) =\u0026gt; { if (!config.SPLAT_ON_CLICK) return; e.preventDefault(); const touches = e.targetTouches; for (let i = 0; i \u0026lt; touches.length; i++) { if (i \u0026gt;= pointers.length) pointers.push(new pointerPrototype()); pointers[i].id = touches[i].identifier; pointers[i].down = true; pointers[i].x = touches[i].pageX; pointers[i].y = touches[i].pageY; pointers[i].color = config.POINTER_COLOR.getRandom(); } }); canvas.addEventListener(\u0026#34;mousedown\u0026#34;, () =\u0026gt; { if (!config.SPLAT_ON_CLICK) return; multipleSplats(parseInt(Math.random() * 20) + 5); }); window.addEventListener(\u0026#34;mouseleave\u0026#34;, () =\u0026gt; { pointers[0].down = false; }); window.addEventListener(\u0026#34;touchend\u0026#34;, (e) =\u0026gt; { const touches = e.changedTouches; for (let i = 0; i \u0026lt; touches.length; i++) for (let j = 0; j \u0026lt; pointers.length; j++) if (touches[i].identifier == pointers[j].id) pointers[j].down = false; }); window.addEventListener(\u0026#34;keydown\u0026#34;, (e) =\u0026gt; { if (e.code === \u0026#34;KeyP\u0026#34;) config.PAUSED = !config.PAUSED; if (e.key === \u0026#34; \u0026#34;) splatStack.push(parseInt(Math.random() * 20) + 5); }); function generateColor() { let c = HSVtoRGB(Math.random(), 1.0, 1.0); c.r *= 0.15; c.g *= 0.15; c.b *= 0.15; return c; } function HSVtoRGB(h, s, v) { let r, g, b, i, f, p, q, t; i = Math.floor(h * 6); f = h * 6 - i; p = v * (1 - s); q = v * (1 - f * s); t = v * (1 - (1 - f) * s); switch (i % 6) { case 0: (r = v), (g = t), (b = p); break; case 1: (r = q), (g = v), (b = p); break; case 2: (r = p), (g = v), (b = t); break; case 3: (r = p), (g = q), (b = v); break; case 4: (r = t), (g = p), (b = v); break; case 5: (r = v), (g = p), (b = q); break; } return { r, g, b, }; } function RGBToHue(r, g, b) { // Find greatest and smallest channel values let cmin = Math.min(r, g, b), cmax = Math.max(r, g, b), delta = cmax - cmin, h = 0, s = 0, l = 0; // Calculate hue // No difference if (delta == 0) h = 0; // Red is max else if (cmax == r) h = ((g - b) / delta) % 6; // Green is max else if (cmax == g) h = (b - r) / delta + 2; // Blue is max else h = (r - g) / delta + 4; h = Math.round(h * 60); // Make negative hues positive behind 360° if (h \u0026lt; 0) h += 360; return h; } function getResolution(resolution) { let aspectRatio = gl.drawingBufferWidth / gl.drawingBufferHeight; if (aspectRatio \u0026lt; 1) aspectRatio = 1.0 / aspectRatio; let max = Math.round(resolution * aspectRatio); let min = Math.round(resolution); if (gl.drawingBufferWidth \u0026gt; gl.drawingBufferHeight) return { width: max, height: min }; else return { width: min, height: max }; } function getTextureScale(texture, width, height) { return { x: width / texture.width, y: height / texture.height, }; } function rgbToPointerColor(color) { let c = color.split(\u0026#34; \u0026#34;); // let hue = RGBToHue(c[0], c[1], c[2]); // let c2 = HSVtoRGB(hue/360, 1.0, 1.0); // c2.r *= 0.15; // c2.g *= 0.15; // c2.b *= 0.15; // return c2; return { r: c[0] * 0.15, g: c[1] * 0.15, b: c[2] * 0.15, }; } "},{"section":"Blog","slug":"/blog/computer-technology/ai/","title":"AI技术","description":"2024年最近两年出现的主要生成式 AI 技术罗列","date":"October 14, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, AI工具","tags":"","content":"近几年ai发展历程 (2022-2024),以下使用表格进行详细展示\n技术名称 技术描述 访问链接 收费情况 GPT-4 (OpenAI) GPT-4 是 OpenAI 发布的最新版本的语言模型，显著提升了生成文本的质量和准确性，广泛应用于对话、写作和代码生成。 OpenAI GPT-4 免费试用，付费订阅（API访问和Pro版本） Claude (Anthropic) Claude 是由 Anthropic 开发的生成式 AI 对话模型，注重安全性和可控性，设计为更可预测和安全的 AI。 Anthropic Claude 免费试用，企业版付费 DALL·E 3 (OpenAI) DALL·E 3 是 OpenAI 的图像生成模型，能够根据文字描述生成高质量、精细的图像，进一步提升了图像生成能力。 OpenAI DALL·E 3 免费试用，API 和高级功能付费 Stable Diffusion XL (Stability AI) 稳定扩散 (Stable Diffusion) 是一种图像生成模型，提供了更高分辨率的图像生成，并且在文本到图像的转换任务中性能强大。 Stability AI 开源，免费使用，付费API ChatGPT Code Interpreter (OpenAI) 该功能扩展了 ChatGPT 的能力，使其能够执行代码、处理数据分析和解决复杂的计算任务，适合开发人员和数据科学家。 OpenAI Code Interpreter 免费试用，Pro版本付费 MidJourney V5 MidJourney 是一个流行的文本到图像生成模型，它在创造艺术风格图像方面表现出色，并被许多设计师和艺术家使用。 MidJourney 付费订阅，按月计费 Gemini (Google DeepMind) Google 的 Gemini 系列模型整合了 DeepMind 的最先进技术，旨在竞争 OpenAI 的 GPT 系列，提供多种生成式 AI 服务。 Google DeepMind 目前无具体定价信息，视使用场景定价 Mistral 7B Mistral 是一个小型高效的生成式语言模型，尽管模型参数较小，但在各类文本生成任务中表现出色。 Mistral AI 免费 LLaMA 2 (Meta) LLaMA 2 是 Meta 的开放源代码语言模型，旨在为研究和开发提供一个强大的生成式 AI 基础。 Meta LLaMA 2 开源，免费使用 Cohere Command R 专为自然语言理解和生成任务设计的生成式 AI 模型，支持多语言和特定任务定制。 Cohere AI 免费试用，企业级付费 "},{"section":"Blog","slug":"/blog/notes/architecture-design/","title":"架构设计笔记","description":"阅读架构设计的笔记","date":"December 1, 2023","image":null,"imageSM":null,"searchKeyword":"","categories":"架构设计, 前端","tags":"架构设计, 前端","content":"该文章将目前可能能用到的架构理念，概念统一汇总整理～\n多态\n多态：多态的实际含义是:同一操作作用于不同的对象上面，可以产生不同的解释和不同的执行结 果。换句话说，给不同的对象发送同一个消息的时候，这些对象会根据这个消息分别给出不同的反馈。 多态背后的思想是将“做什么”和“谁去做以及怎样去做”分离开来，也就是将“不变的事 物”与 “可能改变的事物”分离开来。 把不变的部分隔离出来，把可变的部分封装起来，这给予了我们 扩展程序的能力 使用继承来得到多态效果，是让对象表现出多态性的最常用手段。 高阶函数实现AOP\n把这些功能抽离出来之后， 再通过“动态织入”的方式掺入业务逻辑模块中。这样做的好处首先是可以保持业务逻辑模块的纯净和高内聚性，其次是可以很方便地复用日志统计等功能模块。\ncurrying uncurrying 分时函数 惰性加载函数 在 Web 开发中，因为浏览器之间的实现差异，一些嗅探工作总是不可避免。比如我们需要一个在各个浏览器中能够通用的事件绑定函数 addEvent，常见的写法如下:\nvar addEvent = function (elem, type, handler) { if (window.addEventListener) { return elem.addEventListener(type, handler, false); } if (window.attachEvent) { return elem.attachEvent(\u0026#39;on\u0026#39; + type, handler); } }; 第二种方案是这样，我们把嗅探浏览器的操作提前到代码加载的时候，在代码加载的时候就立刻进行一次判断，以便让 addEvent 返回一个包裹了正确逻辑的函数。代码如下:\nvar addEvent = (function () { if (window.addEventListener) { return function (elem, type, handler) { elem.addEventListener(type, handler, false); } } if (window.attachEvent) { return function (elem, type, handler) { elem.attachEvent(\u0026#39;on\u0026#39; + type, handler); } } })(); 单例模式\n全局变量存在很多问题，减少全局变量声明，1. 使用命名空间；2. 使用闭包封装私有变量\n代理模式 代理模式包括许多小分类，在 JavaScript 开发中最常用的是虚拟代理和缓存代理。虽然代理 模式非常有用，但我们在编写业务代码的时候，往往不需要去预先猜测是否需要使用代理模式。 当真正发现不方便直接访问某个对象的时候，再编写代理也不迟\n"},{"section":"Blog","slug":"/blog/tools/tools-animation-math/","title":"从贝塞尔曲线的计算感受数学建模的魅力","description":"最近在做可视化相关的东西，需要计算贝塞尔曲线上一点的坐标位置，从这个解决过程中感受到了数学建模的魅力。","date":"December 1, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"动画, 数学, 前端","tags":"动画, 数学, 前端","content":"最近在做前端可视化相关的东西，在完成动画效果时，遇到一个不是很好处理的问题，需要让一个元素在画布上以曲线的轨迹进行运动。因为动画这块之前基本也没有怎么接触过，做的也都是简单的线性动画效果，所以碰到这个需求点的时候觉得是有点难度的。\n其实，要真的实现按照一定曲线轨迹运动的效果倒也不难，毕竟圆、椭圆方程在平时做布局计算的时候用的也挺多的。但是，用圆或者椭圆计算曲线相当于是找了个特殊场景，不具备通用性；另一方面，说到曲线的绘制，贝塞尔曲线是绕不开的，这也是非常值得考虑的方案。\n动画帧计算\n一段动画实际上是由多个静态帧组成的，当帧率达到人眼不可分辨的程度时（比如 60 FPS），就感觉像是一个无缝连续的视频在流畅的播放。而某一静态帧的状态用数学公式来表达如下：\ny = F(t) (0 \u0026lt;= t \u0026lt;= 1) 那么对于一个物体从 x0 运动到 x1，如何计算 t 时刻的位置？按照我的思路来看，可以转化为以下数学公式：\nF(t) = (x1 - x0)*t + x0 (0 \u0026lt;= t \u0026lt;= 1) 这么算其实是没错的，但这个公式在数学建模的角度来看，其实是不好的，后面以计算贝塞尔曲线上一点的坐标为例解释为什么。这里先给出线性贝塞尔曲线数学公式：\nB(t) = (1 - t)P0 + tP1 (0 \u0026lt;= t \u0026lt;= 1)\n贝塞尔曲线 贝塞尔曲线（Bézier curve）在工业设计领域是一个非常重要的存在，应用非常广泛，在计算机图形学领域中贝塞尔曲线也有很好的支持，例如 Canvas API 原生就有提供贝塞尔曲线的绘制接口。\nCanvasRenderingContext2D.bezierCurveTo()\n贝塞尔曲线从概念上来看是很难理解的，如何转化为数学公式来计算贝塞尔曲线，而这个过程是什么样的，刚开始理解起来也是比较抽象的。先来看看其（二次贝塞尔曲线）数学定义：\n其中 P0、P1、P2 分别为起点、控制点、终点。\n那么，有了公式计算二次贝塞尔曲线上一点按理来说已经可以实现了，但在这里之所以用贝塞尔曲线这个比较难理解的数学模型来探讨，其实是为了最终得到一个简化的具有普适性的解决动画帧计算的数学模型。对于熟悉动画计算的人来说，很多文档中对于开头提出的问题给出的数学公式为以下：\nF(t) = (1 - t)*x0 + t*x1 (0 \u0026lt;= t \u0026lt;= 1) 这个时候，你会发现无论是以上公式，还是一次、二次或更高次的贝塞尔曲线公式中都有一个类似的元素即 1 - t。当然，公式都是相互推导以不同形式展现的，即：\nF(t) = (1 - t)*x0 + t*x1 = (x1 - x0)*t + x0 (0 \u0026lt;= t \u0026lt;= 1) 公式相等是本质，但不同的展现形式蕴含的思维模式不同（或者说有没有利用好数学建模来进行问题的抽象）。以上面的公式来分析，前者表达的是 x0 与 x1 分别在 t 时刻状态的叠加，后者则表达的是起始状态 x0 叠加从 x0 运动到 x1 过程中 t 时刻的状态。从其蕴含的思维模式来分析，前者关注的是结果，后者则先分析过程再得到结果。\n其实，说到这里，我觉得一个好的数学建模思维的魅力已经体现出来了，动画帧计算应尽可能的简单且关注核心问题，不要被过程所迷惑，这也是为何很多文档中的公式包含 1 - t 元素的原因。\n计算二次贝塞尔曲线上一点的坐标 接下来，结合 wiki 中构建贝塞尔曲线一节的动态图 对二次贝塞尔曲线的形成过程有个直观的理解，利用以上思路对计算二次贝塞尔曲线上一点的坐标这个问题进行数学建模：\n给出 P0、P1、P2 分别为起点、控制点、终点，曲线上的点是控制点由 P0 运动到 P1 过程中点 P01 与终点由 P1 运动到 P2 过程中点 P12 连线上的点，转为数学公式如下：\nP01 = (1 - t)P0 + tP1 P12 = (1 - t)P1 + tP2 P012 = (1 - t)P01 + tP12 这样就得到了 t 时刻曲线上的点坐标为 P012，根据推导 P012 其实就等于前面给出的二次贝塞尔曲线的公式 B(t) 。按照这个思路和数学建模的思维，计算三次、四次贝塞尔曲线上点的坐标就很简单，不断叠加 t 时刻的状态即可。\n结语 总结成一句话来说，用数学建模的思维把复杂问题高度抽象成简单问题，再用简单的方案去解决复杂的问题。对于动画帧计算来说，就要把问题高度抽象成起始状态与终止状态在 t 时刻状态的叠加，不应该关注过程，最终就可以得出线性轨迹和曲线轨迹的计算本质上都是一个线性插值的过程，无论多么复杂的轨迹问题都是要用线性插值的方案来解决。\n参考 https://zh.wikipedia.org/zh-cn/%E8%B2%9D%E8%8C%B2%E6%9B%B2%E7%B7%9A https://www.cnblogs.com/fangsmile/articles/11642607.html "},{"section":"Blog","slug":"/blog/computer-technology/mobile-web/wx-dingding/","title":"微信小程序与钉钉小程序开发流程","description":"微信小程序开发与钉钉小程序开发的移动端兼容上有很多需要注意的点。","date":"November 11, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 小程序, WX","tags":"","content":"开发小程序有很多问题特此记录一下～～～\n小程序开发（移动端开发）兼容注意事项：\nios不兼容yyyy-MM-dd HH:mm:ss这种时间格式，需要将-替换成/，在安卓下两种格式都支持。\n使用window.location.reload()方法刷新页面，在安卓下无效。\n正常情况下使用window.location.replace()方法跳转页面时会覆盖当前页面而不会生成新的history记录，但是在安卓下依然会生成history记录。\nios中，父元素设置border-radius和overflow:hidden实现圆角。如果此时子元素使用了transform属性会导致父元素的圆角失效。\n小程序中使用web-view打开pdf, IOS 可以正常打开，Android 打开为空白；\n微信小程序分包加载，需要注意单个分包或者主包大小不要超过2m\nuni-app的坑，尤其是弹窗官方提供的uni-popup，存在ref引用销毁问题，导致点击多次无法正常绘制了，需要自己写弹窗逻辑（能不用官方的插件尽量不用，有很多性能问题都是官方插件引起，比如日期控件或者弹窗控件都会产城一些未知bug）\n安卓与ios在很多地方api不能共用，比如数字转换添加千分位这个问题，安卓就不支持（JS内置 API （toLocaleString），ios是支持的，但是在安卓的浏览器内核中不存在这个api无法正常转译），具体可以看链接：https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Number/toLocaleString\n虚拟滚动的实现思路\n基本思路就是动态渲染一个div中的元素组件一般是4-10个模块，实现了数据量200条数据但是只需要10个模块\n（1）给需要滚动的组件添加padding-top与padding-bottom，然后分别计算这两个相对的像素值\n（2）或者父元素使用绝对定位，其中动态的div使用相对定位，然后使用两栏或者三栏布局使用卡片式渲染，不断推动向下渲染即可\n（3）难点有二：用户快速滑动可能也会导致渲染白屏，优化体验可以考虑使用降低用户的滑动速度或者是增加更多的渲染模块\n"},{"section":"Blog","slug":"/blog/computer-technology/web/web-tips-fonts/","title":"Web 字体加载对 DOM 位置的影响","description":"由于使用了第三方 Web 字体，产生了一个潜在的线上问题，苦于调试过程中一直没有考虑字体加载会对 DOM 位置产生影响，浪费了大量时间和精力。","date":"October 16, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端","tags":"计算机技术, Web前端","content":"由于公司的业务会用到自己设计师定制的 Web 字体，所以一般在组件开发过程中会利用 CSS 引用该字体（@font-face），前段时间发现一个线上问题：在部分 iOS 机型上，DOM 元素的位置发生了错位。\n首先，对于问题复现的必要条件做了分析，为以下几个方面\n部分 iOS 机型（新旧机型均有） 问题发生在首次页面加载时（即后续加载问题不再复现） 根据以往的经验和代码实现来看，必然是 DOM 测量的尺寸数据不准确导致的，于是首先尝试加了延迟的方案看看效果，发现问题依然存在，然后尝试线上调试看看具体测量到的 DOM 尺寸数据是否准确。由于线上调试比较麻烦，所以也更进一步分析为何问题出现在清除缓存后的首次加载，推测是什么资源加载太慢导致的？但当时由于着急，主要考虑的都是显式引入的资源（例如 js、css 文件等，忽略了一些细节），在这方面也没有什么进展。于是，继续尝试线上调试，结果发现首次加载和二次加载得到的 DOM 测量数据完全一致，此时这个问题就有点“邪门”了，难道是浏览器内核渲染的问题？Google 了很久，也没有什么收获，但由于对线上用户不是很大，就暂时搁置了这个问题，暂且认为是浏览器内核的一个什么 bug（虽然说这个确实没有什么说服力，但苦于花了很多精力和时间依然找不到原因，考虑到解决这个问题的性价比不高就先放弃了）。\n当然，之所以写这篇文章也是为了记录导致这个问题的真正原因和解决方案。后来，有个同事提到之前的文档有记录过类似因为公司定制字体加载导致的页面问题，简单看了下文档后，发现之前确实忽略了这个细节（字体文件通常比较大，加载比较慢，但由于是放在 CDN 上的所以一直没太在意）。经过和业务侧的前端沟通后，一天下午抽空尝试了下，发现确实是由于 Web 字体资源太大（CDN 不太稳定）加载较慢导致的 DOM 位置渲染错位（需要注意的是，该原因并没有导致 DOM 测量出现错误）。这里贴一下解决该问题的示例代码：\ndocument.fonts.ready.then(() =\u0026gt; { this.resize(); }); Web 字体加载快慢没有对 DOM 测量的数据准确性产生影响，也是在视觉效果会有影响（导致 DOM 位置错位）。这个问题场景以前没有遇到过，其原因和解决该问题所用到的 API 也比较冷门，所以在此记录一下。\n参考资源 Document.fonts "},{"section":"Blog","slug":"/blog/computer-technology/typescript/tools-typescript-use-script-to-ts-types/","title":"利用脚本执行 `tsc` 忽略类型检查错误","description":"TypeScript 作为一个强类型的语言，增强了 JavaScript 编程开发体验，类型定义文件为一个第三方模块的使用体验增色不少，现如今很多 npm 包的发布都内置了对类型定义文件的支持。","date":"August 6, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 工具, TypeScript, 类型定义","tags":"","content":"在发布 npm 包时添加对 TypeScript 类型定义文件的支持会让用户的使用体验增色不少，TypeScript 官方提供了 tsc --emitDeclarationOnly 命令用来生成类型定义文件（.d.ts）。但是，该命令会同时执行类型检查，遇到错误时会报错中断命令行进程，这就使其无法直接集成在 CI 环节在发布 npm 包时自动执行生成类型定义文件的操作。当然，一个解决办法就是解决掉代码中所有的类型检查错误即可，既然讨论到这个问题，必然不会花费额外精力去解决一些历史遗留问题。\ntsc --emitDeclarationOnly 怎么能让以上脚本在执行时不做类型检查（或者说忽略错误，例如类似 silent 标志位），在查阅了很多资料之后，显然 TypeScript 官方没有对其支持（因为他们认为忽略类型检查错误就失去了使用 TypeScript 的意义），但另一方面前端生态的很多工具链却都一致的推荐使用类 Babel 这种编译方案（不做类型检查），而且有很多开发者是有这样的需求的。在查阅很多资料无果后，突然想到前段时间学习了 Nodejs 的 child_process API，可以用其来写一些工具脚本，最终有了一个待实践的方案：利用 JS 脚本执行该命令，但忽略类型检查错误不让进程中断，这样就可以安全的集成到 CI 环节中。经过实践，确实能达到预期效果，贴出代码：\nconst { execSync } = require(\u0026#39;node:child_process\u0026#39;); try { const args = process.argv.slice(2); let isSilent = args.findIndex((item) =\u0026gt; item.trim() === \u0026#39;--silent\u0026#39;); if (isSilent \u0026gt; -1) { args.splice(isSilent, 1); isSilent = true; } else { isSilent = false; } if (isSilent) { console.log(\u0026#39;[generate-types] silent mode\u0026#39;); } // see https://nodejs.org/dist/latest-v16.x/docs/api/child_process.html#optionsstdio const result = execSync(`npx tsc --emitDeclarationOnly ${args.join(\u0026#39; \u0026#39;)}`, { cwd: WORKING_DIRECTORY, encoding: \u0026#39;utf8\u0026#39;, stdio: isSilent ? \u0026#39;ignore\u0026#39; : [\u0026#39;inherit\u0026#39;, \u0026#39;inherit\u0026#39;, \u0026#39;ignore\u0026#39;], }); } catch (error) { // console.error(error.message); } 这里实际上是利用 try ... catch 将错误捕获，防止其导致进程异常中断；另外，使用了 stdio 配置项去控制子进程的执行结果信息怎么交由父进程来处理，利用 silent 标志位将所有的输出信息忽略，或者仅忽略掉错误信息，类型检查的结果信息依然可以打印到控制台以做参考。\nnode generate-types.cjs --silent node generate-types.cjs node generate-types.cjs --watch # 等同于 tsc --emitDeclarationOnly --watch 在实际使用的过程中，发现 CI 环节的 Node 环境中会报错（npx 不存在），解决方案就是将要执行的命令写成 npm 脚本，在 js 脚本中运行 npm 脚本即可，例如：\n// npm 脚本 { \u0026#34;tsc:types\u0026#34;: \u0026#34;tsc --emitDeclarationOnly\u0026#34; } // js 脚本 execSync(`npm run tsc:types`); 至此，利用脚本执行命令可以轻松解决无法控制程序命令行为的问题。\n参考资源 https://www.typescriptlang.org/docs/handbook/declaration-files/dts-from-js.html "},{"section":"Blog","slug":"/blog/computer-technology/web/tools-web-fee-toolchain/","title":"前端工程化：对于构建工具链的简单思考","description":"前端工程化是一个值得了解的方向，从软件开发、测试到部署上线整个环节的深入，可以对软件工程有一个更深刻的理解，对于前端来说，构建工具链是工程化中重要的一环，这里对这么多年接触过得工具做一个简单的总结思考。","date":"August 1, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 工具, 构建工具链","tags":"计算机技术, Web前端, 工具, 构建工具链","content":"前端工程化是在做与业务开发完全不同的事情，旨在解决软件工程领域与开发者密切相关的问题，通常会将其与基建开发、DevOps 放在一起讨论。前端开发是复杂的，其结合了 HTML/CSS/JavaScript 3 种语言，甚至还有很多其超集，没有开箱即用的工具链，不像 Java Web 开发、Android 开发等等有官方或者商业领域非常成熟的工具可以利用，一切都源于开源社区的从 0 开始构建。正因如此，前端工程化领域百花齐放，开放与创新展现的淋漓尽致，这也是前端开发者了解学习软件工程的机会。\n这里对于前端开发中比较重要的一个环节，即构建工具链，谈谈这么多年来了解与使用了多种工具后的简单思考。怎么理解构建工具链？也许可以想想前端开发中编译、打包、静态资源压缩、静态语法检查、热更新、代码 Lint、测试、类型文件生成……\n任务运行器与打包工具 在 16、17 年刚开始接触前端构建工具时，最先尝试的则是 gulp.js，当时也了解到 grunt.js 但没有真正的使用过，主要是它们是同类东西，具有可替代性；后来，将 gulp.js 与 webpack(v3) 配合起来用，主要原因还是前者只能处理单个文件，后者可以将多个文件合并（bundle）；再后来，迁移到 webpack(v4) 后替代了 gulp.js 这部分的任务，直接将 gulp.js 移出工具链。\ngulp.js(grunt.js) -\u0026gt; gulp.js + webpack(v3) -\u0026gt; webpack(v4)\n以上是针对 Web 应用开发的构建工具的选择变化，即由任务运行器（Task Runner）向打包工具（Bundler）的转变，这些工具的目标是一致的：为 Web 开发建立一个完整的自动化工作流（automate workflow）。那么，为何会发生这样的转变呢？工具是为开发者服务的，Web 前端开发者对于 Web 应用的优化着力点则在于将多个分散的小文件合并为一个大文件，较少 HTTP 请求次数从而提高加载性能以改善用户体验。换句话说，像 gulp.js 这样的任务运行器更大程度上解决的是开发体验问题，可以自动将 JS/CSS 的超集语言（例如 Less/Sass/CoffeeScript）进行编译，对静态资源进行压缩等等；而打包工具在此基础之上，更加契合了前端领域的 Web 应用优化法则，帮开发者包办一切，只需编码即可交付上线。孰好孰坏？孰优孰劣？这不是一个绝对的问题，特定场景下用更适合的工具解决问题即可，但显然，当下 webpack 是可以解决大多数问题的最佳选择。\n当然，同一时代下，打包工具不仅只有 webpack，还有 rollup（后续会提到）、Parcel 诸如此类的工具，所以前面说这个领域是百花齐放，开放与创新并存。每个工具都有自己的特点和优势，这里我重点讲讲我自己实际用过的一些工具。\n后来，开发一些工具库的时候，尝试了 rollup 这个打包工具。先说一个比较有趣的观点：\nWeb App -\u0026gt; webpack JS Lib -\u0026gt; rollup 这个意思就是打包 Web 应用选 webpack，打包工具库用 rollup。无论这个观点合不合理，但这是一个值得我去尝试 rollup 的理由。鉴于历史原因，一般工具库的构建产物需要包含多种格式（UMD/CJS/ESM），一番体验过后，rollup 可以轻松完成这个任务，反观 webpack 就不是很好处理了。另一方面，rollup 的生态中似乎处理 JS 的工具要多一些，反而处理静态资源，尤其是 CSS、HTML 的优秀工具就很匮乏了，而 webpack 的生态足够繁荣，针对 JS/CSS/HTML 都有相关的优秀工具。说到这里，实际上刚开始提到的观点多少还是有点道理的，两个工具的生态解决问题的侧重点不同。\n任务运行器和打包工具的区别是前者处理单个文件，后者处理并合并所有文件，而真正完成编译、压缩、语法检查等等核心任务的则是其它工具（比如 Babel/ESLint/Prettier/TypeScript），通常会以相应的打包工具的插件方式来使用。\n插件 插件机制是一个程序具备可扩展性和灵活性的关键，各种任务运行器和打包工具均依赖于插件增强自身的能力，所以一个工具的社区生态中优秀插件足够多是非常重要的。这里秉承一个理念：一个工具只解决最关键的一个问题，多个工具组合起来就可以解决特定领域的一类问题，而像 webpack 和 rollup 这样的工具就是用来组合各种各样工具的容器。\n以插件的方式解决问题很好，不同的工具解决同样的问题不用重复实现，避免造轮子，减轻了工具维护者的负担，也促进了前端工具生态的繁荣，可以有很多人以不同的方式解决同样的问题（例如 Terser 与 UglifyJS 都可以用来压缩和混淆 JS 代码）。\n有人曾想过从 webpack 迁移到 rollup，但以我自身的体验为例，举个例子可以说明，插件有好处亦有坏处。webpack 的生态非常繁荣，当你尝试迁移到 rollup 时想找到对应的替代品，这个过程可能会让你非常沮丧，ESLint 工具可以帮助我们做代码 Lint，webpack 社区中有一个非常优秀的插件（fork-ts-checker-webpack-plugin(v6)）可以将 ESLint 集成到 webpack 工作流中，但 rollup 中似乎找不到一个满意的插件（@rollup/plugin-eslint 已经很久没有维护，且不支持 ESLint 8.x）。这个时候，你是不是会抛出一个疑问：一个工具（比如 ESLint）作为独立的工具库避免了造轮子，但为了适配 webpack、rollup 等众多的打包工具，都需要一一编写插件并持续维护，反而又造了一批轮子？\n的确，插件是一个解决问题的好方式，但也有其劣势，每当出现一个新的打包工具，那么就需要复制实现一遍现有打包工具的插件。另一方面，我们也可以思考，将所有的工具集成到打包工具中是否有必要？实际上我最近就面临这个问题。\n当我基于 rollup 工具链构建一个用来开发 UI 组件库的工作流时，庞大的第三方依赖让 rollup 在开发模式（watch）下增量编译非常缓慢（4s 以上），经过调试发现是 @rollup/plugin-node-resolve 插件耗费了大量的时间，这也是 rollup 与 webpakc 对待第三方模块实现有所不同的显著差异，基本上无解；另一方面，为了做 TypeScript 的类型检查，这又进一步减缓了增量编译的速度。为了解决庞大依赖项对增量编译的速度巨大影响，尝试换用用 Go 编写的 esbuild 打包工具，在这个迁移过程中对于 CSS 的处理则耗费了很多时间（因为 esbuild 主要还是专注于处理 JS 代码），对于 TypeScript 也不做类型检查。那么，当我们为了解决一个收益很高的问题而迁移到另一个打包工具时，一些收益较低的特性面临不被支持的问题（比如 TypeScript 类型检查），实际上我们可以将辅助性的工具与打包工具解耦，用任务运行器来与打包工具的工作流并行运行即可解决，这也是我所采用的方案。\nrollup + Core(plugin) + Util(plugin) -\u0026gt; rollup + Core(plugin) + Util(task)\n借助 concurrently 这个命令行工具，我们可以将一些辅助性的工具与打包工具并行运行，这样就可以实现开发模式下用 esbuild，生产模式下用 rollup，还能具备 TypeScript 类型检查的能力：\n# development concurrently --kill-others \u0026#34;node esbuild-watch.cjs\u0026#34; \u0026#34;tsc --noEmit --watch\u0026#34; # production concurrently --kill-others \u0026#34;rollup --config\u0026#34; \u0026#34;tsc --noEmit --watch\u0026#34; 实际上，开发模式使用 esbuild，生产模式使用 rollup 正是打包工具 vite 的底层架构设计。当然，这种方案有其性能劣势，本应该开启一个文件系统的 watch 服务即可，但这里可能会利用诸如 chokidar 这样的 npm 包开启多个 watch 服务，也许操作系统底层对该场景做了优化，但没有深究也就不得而知了。\n所以说，当我们使用打包工具替代任务运行器时，刚开始是方便了，但也加强你对该工具的依赖性，后续很难迁移到其它工具链。没有最好的工具，只有更优的方案，满足自己的需求即可。\n当然，对于利用插件来组合各种工具解决各类问题的方案，显然有部分人觉得是不满意的，每种工具都有特定的配置项，组合的工具越多，配置起来就越复杂。Rome 试图用一套工具来解决目前前端构建工具领域典型的几个环节的问题，替代 Babel/ESLint/webpack/Prettier/Jest 等等，值得关注。\n用高性能语言解决性能问题 当前端的项目日益复杂，庞大的代码库使用 JS 编写的构建工具处理起来显得有些力不从心，毕竟 JS 是一个脚本语言，有性能上的劣势。这个时候用一些高性能语言编写构建工具来解决前端工具链中存在的性能问题成为了一个有趣的方案，当前的代表作是 esbuild（用 Go 编写） 和 swc（用 Rust 编写）。为什么说它有趣呢？作为 Web 开发者，应该很少会有人想到利用一些比 JS 较为低级的高性能语言去编写工具，这个有很高的学习成本；另一方面，这些工具也确实以非常强的性能优势很好的解决了前端工具链中的性能问题，值得尝试。\n以第三方语言编写的工具，目前有一个劣势就是能参与到社区生态中贡献的开发者群体将占比很小，对比 esbuild 和 rollup、webpack 这些用 JS 编写的工具的代码库贡献者数量就有一个非常直观的感受。其次，这些工具利用性能优势解决了核心性能问题，其它问题还依赖于前端社区中现有的工具来完成，而不是重复造轮子（实际上也不现实），而 esbuild 的插件机制实际上还处于实验阶段，而正如官方文档中所说的，用 JS 编写的插件将不具备 Go 的性能优势，esbuild 的方案就是暴露一些耗费性能的程序 API（用 Go 实现）供 JS 代码调用，以达到一个折衷的效果，既支持引入前端生态的现有工具，也不太会降低性能。\n如何定义工具 另一方面，前端工程化所做的一切应该是致力于提高开发者体验、让流程标准化、自动化，从而提高开发效率和保证质量。那么，在这个过程中，所引入的一些工具链不应该成为开发者的“绊脚石”，应该结合团队实际情况选择合适的工具和方案，当团队成员都在迎合工具时，实际上已经违背了前端工程化的初衷了。\n这里其实可以以前端一个比较有争论的工具来举例，即 TypeScript。首先，TypeScript 在前端领域的应用是越来越广泛了，这是一个趋势，说明其在前端生态中有一定的重要性和作用。一般来说，有一部分人认为应该用 TypeScript，可以提高代码质量，而另一部分人则认为不应该用 TypeScript，因为会降低编码效率。当把 TypeScript 引入编译工具链时，一般来说有两种选择，一种是类 Babel 方案（不做类型检查），而另一种就是官方 tsc 方案，出于简单性后者会更方便一些，但后者会做类型检查更加严格，这就意味着开发过程中你要解决所有的错误才能让代码编译通过（这在一些场景下实际上是开发者的噩梦，至少我是这样觉得的并有所体会）。简单来说，引入 TypeScript 的目的是提高代码质量，但以什么样的方式和程度去实践这个事情其实是有争议的。对于体验过早期前端开发的人来说，我觉得 TypeScript 主要是解决了两个问题，第一个就是类型定义所带来的代码智能提示功能（以前是需要边写边查文档的），第二个就是类型检查可以帮助我们提前发现问题并修复（但这里并不代表开发者需要迎合严格的类型检查，应该更多的是作为一种参考信息）。由于前端开发（尤其是业务开发）有其复杂性，不适合生搬硬套类 Java 这种严格的静态类型语言标准，将 TypeScript 作为工具引入，而不是为了迎合 TypeScript 的标准花费精力解决额外的事情（或者说历史遗留问题）。对于 TypeScript 来说，更大的一个作用就是可以用来生成类型定义文件（.d.ts），官方提供的命令行工具（tsc --emitDeclarationOnly）会在发生类型检查错误时报错中断，这就使其很难集成在 CI 中（例如 npm 包发布前自动生成类型定义文件），期望官方能提供一个忽略类型检查错误的命令行标志位，但奈何没有（在查找资料的过程中发现有很多开发者有类似的需求），无奈之下只能以 JS 脚本的方式去运行该命令同时忽略掉类型检查错误以集成在 CI 中。\n所以说，前端生态中，很多优秀的工具官方推荐或者默认是选择不做类型检查的编译方案的（类 Babel），我想这也是有原因的，且是被大多数人所认同的。工程化实施的过程中，引入任何工具链的最终效果应该是“帮助”开发者，而不是带来“绊脚石”的副作用，完美的类型检查是我们所追求的，但投入产出比是需要重点考虑的。\n结语 随着 wasm、ES Module、HTTP2/HTTP3 等的推广与普及，前端工程化领域还在不断演进，Bundle 与 Bundle less 将如何发展值得期待。\n参考资源 https://gulpjs.com/ https://gruntjs.com/ https://webpack.js.org/ https://rollupjs.org/ https://esbuild.github.io/ https://swc.rs/ https://parceljs.org/ https://babeljs.io/ https://vitejs.dev/ https://rome.tools/ "},{"section":"Blog","slug":"/blog/computer-technology/program-architecture-design/bridge-mode-design-of-cross-platform-event-mechanism/","title":"桥接模式：跨平台的事件机制设计","description":"最近在做图表组件库的技术调研的架构方案设计，参考了很多开源库的源码，发现其中跨平台的事件机制设计很值得学习，如果要用软件设计模式来解释，那大概就是桥接模式了。","date":"June 12, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 服务器, Nginx","tags":"计算机技术, 服务器, Nginx","content":"对于 Web 的图表组件库来说，一些功能比较强大的开源库，渲染层可以支持 DOM、SVG、Canvas、WebGL 等多个平台的环境，而图表库的很多功能的实现都和渲染层紧密相关。\n最近，在参考学习一些开源的图表组件库时，发现在跨平台设计中，事件机制的实现很有意思，所以在这里以最简化的代码来解释和记录一下这个方案。如果要用经典的软件设计模式来解释，大概就是桥接模式了。\n桥接模式（Bridge Pattern） 将一个功能的实现拆分为抽象（Abstraction）和实现（Implementor），让其相互独立的扩展和定义，借助该模式可以设计一种平台无关的软件架构。\n事件机制 事件机制是软件设计中最基础、最为常见的一种设计，对于 Web 图表组件库来说要提供一些处理用户交互（例如点击、拖动、右键点击等）的机制。一个典型的事件模型类如下：\nclass EventEmitter { _handlerMap = {}; on(event, callback) {} off(event, callback) {} emit(event, ...args) {} } 对于用户来说，对外暴露 on() 和 off() 方法来注册和取消事件，而图表库内部需要完成事件触发（emit()）的实现，而这里与渲染层耦合。以渲染层为 DOM 实现来举例，支持点击事件：\nclass Chart { constructor() { // 渲染层为 DOM 实现 this.__renderer = new DOMRenderer(); this._handler = new EventEmitter(); } on(...args) { this._handler.on(...args); } off(...args) { this._handler.off(...args); } __bindEvent() { // ! 事件触发（绑定）与渲染层耦合 this.__renderer.domElem.addEventListener(\u0026#39;click\u0026#39;, (event) =\u0026gt; { this._handler.emit(\u0026#39;click\u0026#39;, ...[event, ...otherArgs]); }); } } 跨平台实现 参考桥接模式，这里可以把图表类中的事件机制实现拆分为抽象（Handler）和实现（HandlerProxy），前者管理用户注册的事件池，后者负责特定平台的事件触发实现。示例代码如下：\nclass Handler extends EventEmitter { constructor(handlerProxy) { super(); this.__handlerProxy = handlerProxy; // 注册事件到代理类中 this.__handlerProxy.on(\u0026#39;click\u0026#39;, (event, ...args) =\u0026gt; { // ! 触发用户注册的事件 this.emit(event, ...args); }); } } class DOMHandlerProxy extends EventEmitter { constructor(renderer) { super(); this.__renderer = renderer; } __bindEvent() { // 根据渲染层的平台实现事件绑定，以 DOM 实现为例 this.renderer.domElem.on(\u0026#39;click\u0026#39;, (event, ...args) =\u0026gt; { // ! 触发 Handler 注册的事件 this.emit(event, ...args); }); } } 对于图表类来说，Handler 类提供了完整的事件机制，但其内部把具体平台相关的事件触发实现交给 HandlerProxy 类去实现。这样就完成了事件机制的实现与特定平台实现分离的目标，针对不同平台实现不同的HandlerProxy 类即可。现在图表类的代码应该如下：\nclass Chart { constructor() { // 渲染层为 DOM 实现 this.__renderer = new DOMRenderer(); this._handler = new Handler(new DOMHandlerProxy(this.__renderer)); } on(...args) { this._handler.on(...args); } off(...args) { this._handler.off(...args); } } 现在来看，图表类中之前事件触发实现与平台相关的代码已经被独立出去，且可以根据不同的渲染层实现完成无缝衔接。\n结语 以上就是利用桥接模式对跨平台的事件机制的简化设计，解决此类问题时，最重要的是划分抽象和实现两部分。\n参考 https://en.wikipedia.org/wiki/Bridge_pattern https://refactoringguru.cn/design-patterns/bridge "},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-maintain-open-source-projects-with-tools/","title":"如何更好的维护开源项目","description":"一直以来开源精神被开发者所推崇，维护开源项目需要注意什么，有哪些工具可以帮助我们解决通用的复杂问题，值得学习了解。","date":"April 22, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"工具, 开源, 计算机技术, 项目","tags":"","content":"一直以来，开源精神被开发者所推崇，开源项目为开发者提供了不用付出除时间以外任何成本就可以学习前沿技术的最佳途径，另一方面，我们应该思考开源为何会成功，在全球开发者参与协作的情况下代码仓库为何能保持整洁、不出现大规模冲突而奔溃，上下游依赖如何管理，这背后有既定的规范进行强约束，也有一系列社区工具来完成复杂而有价值的工作。所以，从参与或者维护开源项目的角度来看，这些社区公认的最佳实践值得我们了解，学习这些东西也能在一定程度上提高我们管理项目的能力。\n以下内容属于经验积累，持续更新，仅供参考。\n许可证（License） 代码本质上是开发者的创作成果，具有专利权，所以开发者应该意识到自己所享有的权利，同时在使用其他人所提供的代码时避免侵权。作为开源项目，有必要在开源之前选择一个合适的许可证，提前声明权利和义务（一般作为单独的 LICENSE 文本文件保存），避免在后期陷入麻烦之中，GitHub 官方为我们提供了一个简单的工具站点：\nChoose an open source license\n另外，在如今很多人喜欢自由创作并分享的氛围下，创作者应该了解一个比较有用的许可证类型：\nCreative Commons licenses\n贡献者许可协议（CLA） 对于一些大型开源项目，尤其是有商业公司背景的项目，个人开发者想参与贡献首先面临的是要签署相应的贡献者许可协议（Contributor License Agreement, CLA），该协议本质上是要求开发者授予他们所贡献代码段的永久专利权，目前来看这是商业公司规避法律风险的一种通用做法。\n作为示例，以下是 Facebook(Meta) 公司的贡献者许可协议：\nContributing to Meta Open Source Projects\n文档 我们知道，在全球开发者参与协作的背景下，口头沟通是不现实的（即便有条件，长期来看我认为依赖口头沟通是一件非常低效的事情），所以文档也就成了最关键的东西，无论对于使用开源项目的开发者还是维护开源项目的开发者，文档都成了达成共识的关键，各种类型的文档也成为了默认的规范。\nMarkdown 首先，文档的载体是比较重要的，因为其必须满足易于使用、富有表现力的特点。Markdown 已是开发者群体使用最为广泛的文档格式了，目前许多创作者也用该格式来写博客文章，其最终可以被转换为 HTML 文件从而以更好的视觉效果发布在网络。\nMarkdown 格式没有统一的规范，由于平台差异和实现差异，在一些细节处有略微不同或者增强，但通过了解 CommonMark Spec 来学习使用 Markdown 应该是一个好的开始：\nhttps://commonmark.org/\n这里有一个专门学习 Markdown 的网站，可以了解一些 Markdown 的扩展语法和相关的工具：\nMarkdown Guide\n除此之外，为了使用 Markdown 编写文档更方便，有一种将 JSX 和 Markdown 相结合的增强格式：\nMDX\n自述文档 优秀的开源项目不仅仅只提供源代码，更附带了一系列非常有价值的文档，其中最基本且不可或缺的应该是自述文档（READMEs） 了（通常命名为 README.md），项目维护者应该通过这个文档向人们传递一些项目的基本信息，例如项目名称、作者的动机、建立项目的原因、解决了什么问题、简单的使用方法、注意事项、问题反馈途径、许可证、其它相关文档的引用链接等。\n关于该文档的一些详细信息，可以看看 GitHub 官方对其的描述：\nAbout READMEs\n也许，这里有一个更好的站点可以学习了解：\nMake a README\n当然，对于一些刚开始的简单项目，可以借助一些社区提供的工具来自动生成自述文档，例如：\nreadme-md-generator\n架构概述文档 对于一个大型复杂的项目来说，开发者参与贡献有一定的困难，这个困难体现在开发者无法了解庞大项目背后的整体架构设计理念和原则，难以评估局部代码改动对整体项目的影响，所以项目中如果拥有一个架构概述文档（Architecture Overview） 那么这种状况就会得到改善。\n最简单的方式就是在项目中提供一个 ARCHITECTURE.md，通过下面这篇文章也可以进一步了解：\nARCHITECTURE.md\n作为示例，这是 Google 的一个项目的架构概述文档：\ncrosvm Architecture\n事实上，架构概述文档不止是解决了贡献者参与困难的问题，也是一种非常有价值的学习资料，作为一种行业的通用方案，向社区公开其背后的架构设计理念，可以促进技术改进和变革。这里，以 React Native 的文档为例：\nReact Native Architecture Overview\n行为准则声明 开源社区之所以发展到如今的规模，是因为参与其中的人们遵守共同的价值观、具备契约精神，所以声明你的态度以及表明你的价值观会消除人们的不信任感，鼓励人们积极参与进来。\n开源社区的行为准则（A Code of Conduct for Open Source Communities） 声明通常以 CODE_OF_CONDUCT.md 文档的形式存在于项目中，通过以下站点了解更多信息：\nContributor Covenant\n贡献指南文档 开源项目参与协作的开发者来自全球各个国家，他们有不同的习惯和文化，如何保证项目代码的整洁、风格统一、项目的管理不会由此崩溃，需要指导贡献者按照既定的规则完成整个过程的工作，社区通用的做法是在项目中提供一份贡献指南（Contributing guidelines） 文档，一般被命名为 CONTRIBUTING.md。\n具体内容参考以下 Mozilla Science Lab 的文档：\nHow to Build a CONTRIBUTING.md\n作为示例，Atom 项目的贡献指南非常具有参考意义：\nContributing to Atom\nRFC 文档 RFC (Request for Comments) 文档在互联网世界是一个重要的存在，早期是网络技术标准工作组用来在互联网上针对即将推出的技术标准征求意见进行记录的，最著名的组织是 Internet Engineering Task Force (IETF)。\n事实上，这种模式已在各行各业被采纳，作为开源项目来说，项目的主导方一般在大版本更新中预期引入的重大变化或者新的功能等也会采用 RFC 文档的形式向所有的贡献者和使用者等群体征求意见并记录，这也是项目维护团队针对项目进一步的发展方向达成共识的关键所在。\n作为示例，以下是 React.js 官方的 RFC 文档仓库：\nhttps://github.com/reactjs/rfcs\n国际化与本地化 开源社区是全球开发者都可以参与其中的，所以文档方面应当考虑到国际化与本地化（i18n \u0026amp; L10n）的有限支持，这里为什么说有限支持呢？因为文档的翻译事实上是比较耗费时间成本的一件事情，而且要有高质量的文档翻译则需要了解相应国家文化的人来完成这项工作，所以折衷方案是视项目情况而定，一般来说至少提供一份用国际通用语言英语编写的文档，再提供一份用项目核心开发者群体所在国家的主流语言编写的文档。\n文档的命名应该相同，不同的是本地化的文档用相应的语言标签（参考微软文档）进行标识，例如：\nREADME.md README.zh-CN.md 源代码管理 源代码管理通常借助 SVN 和 Git 等类似版本控制软件进行，现今主流的方案多是采用 Git，所以下面的内容可能更多的倾向于 Git 相关。\nGit 工作流 Git 非常适合多人协作的项目源代码管理，而协作的模式要视具体项目情况而定，一般来说社区推荐的有以下几种 Git 工作流（Workflow），可以进行学习了解，根据情况采用或改进：\nGit Flow - A successful Git branching model GitLab Flow GitHub Flow 提交信息格式 Git 的提交日志信息可能是除通过看源代码以外最快速最直观的了解某次提交做了哪些变动、对项目产生了哪些影响的最佳途径，所以项目拥有一个达成共识的提交信息格式（Commit Message Format） 的约束规则是保证项目质量的一大举措。\n社区有一个推荐的提交信息格式的规范：\nConventional Commits\n作为示例，Google 的 Angular 项目的提交信息格式规范非常具有参考意义：\nAngular Commit Message Format\n代码审查 开源项目的代码贡献是受严格控制的，一般来说参与者分为维护者（Maintainer）和贡献者（Contributor），贡献者对项目代码所做的更改需要提交 PR（Pull Request，GitLab 为 Merge Request）经过维护者的代码审查（Code Review） 后才能成功合并到项目中。\n对于代码审查的意义，不仅在于控制项目的代码质量，还有益于项目成员之间进行相互学习。社区有非常多的代码审查指南可以进行参考，这里推荐谷歌的工程实践进行学习：\nGoogle Engineering Practices Documentation\n软件发布的生命周期 无论是使用软件还是维护软件项目的开发者，都应该了解软件发布的生命周期，尽管现今的 Web 应用弱化了软件版本的概念。遵循行业惯例的好处是可以大大降低人们的理解成本，也能更好的融入社区，以下是关于软件发布的生命周期的详细信息，可以作为很好的参考进行学习：\nSoftware release life cycle\n语义化版本控制 互联网软件会随着时间变化不断的迭代更新以提供新的功能和更好的用户体验，前面所说的软件发布的生命周期是一个概念性的东西，真正运用在软件发布过程中的则是一种推荐性规范语义化版本控制（Semantic Versioning）：\nhttps://semver.org/\n为了便于管理软件发布和版本控制，不同语言的生态中都有基于该规范所开发的一些自动化发布管理工具，借助这些工具则可以在遵守规范的同时省心省力，也不会因为手动管理导致出错。\n变更日志 随着软件版本的迭代发布，应该维护一个变更日志（Changelog），因为软件的版本号变动可传递的信息是有限的，尤其是对于大版本更新、重要问题修复以及破坏性更新等需要更多更详细的信息，这样便于依赖方、使用方对于是否同步更新版本进行决策，也对旧版本用户迁移到新版本有一个比较明确的向导信息。\n开源项目的代码仓库中，比较常见的变更日志文件通常为 CHANGELOG.md，这也是一个社区公认的最佳实践，更多信息可以从以下站点进行了解：\nkeep a changelog\nDevOps 开源项目不同于商业公司的内部项目，缺少非常多的资源来保证项目的质量和管理，例如自动化测试、自动发布、自动漏洞监测修复等等，或者我们可以称之为 DevOps 工具链。不过，好在现今有非常多的工具免费提供给开源项目使用，借助这些工具，我们可以让开源项目和商业公司的项目一样拥有规范的开发、测试、交付流程，从而保证项目质量，也能节省更多的时间专注于编码，而不是花费更多时间去做管理项目这种有价值但复杂又通用的事情。\n下面推荐一些可以加入 CI/CD 工具链中的工具帮助开发者自动化完成开源项目的诸多管理工作。\nCI/CD 平台 CircleCI GitHub Actions 代码审查与质量评估 Codecov Codacy CodeFactor 依赖更新 Renovate 漏洞监测和修复 Snyk 版本控制和发布 semantic-release API 文档管理 hoppscotch 其它 财务管理 很多时候，开源是免费且无偿的，但开源的本质是源代码自由而不是技术免费，开源社区发展到至今繁荣的程度与参与者遵守共同的价值观有很大的关系，开源社区为改变世界的技术变革付出了很多。另一方面，正是在这种强包容性和开放性的社区环境氛围中，开源事业才发展的越来越好，现今有很多人可以因为自己的开源项目给别人带来商业价值而获得财务收益，对于更懂代码的开发者来说，如何进行项目的财务收益管理和分配成了个一个棘手的问题，而社区也给出了相应的方案来帮助项目维护者改善这个局面。\nOpen Source Collective GitHub Sponsors 参考资料 The Turing Way Open Source Guides "},{"section":"Blog","slug":"/blog/business/business-noun/","title":"一些互联网名词","description":"互联网时代创造了诸多名词，而这些与商业活动紧密相关，了解一下还是挺有趣的。","date":"March 27, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"商业, 互联网名词","tags":"商业, 互联网名词","content":"互联网时代是个新概念频出的时代，每年有相当多的新名词诞生，而诸多与商业活动紧密相关的词汇了解一下有助于我们熟悉日常工作中接触的东西。\n互联网名词 商业模式 B2B（Business to Business） 传统的电子商务商业模式，供需双方都是商家（或企业、公司）。代表性企业如阿里巴巴、聪慧网等。\nB2C（Business to Consumer） 一种直接面向消费者销售产品和服务的商业零售模式。代表性企业如京东商城、当当网、亚马逊网等。\nC2C（Consumer to Consumer） 个人与个人之间的电子商务。代表性平台如淘宝网、京东商城、闲鱼、拍拍网等。\nB2B2C（Business to Business to Consumer） 第一个 B 是指商品或服务的供应商，第二个 B 是指商家，C 是指消费者。它是一种通过构建自己的物流供应链系统来提供统一的服务的商业模式，其核心思想是把“供应商 → 生产商 → 经销商 → 消费者”中的各个产业链紧密连接在一起，提升核心竞争力。代表性企业如京东、淘宝天猫等。\nO2O（Online To Offline） 是指将线下的商务机会与互联网结合，线上营销线上购买带动线下经营和线下消费的一种商业模式，例如线上团购，到店消费。代表性平台如携程、猫眼电影、美团等。\nC2B（Customer to Business） 一种新型的电子商务模式，是指先有消费者提出需求，然后生产企业按需求组织生产的商业模式，例如团购、商品预售。\nB2F（Business To Family） 企业以家庭为单位对其消费进行营销和引导的商业模式。代表性平台如京东到家、58 到家等。\nB2M（Business to Marketing） 指面向市场营销的电子商务企业，电子商务公司根据客户需求为核心而建立起的营销型站点，并通过线上和线下多种渠道对站点进行广泛的推广和规范化的导购管理，从而使得站点作为企业的重要营销渠道。\nM2C（Manufacturers to Consumer） 是指生产厂家直接对消费者提供自己生产的产品或服务的一种商业模式，特点是流通环节减少至一对一，销售成本降低，从而保障了产品品质和售后服务质量。\nC2M（Customer to Manufacturer） 新型的工业互联网电子商务模式，是指一种按照客户的产品订单要求，设定供应商和生产工序，最终生产出个性化产品的商业模式，又被称为“短路经济”。\nP2C（Production to Consumer） 是指整合日常生活中的服务资源，如房产、餐饮、交友、家政服务、票务等，实现服务业的电商化的商业模式，例如许多生活服务平台就是采用这种模式。代表性平台如 58 同城。\n云服务模式 IaaS（Infrastructure-as-a-Service） 基础设施即服务，云服务商将一些 IT 基础设施作为服务通过网络对外提供，主要是一些底层相关的硬件资源，比如服务器、数据中心、存储等。\nPaaS（Platform-as-a-Service） 平台即服务，云服务商把服务器平台作为一种服务通过网络对外提供，在 IaaS 的基础之上，再包含预配置的操作系统环境、软件开发平台、软件部署环境等进行交付。\nSaaS（Software-as-a-Service） 软件即服务，云服务商将特定的软件作为一种服务通过网络对外提供，在 PaaS 的基础之上，再包含特定的软件应用进行交付。\n媒体内容 媒体类型相关。\n门户网站（Portal Web），综合信息服务提供。 垂直门户（Vertical Portal），细分领域信息服务提供。 新媒体（New Media），基于数字互联网的新形态媒体。 自媒体（We Media），由个体提供信息服务的一种新媒体形式。 社交媒体（Social Media），基于社会公共关系的一种新媒体形式。 媒介工具相关。\nSNS（Social Network Sites），社交网站。 IM（Instant Messaging），即时通讯。 TMT（Technology，Media，Telecom），科技、媒体、通信融合，数字新媒体产业。 内容生产相关。\nUGC（User-generated Content），用户生产内容 PGC（Professionally-generated Content），专业生产内容 OGC（Occupationally-generated Content），职业生产内容 KOL（Key Opinion Leader），关键意见领袖 内容运营相关。\nMCN（Multi-Channel Network），网红孵化 IP（Intellectual Property），知识产权 CP（Content Provider），内容提供商 ACG（Animation、Comic、Game），二次元文化 运营 用户流量统计相关。\nIP（Internet Protocols），独立 IP。 PV（Page View），页面浏览量。 UV（Unique Visitors），独立访客。 衡量用户活跃度相关。\nPCU（Peak Concurrent Users），最高同时在线用户人数。 ACU（Average Concurrent Users），平均同时在线用户人数。 DAU（Daily Active User），日活跃用户量。 MAU（Month Active User），月活跃用户量。 衡量用户粘性相关。\nRV（Repeat Visitors），重复访客。 TP（Time On Page），页面停留时长。 流量渠道统计相关。\nTS（Traffic Sources），流量来源。 衡量运营效率相关。\nROI（Return On Investment），投资回报率。 GMV（Gross Merchandise Volume），商品交易总额（一定时间段内）。 ARPU（Average Revenue Per User），每用户平均收入。 ARPPU（Average Revenue per Paying User），每付费用户平均收益。 PUR（Pay User Rate），付费用户率。 LTV（Lift Time Value），客户终生价值。 SPU（Standard Product Unit），标准产品单位。 SKU（Stock Keeping Unit），库存量单位。 RR（Retention Rate），留存率，一段时间内，再次使用应用的用户比例。 CR（Conversion Rate），转化率，是指访问某一网站访客中，转化的访客占全部访客的比例。 运营方式相关。\nAARRR 模型 获取用户（Acquisition） 提高活跃度（Activation） 提高留存率（Retention） 获取收入（Revenue） 自传播（Refer） 营销广告 SEO（Search Engine Optimization），搜索引擎优化。 产品 UI（User Interface），用户界面。 UE（User Experience），用户体验。 产品设计相关。\nBRD（Business Requirement Document），商业需求文档。 MRD（Market Requirement Document），市场需求文档。 PRD（Product Requirement Document），产品需求文档。 FSD（Functional Specifications Document），功能设计文档。 流程图（Flow Chart），核心业务流程图形。 原型图（Prototype），产品框架设计。 产品发布相关。\nAB 测试 灰度发布 其它。\nFAQ（Frequently Asked Questions），常见问题解答。 MVP（Minimum Viable Product），最简化可实行产品。 PLC（Product Life Cycle），产品生命周期。 职业 产品岗 PM（Product Manager），产品经理 MRD（Market Requirements Document），市场需求文档，侧重产品立项时的前期调研分析。 PRD（Product Requirement Document），产品需求文档，侧重产品具体功能设计。 设计岗 UI Design（User Interface Design），用户界面设计 UX Design（User Experience Design），用户体验设计 IxD（Interaction Design），交互设计 ID（Industrial Design），工业设计 研发岗 RD（Research \u0026amp; Design Engineer），研发工程师 FE（Front End），前端研发工程师 测试岗 QA（Quality Assurance），质量保证工程师，即测试工程师 运维岗 SA（System Admin），侧重于基础设施建设 OP（Operator），侧重于各个业务线的服务部署、运行、维护 参考 http://www.woshipm.com/zhichang/1743064.html https://wenku.baidu.com/view/4ebe697dce7931b765ce0508763231126fdb7762.html https://wenku.baidu.com/view/6df81e405727a5e9846a6136.html https://www.sohu.com/a/409413815_116126 "},{"section":"Blog","slug":"/blog/computer-technology/typescript/tools-typescript-type-extend/","title":"TypeScript：扩展第三方库的类型定义","description":"TypeScript 作为 JavaScript 的超集，为 Web 开发带来了强类型语言和类似代码智能提示这种良好的开发体验，如何对第三方依赖库的类型定义进行扩展呢？","date":"January 9, 2022","image":null,"imageSM":null,"searchKeyword":"","categories":"","tags":"计算机技术, 工具, TypeScript, 类型定义","content":"TypeScript 作为 JavaScript 的超集，为 Web 开发带来了强类型语言和类似代码智能提示这种良好的开发体验，而代码提示依赖于类型定义文件。类型定义文件的发展也经历了一个逐步演变的过程，从最初基于 JavaScript 编写的 npm 包，通过社区方案来引入类型定义包，再到目前多数模块基于 TypeScript 编写并在发布时带上类型定义文件这种最佳方案，开发者体验得到进一步的提升。\n不过，在使用类型定义文件的过程中我们通常需要和类型定义进行交互，大多数场景可以通过泛型来解决；而有一个典型场景就是需要我们扩展第三方库的类型定义，避免在多个文件中编码时都要引入类型定义的麻烦。可能不是很好理解，在这里通过一个实际的例子就可以解释清楚。\n使用 koa2 框架进行 Node 应用开发时，为了利用 TypeScript 带来的优势，需要引入类型定义，而该框架本身是用 JavaScript 编写的，不过可以通过安装社区提供的 @types/koa 包来获得支持。koa2 框架可以通过扩展 context 对象来引入一些工具，最典型的就是日志管理，这里使用 koa-log4，在 context 上挂载一个 logger 属性引用日志打印器实例，可以通过泛型的方式扩展应用实例上下文对象的定义，但在多个文件中就显的比较麻烦了，开发体验最好且最自然的方式就是直接一次扩展 koa2 的 context 类型定义，后续在多个文件中不用使用泛型即可自动获得代码提示。\n这里直接给出最终代码：\n// src/@types/index.d.ts import log4js from \u0026#39;koa-log4\u0026#39;; declare module \u0026#39;koa\u0026#39; { interface DefaultContext { logger: log4js.Logger; } } 起初，我认为 TypeScript 官方会对这种典型的场景给出明确的方案文档，但找了很久没找到，就去 Google，在 StackOverflow 上发现有人提及类似以上的方案，经过实验确实解决了问题。但是，我一般会找到明确的官方文档记录一下，以备后续参考，也是秉行尽量不 Hack 以官方且优雅的方式解决问题的原则，经过非常仔细的查找之后，确实在官方文档中找到了，但非常分散。\n至此，就比较完美的解决了这个问题。而这个问题也是很久之前就解决的，回过头来发现记录下来会更好一些。\n参考资源 https://www.typescriptlang.org/docs/handbook/declaration-merging.html#module-augmentation https://www.typescriptlang.org/docs/handbook/declaration-files/templates/module-d-ts.html#testing-your-types https://www.typescriptlang.org/docs/handbook/declaration-files/templates/module-plugin-d-ts.html "},{"section":"Blog","slug":"/blog/computer-technology/web/tools-web-fee-polyfill-corejs-eslint/","title":"解析基于 core-js 与 ESLint 的 Web 兼容方案","description":"Web 网页为了保证在多个平台和低中高端设备上的体验稳定性和一致性，通常会做 Polyfill 以保证兼容性，当下社区的主流方案则是基于 core-js，而 ESLint 则可作为自动检测的辅助工具。","date":"December 7, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 工具, Polyfill","tags":"计算机技术, Web前端, 工具, Polyfill","content":"Web 网页为了保证在多个平台和低中高端设备上的体验稳定性和一致性，通常会做 Polyfill 以保证兼容性。\n然而，兼容性问题本身是个难题，Polyfill 也并非很好处理，所以在技术演变的过程中，社区达成了一致，有一个主流的方案，大家共同来使用和维护。当下社区的主流方案则是基于 core-js，另一方面， 利用 ESLint 插件则可以做到自动检测代码中需要添加 Polyfill 的 API。\ncore-js 只是解决了 JavaScript 的兼容性问题，Web 网页还有 CSS / HTML / Web API 的兼容性问题，处理这些问题的过程中，必然会存在大量相似的逻辑，比如目标设备的检测、目标设备的 API 支持情况统计。当然，社区也给出了非常好的方案，下面就来了解一下。\n基于 core-js 的兼容方案 首先，来看看这两者如何进行配合以非常优雅的方式完成 Polyfill 任务的。\ncore-js 是实现了遵循 ECMAScript 标准的模块化标准库，也就是说，主要是实现 JavaScript 的 API，这并不包括浏览器平台的 Web API（例如一些 DOM API、fetch 等）。用起来也很简单，直接在项目中引入即可：\n// polyfill all `core-js` features: import \u0026#39;core-js\u0026#39;; // polyfill only stable `core-js` features - ES and web standards: import \u0026#39;core-js/stable\u0026#39;; // polyfill only stable ES features: import \u0026#39;core-js/es\u0026#39;; 上面是将所有 API 的 polyfills 引入项目，为了构建包尺寸更小，可以选择性的对特定 API 做兼容：\nimport \u0026#39;core-js/modules/es.array.unscopables.flat\u0026#39;; import \u0026#39;core-js/modules/es.array.unscopables.flat-map\u0026#39;; import \u0026#39;core-js/modules/es.object.from-entries\u0026#39;; import \u0026#39;core-js/modules/web.immediate\u0026#39;; 这些方式引入的 polyfill 会污染全局作用域，开发 Web 应用项目时也许不存在太大问题，但若是开发第三方工具库，为了避免这个问题，官方提供了 core-js-pure 包：\nimport Set from \u0026#39;core-js-pure/features/set\u0026#39;; 虽然说 core-js 只是针对 JavaScript API 的兼容方案，但为了方便，也提供了一些非常常用的 Web API 的 polyfills，例如 setTimeout、URLSearchParams 等。\nAPI 兼容性 怎么为 API 做兼容的问题解决掉之后，需要考虑的一个问题是怎么判断 API 的兼容性，首先在 MDN Web Docs 特定 API 文档页面最下方会有一个兼容性统计表格，这个是比较准确和全面的。当然，如果要最准确的结果，可以去特定浏览器厂商的标准状态页面查询，例如 Chrome Platform Status 等。\n除此之外，为了让社区各种工具链自动化去检测 API 兼容情况，有非常著名的 Can I use 站点。该站点方便开发者查询各种 JavaScript / CSS / HTML / Web API 的设备兼容情况，同时维护了一个数据库，供社区其它工具开发者使用。\n兼容目标 有了检测 API 兼容情况和添加 polyfill 的工具后，还有一个很关键的问题：为了加载性能的优化，如果我们不引入全量的 polyfills，怎么针对特定平台去拣选相应的 polyfills？API 兼容检测工具的目标平台是什么？特定 API 是否需要添加 polyfills？\n当然，为了保证社区各种工具链的通用性，也有一个很著名的项目 Browserslist，它可以帮助我们配置代码兼容的目标平台，相应的工具链将会以该目标处理我们所写的代码。\nESLint 有了以上工具后，我们需要一个解析代码并运行这些工具的工具，ESLint 恰好适合这个角色。eslint-plugin-compat 插件可以根据 browserslist 的配置去查询所写代码中需要兼容的 API 并提示出来：\neslint-plugin-compat（解析代码）-\u0026gt; 用解析的代码和 browserslist 配置根据标准查询（MDN/Can I use 等）代码中的兼容情况 -\u0026gt; 开发者手动引入 polyfills\n我们可以注意到，该插件仅仅是帮我们检测出来代码中需要引入 polyfills 的 API，最终还是需要开发者手动引入 polyfills，这是比较麻烦的。当然，ESLint 干了自己该干的，剩下的事情交给 Babel 即可。\nBabel 说到 Polyfill，还得再提一下社区主流的 JavaScript 编译方案 Babel，为什么呢？因为一开始，Babel 团队同时非常贴心的提供了 Polyfill 方案 @babel/polyfill。\n@babel/polyfill 如果看过源码，或者看过目前的文档，其实 @babel/polyfill 做的事情等价于：\n// see docs: https://babeljs.io/docs/en/babel-polyfill/ import \u0026#39;core-js/stable\u0026#39;; import \u0026#39;regenerator-runtime/runtime\u0026#39;; 当然，现在（Babel 7.4.0+）这个方案已经被官方弃用了，这又是为什么呢？其实看上面的代码也能猜出个大概，这种方案不够灵活，把需要和不需要的 polyfills 全部添加到项目代码中，不利于加载性能优化；其次，对于开发者来说是个黑盒子，开发者不清楚干了哪些事，干到了什么程度，不受开发者控制。文档中也有所提及：\nNote: Depending on what ES2015 methods you actually use, you may not need to use @babel/polyfill or the runtime plugin. You may want to only load the specific polyfills you are using (like Object.assign) or just document that the environment the library is being loaded in should include certain polyfills.\n其实意思很简单，就是把 polyfill 的控制权交给了开发者。与此同时，Babel 又给出了另一个方案 @babel/preset-env。\n@babel/preset-env 该方案主要解决了 @babel/polyfill 方案不够灵活的问题，提供了两种选择：即 useBuiltIns 配置项的 usage 和 entry。\nentry 模式 This option enables a new plugin that replaces the import \u0026quot;core-js/stable\u0026quot;; and import \u0026quot;regenerator-runtime/runtime\u0026quot; statements (or require(\u0026quot;core-js\u0026quot;) and require(\u0026quot;regenerator-runtime/runtime\u0026quot;)) with individual requires to different core-js entry points based on environment.\n该模式需要开发者在入口文件显式引入 core-js，然后 Babel 会根据配置的兼容目标环境精细化拣选需要的 polyfills 引入，达到减小最终构建包体积的目的。这里是以所有的 polyfills 和兼容目标环境为基础进行过滤，过滤掉目标环境已支持 API 的 polyfills，也就是说最终还是会引入项目代码没有用到的 API 的 polyfills。\nusage 模式 Adds specific imports for polyfills when they are used in each file. We take advantage of the fact that a bundler will load the same polyfill only once.\n而这种模式就解决了上面的问题，在以上模式过滤掉的结果中，再以项目代码为基础，过滤掉没有用到的 API 的 polyfills，这样最终的构建包体积会进一步减小。\n结语 至此，我们了解到基于 core-js 的兼容方案是通过一系列优秀的社区开源项目共同配合完成的，借助 Babel 的工具可以自动化完成大部分的兼容工作，而借助 ESLint 的插件工具可以显式知道哪些 API 需要引入 Polyfill 来做兼容。\n参考资源 https://github.com/zloirock/core-js https://developer.mozilla.org/ https://caniuse.com/ https://github.com/browserslist/browserslist https://browserslist.dev/ https://eslint.org/ https://github.com/amilajack/eslint-plugin-compat https://babeljs.io/ https://babeljs.io/docs/en/babel-polyfill/ "},{"section":"Blog","slug":"/blog/computer-technology/web/tools-web-fee-debug-with-source-map/","title":"Web 前端调试工具：SourceMap 文件","description":"Web 前端项目在生产环境发布的代码是经过混淆和压缩的，如何调试则成为了一个难题，SourceMap 文件则是一个解决该问题时可以利用的很好的工具。","date":"November 28, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 工具, SourceMap","tags":"计算机技术, Web前端, 工具, SourceMap","content":"Web 前端项目出于加载性能优化和安全考虑，在生产环境部署的代码是经过混淆和压缩的，对于利用生产环境收集到的错误堆栈信息要进行调试是非常具有挑战性的。理想情况下，应该在生产环境收集错误堆栈信息，然后映射到源码进行调试。恰好，SourceMap 文件提供了这个机制，可以将编译（压缩）后的代码映射到源代码中。\n以下是其规范：\nSource Map Revision 3 Proposal\n所以，利用 SourceMap 文件可以改善线上问题调试困难的现状。\n实际应用：调试线上问题 几个月前，新上线的项目接入 SkyWalking 日志后，出了一些兼容性问题，大部分问题根据客户反馈的交互流程基本可以猜到出问题的代码位置，尤其是可以使用测试机进行复现，在本地调试直接可以获知具体的错误栈信息。但其中有几个问题，由于客户的机型太小众，而且系统版本太旧，没有类似的测试机环境可以复现，只能根据线上收集到的错误日志和其中的栈信息定位错误。这看似是个很简单的问题，但实际上不好解决，因为线上日志的错误栈信息中对应的行列号是压缩和混淆后的代码，基本定位不到具体的源码位置。于是，一直在本地模拟用户的交互和测试数据，苦于无法复现，最终回过头来还是决定思考一下怎么根据栈信息定位错误。\n当然，一个很明显的场景就是，本地使用 Webpack 这类构建工具进行开发时，代码本身在本地调试的过程中就已经进行了编译转换和合并，为了能在 Web 开发工具中定位到错误发生的源码位置，会生成 sourcemap 文件来解决这一问题。想到这里，调试线上问题的思路也基本明确了，那就是利用构建发布代码时生成的 sourcemap 文件配合获取的线上日志栈信息中行列号解析出源码的对应位置（文件，行列号）。此时，又出现了两个问题，第一个问题是原来的构建发布代码过程中出于安全考虑是不产生 sourcemap 文件的，当然回过头来想一下，只要目前的项目源码和当前线上发布时的是一致的，重新生成 sourcemap 文件也能解决问题；第二个问题就比较难办了，以前只是配置 Webpack，至于自己如何手动解析 sourcemap 倒还没尝试过，先是查了下资料，发现这个文件格式标准是 Google 提出来的，但没有找到官方提供的解析工具，不过后续却找到了一个 Mozilla 的开源项目 source-map 解决了该问题。\n工具脚本 有了 sourcemap 文件和解析工具其实就很好解决问题了，这里贴一下自己使用的工具脚本源码：\n/** * 调试压缩代码（要保留 dist 文件夹） * ! 上线前请注意不要把 sourcemap 文件一同发布 */ import process from \u0026#39;process\u0026#39;; import path from \u0026#39;path\u0026#39;; import fs from \u0026#39;fs\u0026#39;; import sourceMap from \u0026#39;source-map\u0026#39;; // * 第一步：更改要调试的压缩代码文件对应 sourcemap 文件名称 let sourcemap = fs.readFileSync( path.join(process.cwd(), \u0026#39;./dist/js/index.314d075b.js.map\u0026#39;) ); sourcemap = JSON.parse(sourcemap); async function parse() { const s = await new sourceMap.SourceMapConsumer(sourcemap); // * 第二步：将 `line` 和 `column` 更改为线上错误日志堆栈信息中的行列号 console.debug( s.originalPositionFor({ line: 15, column: 69, }) ); s.destroy(); } // * 最后运行脚本：`node scripts/debug-min-code.mjs` // 查看打印出的实际文件和位置信息 parse(); 实际应用：调试第三方库 对于我们自己写的项目源代码利用诸如 Webpack 等构建工具可以在打包时生成 sourcemap 文件，调试项目源代码就会很方便。但是，在我们开发过程中，一般来说会依赖很多第三方库，大部分的第三方库最终提供的也是经过编译、混淆、压缩、打包的单个 js 文件，如何在开发过程中根据错误堆栈信息调试第三方库也是一个问题。\n一般来说，有两种方案。第一种方案是社区普遍采用的方式，为用户额外提供一个经过编译、打包但未压缩、混淆的单个 js 文件，在包的入口处根据环境导出不同的版本。以 React 的入口文件为示例：\nif (process.env.NODE_ENV === \u0026#39;production\u0026#39;) { module.exports = require(\u0026#39;./cjs/react.production.min.js\u0026#39;); } else { module.exports = require(\u0026#39;./cjs/react.development.js\u0026#39;); } 这里的 NODE_ENV 环境变量是社区共识，而且在各种构建工具中都会自动设置相应的值。这种方案的优势是对于用户来说易于使用，劣势是用户调试过程中的代码依然是被编译和打包后的单个庞大的 js 文件，并非源代码，调试起来也有诸多不便。\n第二种方案就是利用 sourcemap 文件，包在发布的时候附带相应的 sourcemap 文件。但这种方案对于用户来说可能不是开箱即用的，我在使用 Webpack 作为构建工具时，发生错误后，在 Chrome 的开发工具中发现第三方库的 sourcemap 文件没有生效，这个问题的原因可以参考下面这篇文章：\n4 Reasons Why Your Source Maps are Broken\n前端构建工具链中基本都会涉及到处理 sourcemap 文件的过程，所以在使用多个工具链的时候，需要特别注意。对于 Webpack，使用 source-map-loader 这个工具库就可以修复第三方库的 sourcemap 文件失效问题，这样我们在开发过程中就可以基于第三方库的源码进行调试了（当然前提是有提供 sourcemap 文件）。\n参考资料 Source Map Revision 3 Proposal source-map 4 Reasons Why Your Source Maps are Broken source-map-loader "},{"section":"Blog","slug":"/blog/computer-technology/web/practice-of-project-development-and-auto-workflow/","title":"前端开发中的流程自动化与提效实践","description":"前端开发中的流程自动化与提效实践。","date":"November 28, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 提效","tags":"计算机技术, Web前端, 提效","content":"随着前端的发展，越来越多的工具库、方法被用在日常研发流程中，这大大提升了业务开发的效率，而随着各类自动化流程的建设，开发同学也不再需要关注到每一个细节。前段时间项目阶段性交付，在推进的过程中也做了不少尝试，虽然从长期看，这类工作最后可能都该收敛到基础设施部门或者标准的自动化流程中去，但并不妨碍我通过实践来落实一些对项目开发的思考和想法。\n如果你是一名有经验的开发者，可以直接跳到文章末尾，「总结」一章有对全文内容的精简描述。\n接下来，我来分享下在项目开发中尝试的一些自动化和提效实践。本文在撰写中涉及的 UI 框架主要以 create-react-app 所产生的 React 项目为主，会辅以部分其他框架的解决方案以说明。\n新建项目第一步：脚手架 如果你的项目选型是 Angular 的话，那么选择不多可以直接上 Angular CLI；如果是 React 或 Vue 的话，那么会有不少脚手架可以选择，国内很多开发者都有开源不同方案。其中，大多方案会有一些组件库、开源库的绑定，如果你希望一个更加自由的框架搭建，官方脚手架 create-create-app (CRA) 肯定会是第一选择。\n通过 npx 执行如下命令，我们可以通过 CRA 快速创建一个 TypeScript 项目：\nnpx create-react-app project --template typescript 但随着 CRA 的发展，官方脚手架也将原来暴露在模版中的越来越多细节封装到 react-scripts 包里，简单举个例子，比如你想修改项目 webpack 构建流程，用官方模版无法直接上手。\n官方模版提供了 npm run eject 命令，执行这个命令会将潜藏的一系列配置文件和一些依赖项都“弹出”到项目中，然后就可以由你自己完全控制增删，但是该操作是不可逆的。在配置文件被“弹出”后，你后续将无法跟随官方的脚步去升级项目所使用的 react-script 版本了。\n那么，如果你想要一个可以覆盖配置，但又与官方版本保持同步的方案，则可以试试 craco https://github.com/dilanx/craco\n样式隔离方案：CSS Modules module.exports = { style: { css: { mode: \u0026#34;extends\u0026#34;, loaderOptions: { modules: { auto: true, exportLocalsConvention: \u0026#39;camelCaseOnly\u0026#39;, }, }, }, }, }; 在ts环境中可以添加类型定义\n/// \u0026lt;reference types=\u0026#34;node\u0026#34; /\u0026gt; /// \u0026lt;reference types=\u0026#34;react\u0026#34; /\u0026gt; /// \u0026lt;reference types=\u0026#34;react-dom\u0026#34; /\u0026gt; /// \u0026lt;reference types=\u0026#34;react-scripts\u0026#34; /\u0026gt; declare module \u0026#39;*.module.css\u0026#39; { const classes: { readonly [key: string]: string }; export default classes; } declare module \u0026#39;*.module.scss\u0026#39; { const classes: { readonly [key: string]: string }; export default classes; } declare module \u0026#39;*.module.sass\u0026#39; { const classes: { readonly [key: string]: string }; export default classes; } ESLINT 代码检查：两个自定义 lint 场景分享 自动化环境配置：git hook 钩子定义 husky 是一个为 git 客户端增加 hook 的工具，可以被用于我们配置本地自动化环境。我们可以安装 husky 并定制我们需要的 git 钩子及具体需要执行的任务，这样可以方便我们在对代码执行 git 操作时，在特定时机对代码进行特定的检查与处理，常见的钩子有如下两个：\ncommit-msg - 提交信息钩子，在执行 git commit 或者 git merge 时触发 pre-commit - 预先提交钩子，在执行 git commit 时触发 如下为一段 husky 安装和初始化代码：\nnpm install husky -D npx husky-init \u0026amp;\u0026amp; npm install // 添加任务一条 commit-msg 钩子 npx husky add .husky/commit-msg \u0026lsquo;./node_modules/.bin/commitlint \u0026ndash;from=HEAD~1\u0026rsquo; 举个例子，比如我们可以结合 commitlint 工具，在 commit-msg 阶段针对 commit 信息进行检查和处理（如上代码所示），又或者在 pre-commit 阶段对将要提交的代码进行格式化操作。\n自定义命令调用：代码风格统一与 commit 信息规范 不仅是对于开发代码，对于 commit 信息来说，五花八门的书写风格，也十分不利于阅读和维护，比如，当我们需要翻阅历史提交来定位具体 commit 所带来的代码变动时，这依赖于规范的 commit 信息。借助 commitlint 可以帮助我们达到这一点。\ncommitlint 需要配合 husky 一起使用，具体来说，通过 husky 来保证针对具体钩子的命令配置，通过 commitlint 保证 命令执行能够对 commit msg 信息进行特定检查。一个简单的 commitlint 安装和配置如下：\n# 安装 npm install --save-dev @commitlint/{config-conventional,cli} # 配置 echo \u0026#34;module.exports = {extends: [\u0026#39;@commitlint/config-conventional\u0026#39;]}\u0026#34; \u0026gt; commitlint.config.js 配置了 commitlint 之后，若是使用默认配置，那么只有当我们的 commit msg 符合如下规范时，commit 操作才能正常完成执行，否则中断（其中 scope 为可选）：\n\u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): description 如果需要自定义规则，则需要我们更改 commitlint.config.js 文件，为其增添 rules，关于这一部分可以参考官方文档 https://commitlint.js.org/。\n此外，在添加了 commitlint 配置文件后，我们可能会看到 IDE 对这个文件的检查标红，由于在项目构建中我们并不关注该配置文件的格式等内容（因为他只是对 commitlint 的简单配置），所以我们可以在 eslint 配置文件中将其忽略掉。同样的，如果有其他的文件属于类似的定位，你也可以一并将其加入：\n{ \u0026#34;ignorePatterns\u0026#34;: [\u0026#34;commitlint.config.js\u0026#34;] } 说完 commit 规范，我们的代码格式本身也需要规范，比如针对 TypeScript 代码会有变量命名和排序的规则，针对 html 模版会有缩进、标签闭合等规则，这些也可以利用工具结合 git hook 来实现，此处，我们介绍下 linter 工具：lint-staged。\nlint-staged 是一个在 git 暂存文件上运行 linters 的工具，通过 lint-staged 定制各类文件格式化的操作（主要通过 eslint 和 prettier 保证执行）。结合 pre-commit git hook，我们在此钩子被触发时执行 lint-staged，便能完成对相应文件的格式化处理。如何让工具针对不同类型的文件区分处理呢？这里可以通过配置达到目的，即在 pakage.json 中对 lint-staged 字段进行声明：\n{ ..., \u0026#34;lint-staged\u0026#34;: { \u0026#34;*.{js,jsx,ts,tsx}\u0026#34;: [ \u0026#34;eslint -c ./.eslintrc.json --fix\u0026#34; ], \u0026#34;(*.json|.eslintrc|.prettierrc)\u0026#34;: [ \u0026#34;jsonlint --in-place\u0026#34; ], \u0026#34;*.{s,}css\u0026#34;: [ \u0026#34;prettier --write\u0026#34; ], \u0026#34;*.{html,md}\u0026#34;: [ \u0026#34;prettier --write\u0026#34; ] } } 如上代码表明，lint-staged 可以针对 JavaScript/TypeScript 类文件执行 eslint 处理，针对 json 类文件执行 jsonlint 处理，而对样式文件和 html 文件都用 prettier 处理。\n本地开发代理环境 从本地开发的场景来看，最需要完善的一个功能就是转发 API 请求了，用以规避可能存在的 CORS 错误，或者绕开一些请求限制，形式上可以是针对特定请求变更 header 信息，也可以是针对特定请求变更实际请求的域名与路径。但无外乎都需要在本地建立一个代理环境。前端项目在本地开发时，我们可以通过一个叫做 http-proxy-middleware 的库来增强本地 dev server 的能力。\n通过文档介绍，我们知道可以通过调用 createProxyMiddleware API 来构造一个中间件，以供 Node.js 项目使用，针对 express 应用可以通过如下配置完成代理服务器中间件的配置：\nimport * as express from \u0026#39;express\u0026#39;; import { createProxyMiddleware } from \u0026#39;http-proxy-middleware\u0026#39;; const app = express(); app.use( \u0026#39;/api\u0026#39;, createProxyMiddleware({ target: \u0026#39;http://www.example.org/api\u0026#39;, changeOrigin: true, }) ); app.listen(3000); 而对于通过 CRA 构建的项目，由于 CRA 已经做了一些封装工作，于是在本地开发时，我们不再需要显式地起一个 Node.js 应用，而如上对代理中间件地调用，也可以在指定文件中按照规范书写（文件名以及方法签名需要规范，此处不列举，CRA 官方文档有说明）。\n代码复用：组件模版与 code snippets 当我们新建一个项目时，我们会找脚手架替我们搭建一个合适的架子，然后我们往里面填充组件、页面、服务等等，而针对更细粒度的代码，我们同样可以考虑通过代码复用来提升我们的开发效率，这里的场景主要可以分为两类：\nCode snippets 类代码片段 组件粒度的文件代码 针对第一类场景，我们在 IDE 中安装的不少插件都替我们达到了这个目的。当我们在特定类型的文件中敲出几个字母，然后一回车，就能快速生成一段代码片段。举个例子，比如当我们使用 RxJS 时经常需要定义 BehaviorSubject 及其 getter \u0026amp; setter，要是输入 bgs 就能出现如下代码，便能提高我们在写一些初始化代码时的效率： /* TODO: 数据流定义 */ behaviorName$ = new BehaviorSubject\u0026lt;string\u0026gt;(initialValue); get behaviorName() { return this.behaviorName$; } set behaviorName(value: string) { this.behaviorName$.next(value); } 而我们要做的事情就是将 bgs 和上述代码（及特定占位符）连接起来，实现方案可以是 VS Code 插件，比如我之前写过一个 https://marketplace.visualstudio.com/items?itemName=hijiangtao.tutor-code-snippets，也可以是 WebStorm 插件或者 live templates。\n针对第二类场景，我们需要的往往是指定路径下一套遵循我们命名规范的模版、样式和 TypeScript 逻辑代码。举个例子，在 Angular 项目中，当我们新建一个组件时，我们需要同时生成 HTML、JavaScript、CSS 文件并更新离其最近的 *.module.ts 文件：\nCREATE projects/src/app/demo/demo.component.css (0 bytes) CREATE projects/src/app/demo/demo.component.html (19 bytes) CREATE projects/src/app/demo/demo.component.spec.ts (612 bytes) CREATE projects/src/app/demo/demo.component.ts (267 bytes) UPDATE projects/src/app/app.module.ts (1723 bytes) 在 Angular 项目中，我们可以通过 Angular schematics 来很方便的实现这一目的；而针对 React 或者 Vue 项目，社区也有不少实现方案，比如 generate-react-cli。\n如果不借助社区或者官方方案，要实现第二类场景所需的工具，也可以自己开发一个 npm 包并暴露相应 bin 脚本，然后通过 npx 执行来达到目的，关于 npx 的介绍可以参考我之前写过的一篇博文《记录一下 npx 的使用场景》。\n版本发布：发版与 CHANGELOG 自动化 每当我们需要上线一个新需求时，为了更好的记录变动，我们一般需要发个版本，并同时记录一些 CHANGELOG，如果能把这部分工作完全自动化，毋庸置疑可以提升我们的项目规范和发版效率。这里以 standard-version 举例。我们引入 standard-version 对自动打 tag 以及 CHANGELOG 生成进行规范，具体来说，是期望通过 standard-version 达到如下目的：\n根据指定规则自动升级项目不同级别（major、minor、patch）的版本并打 tag 对比历史 commit 提交自动生成不同版本间的可阅读、分类的 CHANGELOG 日志 通过配置，我们还可以重命名上文提到的 commit 信息中的 type 字段在 CHANGELOG 中的标题展示，如下为一个示例配置：\nmodule.exports = { \u0026ldquo;types\u0026rdquo;: [ { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;feat\u0026rdquo;, \u0026ldquo;section\u0026rdquo;: \u0026ldquo;Features\u0026rdquo; }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;fix\u0026rdquo;, \u0026ldquo;section\u0026rdquo;: \u0026ldquo;Bug Fixes\u0026rdquo; }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;test\u0026rdquo;, \u0026ldquo;section\u0026rdquo;: \u0026ldquo;Tests\u0026rdquo; }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;doc\u0026rdquo;, \u0026ldquo;section\u0026rdquo;: \u0026ldquo;Document\u0026rdquo; }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;build\u0026rdquo;, \u0026ldquo;section\u0026rdquo;: \u0026ldquo;Build System\u0026rdquo; }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;ci\u0026rdquo;, \u0026ldquo;hidden\u0026rdquo;: true } ] } 如下为自动生成的 CHANGELOG 示例：\nChangelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines.\n1.11.0 (2022-06-28) Features 测试 feature 提交 @hijiangtao (merge request !65) (a091125) 1.10.1 (2022-06-24) Bug Fixes 修改 XXX，并新增 YYY (merge request !63) (e3a01ce) 在使用 standard-version 的时候，默认的配置可以满足绝大部分场景了，但更细粒度的控制仍需要我们修改命令或者配置。比如，当我们在 package.json 中指定了仓库 url 后，我们便可以在 commit 信息中通过 @ 符号指定对应用户、通过 # 引用对应 issue/PR，这些在生成 CHANGELOG 时都会被转成对应包含链接地址的超链接，如下列上一些我在开发中的版本自动生成所涉及的应用场景及注意事项： // 首次执行（不变更版本） standard-version -a \u0026ndash; \u0026ndash;first-release\n// 但是如果项目版本不符合规范，还是需要手动发布，因为需要保证项目从 v1.0.0 开始 // https://github.com/conventional-changelog/standard-version/issues/131 standard-version -a \u0026ndash; \u0026ndash;release-as 1.0.0\n// 在 package.json 中确保项目正确配置 repository 对象 repository.url\n// 带通知具体 user 的 commit-msg git commit -m \u0026ldquo;fix: bug produced by @timojiang\u0026rdquo;\n// 带 issue 的 commit-msg git commit -m \u0026ldquo;fix: implement functionality discussed in issue #2\u0026rdquo; 总结 本文从项目初始化选用脚手架开始、样式隔离、lint 规则与 git hook 再到模版工具和自动化版本日志，介绍了本人在开发过程中的一些实践和思考，旨在指出一个项目从代码初始化到交付上线过程中可能涉及到的不同流程中，存在的不同提交效率和自动化流程的工作，囿于文章篇幅，没有针对所有涉及到的流程和工具进行详细的 API 介绍，但你仍可以针对其中提到的各类关键词在互联网上进行搜索和查看。\n本文在撰写时也尽量针对不同流程换用了普适的一些描述，以保证所提供的方案在替换了具体工具库后仍是长期可用的，防止文章内容受工具的时效性影响。\n全文来看，主要有这么几点实践总结：\n在脚手架的选择上，你可以使用 create-react-app 或者 umi 等社区方案，但如果想要更灵活的脚手架，当你使用 CRA 的时候，可以一并考虑 craco； CSS Modules 的作用无需多说，但同样需要注意 TypeScript 检查以及你在命名 CSS 变量写法上的兼容； ESLINT 现在已经是大部分项目的标配了，如果你的项目涉及多人协作，可以配置一些额外的 plugin 协助保持风格一致、减少代码合并冲突。当然，在统一代码风格上，还可以通过 husky 定制 git 钩子与具体需要执行的任务，比如： commit-msg pre-commit\n其中通过 lint-staged 在 pre-commit 时机定制各类文件格式化的操作（主要用 eslint 和 prettier 保证执行），通过 commitlint 保证 commit msg 信息符合规范。 本地开发代理环境在很多团队是必须的，你可以选用一个中间件来增强你的 dev server。 我们同样可以考虑通过代码复用来提升我们的开发效率，这里的场景主要可以分为两类：code snippets 以及组件级别的文件修改。 每当项目上线，规范来说，都需要发版及记录日志变更，我们可以引入 standard-version 对自动打 tag 以及 CHANGELOG 生成进行规范。 "},{"section":"Blog","slug":"/blog/computer-technology/web/web-app-model-zustand/","title":"Web 应用：轻量级状态管理工具 zustand","description":"Web 网页向 Web 应用发展的过程中，势必会出现 Web 项目的复杂化问题，而在移动端场景，基于 React.js 的应用中如何管理状态？zustand 也许值得一试。","date":"November 18, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 应用状态管理, React","tags":"计算机技术, Web前端, 应用状态管理, React","content":"基于 React.js 的 Web 应用如何完成状态管理？社区主流方案是 react-redux，其本质上基于 React 的 Context 特性实现，如果应用足够简单，实际上用 Context 手写一个简单的状态管理工具倒也并不难。不过，考虑到工具的完善性、项目的健壮性，通常采用较好的、成熟的社区方案。在移动端场景下，react-redux 略显臃肿，轻量级状态管理工具 zustand 倒是一个不错的替代方案。\n轻量级状态管理方案 Web 优化中，资源大小的优化是重中之重，而且也是成本最低，收益最高的优化方式，在移动端场景下尤为突出。每在项目中引入一个工具库，都要考虑是否有更轻量级的替代品。众所周知，moment 就是一个典型的例子，我通常采用 dayjs 作为替代方案。而在应用状态管理工具的选择中，可以利用 Bundlephobia 首先评估一下社区主流方案 react-redux。\nMINIFIED MINIFIED + GZIPPED redux@4.1.2 4.3kB 1.6kB react-redux@7.2.6 16.2kB 5.4kB 20.5kB 7kB 仅必须的依赖就需要 7kb 之多，而我们也知道，redux 不仅是一个状态管理工具，其同时也提倡一种优秀的模式，即我们熟知的：\nStore -\u0026gt; Dispatch -\u0026gt; Action -\u0026gt; Reducer -\u0026gt; Store\n而这种模式需要我们手写大量的模板代码，于是就有了官方解决方案 @reduxjs/toolkit 和社区方案 @rematch/core，这进一步加剧了资源大小所带来的影响。\nMINIFIED MINIFIED + GZIPPED @reduxjs/toolkit@1.6.2 32.1kB 10.5kB @rematch/core@2.2.0 4.7kB 1.7kB 经过分析，事实上我们可以看到 redux 的核心代码库仅有 1.6kb 的大小，但为了适配 React.js 和解决模板代码的问题，至少也要增加 7.1kb 的资源大小。换句话说，状态管理工具的核心实现其实是比较简单的，这也是核心库较小的原因，而在移动端场景下，项目一般较为简单、规模较小，对于工具的核心需求其实也仅仅是满足应用状态管理即可。于是，zustand 社区方案成为了我的一个选择。\nMINIFIED MINIFIED + GZIPPED zustand@3.6.5 2kB 954B jotai@1.4.3 6.1kB 2.5kB 上表中，还列出了 jotai，它与 zustand 出自同一个开发者群体之手，前者仅适用于 React.js 组件内的状态管理，而后者还适用于组件之外的状态操作。zustand 足够简单，且无需太多模板代码，仅 954B 大小即可满足应用状态管理的核心需求。\n至此，移动端场景下，要替代 react-redux 这种主流方案，考虑以下几点：\n满足应用状态管理的核心需求 具备资源大小优势 用法足够简单 方案成熟（较多人采用、有配套的调试工具等） 可在组件外操作状态 其中，可在组件外操作状态这一点其实是为了满足方案的灵活性，有时候业务需求的实现可能会涉及到在组件之外进行状态操作的场景，这个时候就很方便了。\nredux vs zustand 接下来，分析一下两者的源码实现，即可了解是否 zustand 可作为一个较好的替代方案。分两步进行，第一步首先来看看两者的核心实现，即状态管理的机制。\n首先，我们要明白状态管理做的是什么事情。状态即数据，对于一个原生的 Web 应用来说，某一时刻页面展示的结构和样式取决于此时的状态，状态可能会由于用户交互动作发生变化。Web 应用有很多状态，比如表单的勾选按钮状态，我们可以将这种状态视为局部状态，该状态的变化不会导致页面其它部分发生变化；当然，如果我们将用户体验设计更进一步，勾选按钮的状态会同步影响表单提交按钮是否处于可点击的状态，此时一个状态在页面两个部分都有影响，对于更复杂的 Web 应用来说，一个状态可能影响到页面数十个部分，我们就需要对状态的维护更新机制进行设计，将状态的维护从页面进行解耦，独立到全局来进行，则将这种状态称之为全局状态。显然，对于局部状态来说，页面局部可以完成自治，而对于全局状态来说，则需要一个全局中心化的“数据库”来进行管理。\n现在，我们可以知道，状态管理需要提供一个类似中心化的“数据库”，同时对于状态要提供更新机制，而状态可以被多个部分依赖，状态更新的同时依赖方可以及时获取到最新状态。这不就是软件架构中典型的发布/订阅模式吗？所以，先来看看 redux 和 zustand 两者提供的 API，大致就能理解其核心实现的模型。\n// Redux (https://redux.js.org/api/api-reference) createStore(reducer, [preloadedState], [enhancer]); // Store getState(); subscribe(listener); dispatch(action); // zustand (https://github.com/pmndrs/zustand) createStore(); // Store getState(); subscribe(); setState(); 由此可见，两者提供的核心 API 是非常相近的，从 API 命名的角度来看，其核心实现无疑是基于发布/订阅模式。\n两者都有一个 createStore() API 来创建一个中心化的数据存储区，同时创建的 store 实例均会暴露出主动获取状态的 API getState()，订阅状态更新的 API subscribe()，以及更新状态的 API dispatch() 和 setState()，当然 redux 还引入了一个 reducer 的概念和 API。\n两者的核心库均只有 1kb 大小，而 zustand 更小，这是因为 zustand 实现更为简单一些，其差异主要集中在状态更新机制上，其次是状态订阅机制。\nsubscribe() 在状态订阅的 subscribe() API 实现中，zustand 仅是简单的直接将订阅函数添加到订阅列表中，同时提供了一个 selector 机制来过滤状态：\n// see https://github.com/pmndrs/zustand/blob/v3.6.5/src/vanilla.ts#L126 const subscribe: Subscribe\u0026lt;TState\u0026gt; = \u0026lt;StateSlice\u0026gt;( listener: StateListener\u0026lt;TState\u0026gt; | StateSliceListener\u0026lt;StateSlice\u0026gt;, selector?: StateSelector\u0026lt;TState, StateSlice\u0026gt;, equalityFn?: EqualityChecker\u0026lt;StateSlice\u0026gt; ) =\u0026gt; { if (selector || equalityFn) { return subscribeWithSelector( listener as StateSliceListener\u0026lt;StateSlice\u0026gt;, selector, equalityFn ); } listeners.add(listener as StateListener\u0026lt;TState\u0026gt;); // Unsubscribe return () =\u0026gt; listeners.delete(listener as StateListener\u0026lt;TState\u0026gt;); }; // see https://github.com/pmndrs/zustand/blob/v3.6.5/src/vanilla.ts#L107 const subscribeWithSelector = \u0026lt;StateSlice\u0026gt;( listener: StateSliceListener\u0026lt;StateSlice\u0026gt;, selector: StateSelector\u0026lt;TState, StateSlice\u0026gt; = getState as any, equalityFn: EqualityChecker\u0026lt;StateSlice\u0026gt; = Object.is ) =\u0026gt; { console.warn(\u0026#39;[DEPRECATED] Please use `subscribeWithSelector` middleware\u0026#39;); let currentSlice: StateSlice = selector(state); function listenerToAdd() { const nextSlice = selector(state); if (!equalityFn(currentSlice, nextSlice)) { const previousSlice = currentSlice; listener((currentSlice = nextSlice), previousSlice); } } listeners.add(listenerToAdd); // Unsubscribe return () =\u0026gt; listeners.delete(listenerToAdd); }; 通过上面 listenerToAdd() 函数可以看到，在订阅状态时提供了 selector 的话，状态更新时会首先将状态过滤一遍再通知给订阅者。\n// see https://github.com/pmndrs/zustand/blob/v3.6.5/src/vanilla.ts#L89 const setState: SetState\u0026lt;TState\u0026gt; = (partial, replace) =\u0026gt; { // ... listeners.forEach((listener) =\u0026gt; listener(state, previousState)); // ... }; 通过 setState() 更新状态时，所有订阅函数将会调用，同时会将新的状态和旧的状态传递给订阅函数。\n接下来，看看 redux 的实现，redux 在添加订阅函数时做了一些特殊的判断，以及特殊处理：\n// see https://github.com/reduxjs/redux/blob/v4.1.2/src/createStore.js#L128 function subscribe(listener) { // ... if (isDispatching) { throw new Error(\u0026#39;...\u0026#39;); } let isSubscribed = true; ensureCanMutateNextListeners(); nextListeners.push(listener); return function unsubscribe() { if (!isSubscribed) { return; } if (isDispatching) { throw new Error(\u0026#39;...\u0026#39;); } isSubscribed = false; ensureCanMutateNextListeners(); const index = nextListeners.indexOf(listener); nextListeners.splice(index, 1); currentListeners = null; }; } // see https://github.com/reduxjs/redux/blob/v4.1.2/src/createStore.js#L82 function ensureCanMutateNextListeners() { if (nextListeners === currentListeners) { nextListeners = currentListeners.slice(); } } 根据实现，redux 通过 isDispatching 标志位避免在状态更新期间添加订阅函数，以及通过 ensureCanMutateNextListeners() 函数将订阅函数列表做了浅拷贝再进行添加和删除操作，这都是对潜在的问题的规避。\n// see https://github.com/reduxjs/redux/blob/v4.1.2/src/createStore.js#L197 function dispatch(action) { // ... const listeners = (currentListeners = nextListeners); for (let i = 0; i \u0026lt; listeners.length; i++) { const listener = listeners[i]; listener(); } return action; } redux 通过 dispatch() 更新状态时，由于在订阅时没有默认提供 selector 机制，所以会无差别的通知所有订阅者，同时也不会将新旧状态传递给订阅函数，当然在官方示例代码中可以看到，官方推荐在订阅函数中主动通过 getState() 获取新的状态以及完成 selector 操作。可以说，由于 redux 和 zustand 设计理念不同，订阅的实现方式也略有差别，前者控制的更细致，而灵活性很高，而后者在保持简单性的同时也没有牺牲灵活性。\nsetState() \u0026amp;\u0026amp; dispatch() 状态更新机制是两者实现最大的不同，zustand 提供一个 setState() 函数来更新状态：\n// see https://github.com/pmndrs/zustand/blob/v3.6.5/src/vanilla.ts#L89 const setState: SetState\u0026lt;TState\u0026gt; = (partial, replace) =\u0026gt; { // TODO: Remove type assertion once https://github.com/microsoft/TypeScript/issues/37663 is resolved // https://github.com/microsoft/TypeScript/issues/37663#issuecomment-759728342 const nextState = typeof partial === \u0026#39;function\u0026#39; ? (partial as (state: TState) =\u0026gt; TState)(state) : partial; if (nextState !== state) { const previousState = state; state = replace ? (nextState as TState) : Object.assign({}, state, nextState); listeners.forEach((listener) =\u0026gt; listener(state, previousState)); } }; 根据源码实现来看，zustand 通过 Object.assign 函数合并更新状态，同时提供 replace 标志位直接将旧状态完全替换。\n而 redux 的状态更新则要复杂一些，主要是官方推荐的编程模式将状态更新拆分为多个步骤，dispatch() 函数触发一个 Action，而具体处理 Action 以及状态合并的操作均由 Reducer 函数完成，该函数是一个纯函数。至于为什么要这么设计，官方有说明，纯函数对于状态变化来说是可预测的，而且利于测试，更是实现时间旅行类似功能的基础。\n// see https://github.com/reduxjs/redux/blob/v4.1.2/src/createStore.js#L197 function dispatch(action) { if (!isPlainObject(action)) { throw new Error( `Actions must be plain objects. Instead, the actual type was: \u0026#39;${kindOf( action )}\u0026#39;. You may need to add middleware to your store setup to handle dispatching other values, such as \u0026#39;redux-thunk\u0026#39; to handle dispatching functions. See https://redux.js.org/tutorials/fundamentals/part-4-store#middleware and https://redux.js.org/tutorials/fundamentals/part-6-async-logic#using-the-redux-thunk-middleware for examples.` ); } if (typeof action.type === \u0026#39;undefined\u0026#39;) { throw new Error( \u0026#39;Actions may not have an undefined \u0026#34;type\u0026#34; property. You may have misspelled an action type string constant.\u0026#39; ); } if (isDispatching) { throw new Error(\u0026#39;Reducers may not dispatch actions.\u0026#39;); } try { isDispatching = true; currentState = currentReducer(currentState, action); } finally { isDispatching = false; } const listeners = (currentListeners = nextListeners); for (let i = 0; i \u0026lt; listeners.length; i++) { const listener = listeners[i]; listener(); } return action; } 根据源码实现来看，这里出现了 isDispatching 标志位，主要是用来限制状态更新过程中不能再次发起状态更新操作，避免出现错误。\n不过，有一点值得提一下，redux 默认不支持异步更新状态，需要借助 redux-thunk 库来支持；而 zustand 本身则是支持异步更新状态的。\n根据以上分析来看，实际上核心实现是相似的，而且 zustand 作为后来者，对 redux 有借鉴也有简化的地方，满足状态管理的核心简单需求是没有多大问题的，可作为 redux 的一个替代方案。\nReact.js 适配 如果说，核心库差异较小，而且包尺寸相近的话，那么最大的差异则出现在对 React.js 库的适配上面。\nzustand 出现的较晚，目前 Hook API 已经成为 React.js 社区的主流，所以 zustand 在对其适配的时候也是以 Hook API 的方式实现，没有提供类组件的适配。\n// see https://github.com/pmndrs/zustand/blob/v3.6.5/src/index.ts#L64 function create\u0026lt; TState extends State, CustomSetState, CustomGetState, CustomStoreApi extends StoreApi\u0026lt;TState\u0026gt; \u0026gt;( createState: | StateCreator\u0026lt;TState, CustomSetState, CustomGetState, CustomStoreApi\u0026gt; | CustomStoreApi ): UseBoundStore\u0026lt;TState, CustomStoreApi\u0026gt; { // ... const useStore: any = \u0026lt;StateSlice\u0026gt;( selector: StateSelector\u0026lt;TState, StateSlice\u0026gt; = api.getState as any, equalityFn: EqualityChecker\u0026lt;StateSlice\u0026gt; = Object.is ) =\u0026gt; { const [, forceUpdate] = useReducer((c) =\u0026gt; c + 1, 0) as [never, () =\u0026gt; void]; // ... const stateBeforeSubscriptionRef = useRef(state); useIsomorphicLayoutEffect(() =\u0026gt; { const listener = () =\u0026gt; { try { const nextState = api.getState(); const nextStateSlice = selectorRef.current(nextState); if ( !equalityFnRef.current( currentSliceRef.current as StateSlice, nextStateSlice ) ) { stateRef.current = nextState; currentSliceRef.current = nextStateSlice; forceUpdate(); } } catch (error) { erroredRef.current = true; forceUpdate(); } }; const unsubscribe = api.subscribe(listener); if (api.getState() !== stateBeforeSubscriptionRef.current) { listener(); // state has changed before subscription } return unsubscribe; }, []); const sliceToReturn = hasNewStateSlice ? (newStateSlice as StateSlice) : currentSliceRef.current; useDebugValue(sliceToReturn); return sliceToReturn; }; // ... return useStore; } zustand 将 createStore 函数的返回值作为一个自定义 hook 来实现，其中为了让 React.js 组件能感知到状态更新，是利用 useEffect 来完成订阅操作，而状态更新发布后，则通过 forceUpdate() 来强制组件进行 rerender 以获取最新的状态。\n这里，看看如何在函数组件中使用 zustand：\nimport create from \u0026#39;zustand\u0026#39;; // Store const useStore = create((set) =\u0026gt; ({ bears: 0, increasePopulation: () =\u0026gt; set((state) =\u0026gt; ({ bears: state.bears + 1 })), removeAllBears: () =\u0026gt; set({ bears: 0 }), })); // Component function BearCounter() { const bears = useStore((state) =\u0026gt; state.bears); return \u0026lt;h1\u0026gt;{bears} around here ...\u0026lt;/h1\u0026gt;; } function Controls() { const increasePopulation = useStore((state) =\u0026gt; state.increasePopulation); return \u0026lt;button onClick={increasePopulation}\u0026gt;one up\u0026lt;/button\u0026gt;; } 实际上，用法和 react-redux 非常相似，但获取状态与更新状态均只需要使用 useStore 一个 API 即可完成业务。\n然而，react-redux 的实现则要复杂的多。由于其出现的较早，所以同时适配了类组件和函数组件。这里不再细究 react-redux 的具体实现，但其与 zustand 最大的差异则在于把状态放在了 Context 中存储，所以需要使用 Provider 将页面的根组件包裹起来才能使用。redux 的 useSelector() Hook API 与 zustand 上面提到的 useStore() 的实现逻辑也非常相似。\n调式工具 一个核心工具库好不好用，不仅要能解决业务问题，同时也要能提供良好的开发体验，redux 之所以能成为 React.js 社区普遍采用的状态管理方案，不仅在于其实现的优雅，倡导的优秀的模式，更在于其配套的调试工具、中间件也非常好用。所以，zustand 作为后来者并没有重复造轮子，而是尽最大的可能重用 redux 社区的开源方案，这一点也是比较好的，至少从 redux 迁移到 zustand 不会有太大的困难，开发体验上来说还是不错的。\n结语 至此，完成了对 zustand 这个轻量级的状态管理方案的探索，至少在满足状态管理简单的核心需求、使用简单、具备良好的调式工具等几方面来说还是不错的，作为 redux 的轻量级替代方案，完全值得一试。\n参考 redux react-redux zustand Let’s build our own Redux "},{"section":"Blog","slug":"/blog/computer-technology/web/web-performance-fastdom/","title":"Web 前端性能优化：批量 DOM 操作 - FastDOM","description":"原生应用时代，DOM 操作一般借助类似 jQuery 的工具库手动完成，而在框架/库应用时代 DOM 操作退居幕后自动完成，原生应用与框架应用性能孰高孰低？DOM 批量操作对于性能有何影响？利用 FastDOM 库来解决这些性能问题。","date":"October 4, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 性能优化, DOM","tags":"计算机技术, Web前端, 性能优化, DOM","content":"利用 JS 开发的原生应用与依赖于 React.js/Vue 开发的框架/库应用，性能孰高孰低？这两者最显著的区别在于原生应用需要手动操作 DOM 完成业务，而框架/库应用是基于数据变化响应式的应用，后者只需要关注数据如何变化，至于体现在 DOM 上的变化皆由框架/库内部自动完成。所以，要搞清楚两者的性能优劣，可能批量的 DOM 操作是一个不可忽略的核心因素。从代码执行的角度分析，框架/库也是基于原生 API 进行的封装抽象，因此代码执行时的路径更长、堆栈更深，由此可见原生 API 的操作性能应该是最高的。但是，现实情况是业务通常来说是复杂的，代码实现中 DOM 操作的逻辑分散在各处，那么多个 DOM 操作之间是否会产生影响从而不利于性能？这个时候就要关注宿主浏览器的渲染机制是如何理解批量的 DOM 操作的，这里引入的概念就是关键渲染路径（Critical rendering path）。\nhttps://developer.mozilla.org/en-US/docs/Web/Performance/Critical_rendering_path https://developers.google.com/web/fundamentals/performance/rendering\n简单的来说，浏览器逐帧渲染的机制每次都需要经历一个先计算后布局再渲染的过程，DOM API 可以分为读和写两类，如果把一些批量的 DOM 操作先按读和写分为两组，统一先执行读操作，然后再执行写操作，这样就能实现最高的性能。这里的问题就在于如果高频率的进行 DOM 读写的交替操作会加重浏览器的负担，浏览器无法在一次渲染路径内完成所有的 DOM 操作，因此产生严重的性能问题。\n那么，现在问题就很明朗了，一个复杂的业务场景中，如何实现批量 DOM 操作合理的调度才是实现高性能的关键，原生应用依赖于开发者自主对于代码的规划，要将分散在各处的 DOM 操作进行合理的调度并不是一件容易的事情，反而可能因此搞乱项目架构；而现在的类似 React.js 的框架/库则基于此，以一种数据驱动的响应式应用的理念，将复杂的 DOM 操作封装在内部，设计一种优化的调度机制实现高性能的应用。\n// 批量的 DOM 操作 -\u0026gt; DOM 读 1 -\u0026gt; DOM 写 1 -\u0026gt; DOM 读 2 -\u0026gt; DOM 写 2 // 优化调度 -\u0026gt; DOM 读 1 -\u0026gt; DOM 读 2 -\u0026gt; DOM 写 1 -\u0026gt; DOM 写 2 真实的业务场景 以上，讨论了原生应用与框架/库应用在性能方面的关键所在，批量 DOM 操作的调度至关重要。虽然说框架/库在底层帮助我们完成了 DOM 操作和调度，但在日常的业务开发过程中难免会遇到需要开发者与 DOM 交互的场景，而我此前就遇到一个真实的业务场景。\n在一个优化过的虚拟列表中，需要针对列表项中一些 DOM 元素进行缩放处理，而实现的具体思路是先要在渲染完成后测量 DOM 尺寸进行计算，再加样式进行 DOM 的缩放。以 DOM 结构说明：\n\u0026lt;div class=\u0026#34;virtual-list\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;width-50 js-scale\u0026#34;\u0026gt;some text too long.\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;width-50 js-scale\u0026#34;\u0026gt;some text too long.\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;width-50 js-scale\u0026#34;\u0026gt;some text too long.\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;width-50 js-scale\u0026#34;\u0026gt;some text too long.\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; 在列表滚动渲染的过程中，需要针对 js-scale DOM 元素进行缩放处理，不允许自动换行的文本过长时（超过指定宽度时），利用 transform: scale(n); 样式进行缩放。那么，这里就涉及一次 DOM 的读和写操作，本身虚拟列表对性能要求比较高，虚拟化的实现过程中有性能损耗，缩放的实现对性能的影响要降到最低。\n最简单的实现就是以 row 为单位，在每次渲染初始化后就进行缩放处理，由于 row 是逐个渲染的，所以缩放的处理过程实际上为：\n-\u0026gt; row1 DOM 读 -\u0026gt; row1 DOM 写 -\u0026gt; row2 DOM 读 -\u0026gt; row2 DOM 写 ... 实际上，这就是前面所分析的，DOM 的读和写操作高频的交替发生，性能影响非常明显。以 row 为单位进行缩放处理降低了实现的复杂度，但要将所有 row 的 DOM 操作统一调度起来会麻烦一些，不过并不是很难。实现的思路就是用两个数组分别收集对 DOM 的读和写操作函数，然后再统一先执行所有的读操作，再执行写操作，为了保证 UI 交互的及时响应，要动态的每隔一段时间就统一把收集到的 DOM 操作执行一遍再重新收集。\nFastDOM 不过，不必造轮子，在 Google 的 Web 性能文档中提及一个 npm 工具库 FastDOM，正如其名，该工具库的目的就是加速 DOM 的批量处理以提高性能。\nhttps://developers.google.com/web/fundamentals/performance/rendering/avoid-large-complex-layouts-and-layout-thrashing\n在利用 FastDOM 验证以上真实业务场景中所遇到的性能问题时，效果还是比较理想的。\n那么，我们接下来就看看其实现机制，其工作原理文档中也有所提及：\nhttps://github.com/wilsonpage/fastdom#how-it-works\n简单的来说，与之前设想的实现思路一致，用 window.requestAnimationFrame() API 来动态控制以提高对 UI 交互的及时响应。事实上，其源码实现也并不难，可以简单的来分析一下。其提供了两个最主要的 API：\nfastdom.measure() - 对应 DOM 的读操作 fastdom.mutate() - 对应 DOM 的写操作 在其内部，用两个数组分别收集 DOM 的读和写函数：\n// https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L39 function FastDom() { var self = this; self.reads = []; self.writes = []; // ... } // https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L71 measure: function(fn, ctx) { var task = !ctx ? fn : fn.bind(ctx); this.reads.push(task); scheduleFlush(this); // ... } // https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L88 mutate: function(fn, ctx) { var task = !ctx ? fn : fn.bind(ctx); this.writes.push(task); scheduleFlush(this); // ... } 短短几行代码就已经完成了对批量 DOM 操作调度的初步实现，在这里需要重点关注 scheduleFlush() 的实现，其决定了所收集的 DOM 操作何时执行，并且是如何保证 UI 交互响应的及时性的。\n// https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L28 var raf = win.requestAnimationFrame || win.webkitRequestAnimationFrame || win.mozRequestAnimationFrame || win.msRequestAnimationFrame || function(cb) { return setTimeout(cb, 16); }; // https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L168 function scheduleFlush(fastdom) { if (!fastdom.scheduled) { fastdom.scheduled = true; fastdom.raf(flush.bind(null, fastdom)); } } // https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L185 function flush(fastdom) { var writes = fastdom.writes; var reads = fastdom.reads; var error; try { fastdom.runTasks(reads); fastdom.runTasks(writes); } catch (e) { error = e; } fastdom.scheduled = false; // If the batch errored we may still have tasks queued if (reads.length || writes.length) scheduleFlush(fastdom); // ... } // https://github.com/wilsonpage/fastdom/blob/master/fastdom.js#L58 runTasks: function(tasks) { var task; while (task = tasks.shift()) task(); } 对于调度的实现过程略微复杂，但代码看起来还是很简单的，利用 requestAnimationFrame() API 刷新 DOM 操作队列，尽最大可能保证帧率的稳定性，利用 fastdom.scheduled 标志位控制刷新队列的操作定期执行，防止短时间内出现“长任务”对帧渲染产生不利影响，而 requestAnimationFrame() API 的兼容性也做了特殊处理，回退到 setTimeout(cb, 16) 以保证实现尽可能接近原生 API。\n除此之外，FastDOM 还提供了一些其它的 API 增强开发的便利性和实用性，比如 clear() API 可以在必要时清空 DOM 操作队列，而 catch() 则可以统一处理捕获到的异常。\n结语 本文主要基于原生应用和框架/库应用在性能方面的差异进行分析，针对其核心因素批量 DOM 操作的合理调度，借一个真实的业务场景来说明如何手动调度 DOM 批量操作以实现高性能。本着不造轮子的原则，对 Google 文档中提及的 FastDOM 工具库的源码实现做了简单分析，以验证设想的实现思路。\n参考资源 https://developer.mozilla.org/en-US/docs/Web/Performance https://developers.google.com/web/fundamentals https://github.com/wilsonpage/fastdom https://web.dev/user-centric-performance-metrics/ https://caniuse.com/ "},{"section":"Blog","slug":"/blog/computer-technology/web/web-performance-case-1/","title":"Web 前端性能优化：案例分析 1","description":"Web 性能相关的概念很多，但如何落地在真实业务场景中，其实是一个比较难的事情，或者说机会鲜有，在这里记录一下真实业务案例做性能优化的过程。","date":"September 24, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 性能优化, 案例分析","tags":"计算机技术, Web前端, 性能优化, 案例分析","content":"能在真实业务场景中落地 Web 性能优化方案的机会鲜有，大多数时候业务是较为简单而且要求不高的，前段时间恰好有一个比较核心的业务，对稳定性和性能有一定的要求，在这个过程中也算是做了很多尝试和实践，在此作为案例记录一下分析的过程和最终解决的方案。\n业务情况与技术难点 首先，介绍一下业务的具体情况和存在的技术难点。这是一个移动端 WebView 渲染的页面，属于 App 的二级核心页面，用户量数十万，日均 UV 万人，金融资产相关，所以可以看得出来对页面的稳定性要求是比较高的；其次，页面布局分为上中下三部分，中部是一个长列表，页面整体可以竖向滚动。以 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;header /\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34; /\u0026gt; \u0026lt;footer /\u0026gt; \u0026lt;/body\u0026gt; 那么，重点来了，就是页面中部这个长列表是该页面的业务核心展示位置，这个长列表事实上类似于一个表格，在页面整体向上滚动过程中表头要做到吸顶效果，而表格内部是可以横向滚动的，且横向滚动过程中第一列（包括表头）要实现列冻结效果，说到这里如果了解 Excel 的行列冻结效果的话就很清楚了；其次，每一行作为一个列表项，列表项具有非常复杂的内部布局，且可以嵌套子项进行折叠交互，列表项存在 10% 用户会出现 1000+ 项的场景。以更细化的 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;header /\u0026gt; \u0026lt;main class=\u0026#34;long-list horizontal-scroll-container\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;row sticky-top\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer /\u0026gt; \u0026lt;/body\u0026gt; 以上，就是该业务的大致需求了，经过分析有以下几个技术难点：\n滚动吸顶效果（兼容、抖动问题） 长列表性能（虚拟列表） 列冻结效果（性能、交互流畅性） 表头的吸顶与列冻结效果结合（性能、抖动问题、交互流畅性） 列表项布局（嵌套布局、子项折叠交互） 列表数据动态更新 逐个击破 接下来，就是针对每个技术难点进行分析和攻克，这里主要记录一下当时的分析过程，后续也会看到多个难点的实现方式会互相产生影响，这也是该项目复杂的原因。\n滚动吸顶效果 对于吸顶效果，在目前移动设备已足够先进的情况下，其实老旧机型兼容问题倒不是最大的问题，所以 CSS 能解决当然是最好的。首先 CSS 属性 position:sticky 则可以很方便的实现滚动吸顶效果，经过尝试在主流设备上确实效果不错。作为一个覆盖了数十万用户的 C 端业务，有必要保证一定的兼容性，结果发现在 IOS 和一些比较老的安卓机型会出现问题，而社区并没有提供一个很好的 Polyfill 方案，所以只能换个思路，用 JS 来实现。\nhttps://caniuse.com/?search=sticky\nJS 实现滚动吸顶效果最简单的方式就是监听 scroll 事件，更改 position: fixed; top: 0px; 或者 position: relative; top: npx; 或者 transform: translateY(npx);，经过实践，第一种吸顶后滚动容器高度会塌陷，后两者则不会；但是，后两者这种方式在滚动过程中会很明显的发现有抖动现象，也就是说在滚动过程中不断的计算 Y 值然后更改，在视觉上给人一种很不稳定的感觉，体验并不好，而第一种的话可以给要吸顶的元素增加一个固定高度的父元素，保证吸顶后滚动容器高度不会塌陷。实现方式类似以下 DOM 结构：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sticky-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sticky-content\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div /\u0026gt; \u0026lt;div /\u0026gt; \u0026lt;div /\u0026gt; \u0026lt;/body\u0026gt; 在这里，sticky-content 就是要实现吸顶的元素，sticky-container 则充当占位符，防止滚动容器高度坍塌。不过，在实际测试过程中发现 IOS 的 scroll 事件有点问题，响应有一定的延迟，所以抖动现象非常明显。于是，引入 IntersectionObserver API 来替代监听 scroll 事件倒是一个很不错的想法，而且社区有提供 Polyfill 方案。经过实践，效果很理想。\n简单总结一下实现思路，利用 IntersectionObserver API 监听滚动过程中 sticky-content 元素出入视区并触发添加/取消 position: fixed; top: 0px; 样式实现吸顶，而 sticky-container 的高度需要根据子元素的高度进行实时测量并固定（可以利用 Resize Observer API 实现）以防止滚动容器 scroll-container 元素的高度坍塌。\n长列表性能 一般来说，在做开发方案的时候不应该过度设计，或者说过度优化，一旦决定要做比较复杂的实现方案就要有一定的数据依据。根据需求和产品给出的用户数据来看，页面中部的长列表有 10% 的用户展示列表项会超过 1000 个，也就是说长列表的性能是必须要考虑的事情。\n长列表的性能优化最典型的技术就是“虚拟列表”，而最典型又最简单的场景则是列表容器给一个固定高度，列表项高度固定。根据 UI 稿和交互稿来看，页面上中下的布局，滚动的是整个页面，而不是中部的长列表，而且这样的交互方式确实也更自然一些。所以，固定列表容器高度的“虚拟列表”方案是不合适的。除此之外，前面提到根据需求来看列表项具有比较复杂的逻辑，布局也较为复杂，列表项的高度也是不固定的，这就给实现虚拟列表带来一定的难度。\n分析到这里，社区著名的 react-window 虚拟列表组件及其相关的组件库均不能实现目前的需求，但提供了可变高度列表项的用例。此时，转变思路，既然长列表无法作为一个固定高度的滚动容器，那么将整个页面视为一个虚拟列表是否行得通？以 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container virtual-list\u0026#34;\u0026gt; \u0026lt;header /\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34; /\u0026gt; \u0026lt;!-- \u0026lt;main class=\u0026#34;long-list virtual-list\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;footer /\u0026gt; \u0026lt;/body\u0026gt; 经过简单的验证后，发现此方案行不通。首先，因为页面要调用客户端协议实现下拉刷新交互，发现页面容器固定高度为 100%，设置 overflow: scroll; 样式后下拉刷新的交互手势事件监听会出问题，客户端还不好解决；其次，整个页面作为虚拟列表，要把页面每个元素都作为列表项进行处理，反而还把问题变得复杂化了。于是，放弃此方案，寻找一种不固定滚动容器高度的虚拟列表方案。恰巧，发现 react-virtualized 有一个示例刚好符合这种场景：\nhttps://bvaughn.github.io/react-virtualized/#/components/WindowScroller\n基于此，也快速做了验证，效果还不错，但是马上就要面临下一个问题，在这种场景下怎么做到列冻结的效果？似乎又陷入了一个僵局。这个时候，去看了一下该示例的源码，想探究一下实现的机制，发现主要还是依赖于监听 scroll 事件。\n回过头来，重新分析需求和所提供的用户数据，10% 的用户展示列表项会超过 1000 个，而这 10% 的用户又可能所使用的设备偏中高端机型，即便如此，列表项的上限也仅会在千这个数量级，并不会上万。那么，一个页面渲染上千个 DOM 元素对于中高端机型来说倒不会有太大性能问题。根据 UI 稿来分析，一个列表所包含的 DOM 元素数量在 30-50 之间，如果有 1000 项，就会有 3w-5w 个 DOM 元素，性能压力很大；但是，假如让视区外的列表项仅渲染一个 DOM 元素做占位，此时整个列表的 DOM 元素数量会下降到 1000 - n + n(30-50)，而这个 n 则代表可在视区内展示的列表项个数，一般在 3-6 之间，这样 DOM 元素的数量急剧下降，性能压力得到极大的缓解。以 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;header /\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34;\u0026gt; \u0026lt;!-- screen top --\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- screen bottom --\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34; /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer /\u0026gt; \u0026lt;/body\u0026gt; 总结一下，这里主要解决两个问题：1. 滚动容器不能是固定高度；2. 列表项布局要足够灵活，可以实现列冻结效果。理想的“虚拟列表”实现需要同时处理滚动容器和列表项的逻辑，经过分析在有限的条件下可以实现一个“半虚拟化列表”。半虚拟化是什么意思呢？这里就要借鉴一下实现吸顶的方案了，让逃离视区的列表项并非不渲染任何 DOM 元素，而是渲染 1 个 DOM 元素做占位以自动撑开滚动容器的高度，虚拟掉列表项的子元素，而留下列表项容器元素做占位，自然而然的也就把问题的复杂度降低到只需要处理列表项的逻辑，而滚动容器的逻辑不再需要手动处理，由布局自动完成。具体实现可以借助 IntersectionObserver API 监听列表项出入视区，而利用 Resize Observer API 固定列表项容器元素的高度，这里还有一个小技巧应该给列表项容器元素给一个默认的高度（可以估算一个平均值）以撑开容器高度，这样可以降低滚动过程中布局偏移（LS）现象的影响以提高用户体验。以 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;header /\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34;\u0026gt; \u0026lt;!-- screen top --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- screen bottom --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer /\u0026gt; \u0026lt;/body\u0026gt; 在多次更换和验证实现长列表的方案时，除过用不同配置的真机设备和不同数量级数据的测试真实感受交互过程中卡顿外，最重要且可以量化性能指标的手段则是利用 Chrome 开发工具的 Performance 工具分析滚动交互过程中的帧率情况，包括出现的布局偏移（LS）现象频率，以及利用 Memory 工具分析内存消耗和稳定情况。\n列冻结效果 接下来就是在优化后的长列表中如何实现列冻结效果，上面提到的 react-virtualized 虚拟列表组件恰好也有一个相关的示例：\nhttps://bvaughn.github.io/react-virtualized/#/components/MultiGrid\n该组件官方示例也没有提供将非固定高度滚动容器和行列冻结效果相结合的用例，可见这并不是一个容易实现的效果。在粗略的看了一下该示例的源码和实现机制后，也略微有了一点思路，然后在网上查找了一下实现行列冻结效果的案例，基本上较为容易实现和处理且效果最好的就是双层叠加方案。以 DOM 结构说明：\n\u0026lt;div\u0026gt; \u0026lt;section class=\u0026#34;horizontal-scroll\u0026#34;\u0026gt; \u0026lt;!-- screen top --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- screen bottom --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;!-- screen top --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- screen bottom --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/div\u0026gt; 以上，长列表将渲染为两个容器 horizontal-scroll 和 overlay，前者实现横向滚动交互，后者则实现列冻结效果。具体的来说，两者 DOM 结构为镜像关系，overlay 通过绝对定位（position: absolute;）叠加在 horizontal-scroll 上层实现列冻结的效果，非冻结的列通过屏蔽交互（pointer-events: none; 和 opacity: 0;）就可以达到让下层处理横向滚动交互的效果。\n这样的实现方式是基于长列表优化之上，经过测试和验证，效果比较理想，也降低了实现过程中逻辑处理的复杂性。而且，相比于其它监听事件动态更新坐标值的实现机制，这种在交互流畅性方便更为稳定一些，用户体验相对更好。\n表头的吸顶与列冻结效果结合 起初，我们提到这几个技术难点也许单独解决并不难，但相互之间由于实现机制会产生影响，这就体现在长列表的表头既需要在竖向滚动时实现吸顶效果，还要在横向滚动时实现列冻结效果。起初，为了实现的简单性，将表头从长列表中抽离单独处理，以 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;sticky-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sticky-content sticky-top\u0026#34;\u0026gt; \u0026lt;section class=\u0026#34;horizontal-scroll-header\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left-header\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;section class=\u0026#34;horizontal-scroll-list\u0026#34; /\u0026gt; \u0026lt;section class=\u0026#34;overlay\u0026#34; /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/body\u0026gt; 在之前的基础上，利用 scroll 事件同步 horizontal-scroll-header 与 horizontal-scroll-list DOM 元素的横向滚动坐标 scrollLeft，而 sticky-left-header 则利用绝对定位（position: absolute;）固定叠加在 horizontal-scroll-header 上层实现列冻结的效果。当然，这个思路在实现的时候较为简单，但也存在一些问题，比如在 IOS 上利用 scroll 事件同步两个 DOM 元素的滚动坐标体检比较差，能明显感觉到两个滚动容器之间滚动的不同步性。\n后期，经过调整思路，决定将表头也放到列表中和列表项一样来处理，不同的是要做一些特殊处理。为什么这么做呢？具体去分析的话，其实竖向滚动引起的吸顶效果和横向滚动引起的列冻结交互不是同时触发的，也就是说表头可以存在两种不同的状态，第一种是竖向滚动的时候按之前的思路实现吸顶，此时因为 sticky-content 用了 position: fixed;top: 0px; 会脱离文档流，但 sticky-container 做了占位符（没有脱离文档流）还是可以跟随长列表横向滚动的，于是第二种状态就出现了，在长列表横向滚动的时候将 sticky-content 的固定定位样式去掉，转换为 sticky-container 的 transform: translateY(npx);，这个时候表头在不脱离文档流的情况下跟随长列表横向滚动就不再依赖 scroll 事件同步了。以 DOM 结构说明：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34;\u0026gt; \u0026lt;section class=\u0026#34;horizontal-scroll\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;sticky-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sticky-content sticky-top\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;sticky-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sticky-content sticky-top\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/body\u0026gt; 经过验证，在 IOS 设备上体验比之前要好很多。在实现时，两种状态的切换触发依赖于 scroll 事件和 IntersectionObserver API 的相互配合。\n列表项布局与数据动态更新 至此，基本上核心难点已经解决了，为什么不在社区提供的方案上做改造也是因为接下来面临的一个难题，列表项才是业务的核心展示位置，布局较为复杂，而且数据是动态的，各个列表项的布局不一定一致，所以自主实现的目的也是考虑到业务迭代灵活性。\n在之前实现的方案中，列冻结效果实现采用了双层 DOM 叠加的方式，这也在此处暴露出一个隐患，发现逻辑一旦处理不好，上下两层对应的 DOM 布局渲染的不完全一致的话整个列表上下两层就会出现错位的现象，这里的核心问题就是同一个列表项在上下两层渲染的 DOM 结构应该完全一致，这样才能保证高度相同列表不会出现错位情况。起初，解决这个问题的方式采用了利用 innerHTML API 将一层的 DOM 结构直接镜像过去，但也引入了交互逻辑的复杂性问题，而且在滚动过程中配合列表项虚拟化实时同步 DOM 结构严重影响了体验。后来，将这个问题做了简化，上下层列表出现错位的原因就是对应列表项的 DOM 高度（height）不一致，利用 Resize Observer API 则可以非常巧妙的解决这个问题，对一层 DOM 结构变化做监听，及时同步两层 DOM 占位元素的 height 属性，滚动交互的过程中体验是比较理想的。\n其次，数据的动态更新影响到列表项 DOM 结构的变动，也一并利用 Resize Observer API 做了统一处理，这样的话将一个很复杂的问题就以非常简单的方式解决掉了。\n那么，该页面最终整个的实现方案体现在 DOM 结构中的话就是以下：\n\u0026lt;body class=\u0026#34;vertical-scroll-container\u0026#34;\u0026gt; \u0026lt;header /\u0026gt; \u0026lt;main class=\u0026#34;long-list\u0026#34;\u0026gt; \u0026lt;section class=\u0026#34;horizontal-scroll\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;sticky-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row sticky-content sticky-top\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;!-- screen top --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- screen bottom --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;sticky-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row sticky-content sticky-top\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;!-- screen top --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column sticky-left\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- screen bottom --\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;placeholder\u0026#34; /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer /\u0026gt; \u0026lt;/body\u0026gt; 结语 这里主要是记录一下该业务遇到的一些技术难点，在解决这些技术难点时的分析过程和最终采取的方案，业务已经上线多月，用户体验较为理想。最后，想说的是，这些最终的解决方案是在综合考虑了业务复杂性、开发成本（时长、难度等）、用户最终体验效果等多个因素下产生的，在技术层面来说并没有达到最好的性能要求，在用户体验方面来说并没有照顾到全量的用户，但能满足多方的利益，后续还可以通过迭代来在细节处进行改进。\n还有一点觉得比较重要的是，在这里没有贴太多实现的代码（仅仅以 DOM 结构代码做示例），主要考虑的是技术难点的解决重要的是思路，如何把复杂问题简单化，把问题降维处理，以低成本投入获取高收益才是最重要的，至于代码实现的细节则在不同场景下取决于具体的业务，不具备普适性。\n参考资源 https://developer.mozilla.org/en-US/docs/Web/Performance https://developers.google.com/web/fundamentals https://web.dev/user-centric-performance-metrics/ https://developer.mozilla.org/en-US/ https://caniuse.com/ "},{"section":"Blog","slug":"/blog/computer-technology/nodejs/nodejs-spawn-vs-exec/","title":"Child process API: spawn vs exec","description":"使用 Node.js 编写一些脚本工具是非常方便的，而常用的 spawn 与 exec API 有什么不同呢？","date":"August 25, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Node.js, spawn, exec","tags":"","content":"利用 Node.js 编写一些命令行工具、一次性脚本是很方便的，而在这类场景下 child_process API 的 spawn 和 exec 方法的应用则非常常见。在我使用它们时，却不知道该如何进行选择，遂对此进行了探究。\nChild process API 先来看看 child_process API，根据官方文档描述：\nThe child_process module provides the ability to spawn subprocesses in a manner that is similar, but not identical, to popen(3). This capability is primarily provided by the child_process.spawn() function:\n其类似于 Linux 的 popen 命令行为，spawn 是其核心方法，通过创建一个管道（pipe），调用 fork 生成一个子进程，并执行 shell 命令。例如，通过该 API 就可以以编程的方式生成子进程并执行二进制文件，这在编写脚本工具时是一个非常常见的场景。\n在这里，主要讨论的是异步版本，当然 Node.js 为它们提供了相应的同步版本，例如 spawnSync 和 execSync。\nspawn 前面说到 spawn 是 Child process API 的核心方法，其实从源码可以一窥究竟：\n// https://github.com/nodejs/node/blob/v16.8.0/lib/child_process.js function exec(command, options, callback) { const opts = normalizeExecArgs(command, options, callback); return module.exports.execFile(opts.file, opts.options, opts.callback); } function execFile(file /* , args, options, callback */) { // ... const child = spawn(); // ... } // --- function fork(modulePath /* , args, options */) { // ... return spawn(options.execPath, args, options); } 可见，exec 和 fork 最终还是依赖于 spawn 的实现。而对于后者的实现：\nconst child_process = require(\u0026#39;internal/child_process\u0026#39;); const { ChildProcess } = child_process; function spawn(file, args, options) { // ... const child = new ChildProcess(); child.spawn(options); // ... } 依赖于底层的内部模块 internal/child_process 。\nspawn 的主要功能是生成一个子进程，并执行给定的命令，父子进程之间通过管道（pipe）传递 stdio 信息，而且默认不生成 shell。根据示例：\nconst { spawn } = require(\u0026#39;child_process\u0026#39;); const ls = spawn(\u0026#39;ls\u0026#39;, [\u0026#39;-lh\u0026#39;, \u0026#39;/usr\u0026#39;]); ls.stdout.on(\u0026#39;data\u0026#39;, (data) =\u0026gt; { console.log(`stdout: ${data}`); }); ls.stderr.on(\u0026#39;data\u0026#39;, (data) =\u0026gt; { console.error(`stderr: ${data}`); }); ls.on(\u0026#39;close\u0026#39;, (code) =\u0026gt; { console.log(`child process exited with code ${code}`); }); 父进程通过监听子进程相应的 stdio 事件进行通信。\nexec 前面根据源码可以看到 exec 的实现基于 spawn，但不同的是，前者在生成子进程的同时，会先生成一个 shell，然后在 shell 中执行给定的命令，子进程的输出信息会进行缓冲并最终传递给回调函数。根据示例：\nconst { exec } = require(\u0026#39;child_process\u0026#39;); exec(\u0026#39;cat *.js missing_file | wc -l\u0026#39;, (error, stdout, stderr) =\u0026gt; { if (error) { console.error(`exec error: ${error}`); return; } console.log(`stdout: ${stdout}`); console.error(`stderr: ${stderr}`); }); 父进程并非通过监听子进程的 stdio 事件，而是给子进程传递一个回调函数来获取子进程的输出信息。\n这里有一个显著的区别，exec 会先生成一个 shell 在执行命令，而 spawn 则会直接执行命令，但考虑到前者基于后者实现，事实上后者可以通过传递 options.shell 选项来选择是否生成 shell。\n官方文档有一句话也值得留意：\nUnlike the exec(3) POSIX system call, child_process.exec() does not replace the existing process and uses a shell to execute the command.\nexec 的 POSIX 系统调用的行为是，在当前进程中用新的进程映像（程序）替换旧的进程映像并执行，本质上并没有生成新的进程，也就不存在父子进程的概念。而在这里，Node.js 的 exec 方法的行为并不是替换进程映射，而是生成 shell 去执行命令。\nspawn vs exec 现在可以总结一下两者的显著区别：\nspawn 默认不生成 shell，而 exec 必然会生成一个 shell spawn 通过 stdio 事件流和父进程通信，而 exec 会对输出信息进行缓冲并通过回调函数将其传递给父进程，且后者默认有 1024 * 1024 字节的缓冲区限制 对于第一点，如果要执行的命令依赖于 shell 的一些功能，比如管道、I/O 重定向则选择 exec 会更便捷。对于第二点，对比示例代码，可以很明显的看出来，spawn 适合长时间执行的命令，且有持续的输出信息；而后者更适合执行短时的命令，且在命令执行完后一次性获取输出结果。\n工具库 execa 分析完它们两者的区别之后，这里推荐一个 npm 工具包 execa，其对 child_process 的方法进行了扩展和抽象，在很多常见的使用场景中大大减少了模板代码，也为调试提供了一定的便利性。看看文档中一段示例代码：\nconst execa = require(\u0026#39;execa\u0026#39;); (async () =\u0026gt; { // Catching an error try { await execa(\u0026#39;unknown\u0026#39;, [\u0026#39;command\u0026#39;]); } catch (error) { console.log(error); /* { message: \u0026#39;Command failed with ENOENT: unknown command spawn unknown ENOENT\u0026#39;, errno: -2, code: \u0026#39;ENOENT\u0026#39;, syscall: \u0026#39;spawn unknown\u0026#39;, path: \u0026#39;unknown\u0026#39;, spawnargs: [\u0026#39;command\u0026#39;], originalMessage: \u0026#39;spawn unknown ENOENT\u0026#39;, shortMessage: \u0026#39;Command failed with ENOENT: unknown command spawn unknown ENOENT\u0026#39;, command: \u0026#39;unknown command\u0026#39;, escapedCommand: \u0026#39;unknown command\u0026#39;, stdout: \u0026#39;\u0026#39;, stderr: \u0026#39;\u0026#39;, all: \u0026#39;\u0026#39;, failed: true, timedOut: false, isCanceled: false, killed: false } */ } })(); 上面的代码中，错误信息对于开发者来说是易读的，调试起来难度要小很多。\n更多的东西，建议直接看该 npm 包的文档进行详细了解。\n参考资源 https://nodejs.org/dist/latest/docs/api/child_process.html https://stackoverflow.com/questions/48698234/node-js-spawn-vs-execute https://www.hacksparrow.com/nodejs/difference-between-spawn-and-exec-of-node-js-child-rocess.html https://linuxhint.com/linux-exec-system-call/ https://2ality.com/2022/07/nodejs-child-process.html https://github.com/sindresorhus/execa "},{"section":"Blog","slug":"/blog/computer-technology/web/tools-web-fee-test-with-jest-puppeteer/","title":"使用 Jest 和 Puppeteer 构建 Web 自动化测试平台","description":"谷歌发布的 Puppeteer 工具和脸书发布的 Jest 测试工具为 Web 端到端测试提供了极大的便利，这里记录了如何使用它们构建一个 Web 自动化测试平台。","date":"August 15, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 工具, 测试, Jest, Puppeteer","tags":"计算机技术, Web前端, 工具, 测试, Jest, Puppeteer","content":"测试为软件的稳定和完善提供了必要的支持，Web 前端开发领域相比于做单元测试，端到端测试更有意义和价值。谷歌发布的 Puppeteer 工具和脸书发布的 Jest 测试工具为 Web 端到端测试提供了极大的便利，这里记录了如何使用它们构建一个 Web 自动化测试平台。\n技术预研 在本地跑通测试流程是首要解决的问题，在日常项目的脚手架中已经做了很多这方面的工作，而且从头开始来做也没有太大难度，基本上按官方文档步骤来做即可。直接使用 Jest 和 Puppeteer 做测试也是可以的，不过要繁琐很多，借助 jest-puppeteer 这个 npm 包可以简化很多流程，测试代码也要简略的多。\n需求分析 Web 端到端自动化测试平台要求用户可以通过 Web UI 上传测试脚本代码到服务器，而服务器可以定时运行上传的测试脚本获取结果日志并存档，通过对整个流程分析可以确定有以下几个技术难点：\nJest 和 Puppeteer 的服务端测试运行环境构建（版本管理） 用户测试脚本不可信，需要沙箱机制 数据传输涉及到 Buffer，用 HTTP 还是 WebSocket 脚本定时运行的任务调度 搞清楚需求和相应的技术难点后，可以先看看业内有没有解决方案可以参考。\nWeb 端到端自动化测试平台功能需求\n市场调研 根据调研的情况来看，在好几年前已经有很多人在做类似的方案，但是很少有成熟的方案，仅限于本地测试（玩具项目），分析一方面原因是当时各个技术都不太成熟，另一方面当时端到端测试愿意开源的也不多。但在调研过程中收获还是不少的，有很多方面也印证了我对技术架构的构想。下面来简单的介绍一下业内可供参考的方案，有些是完整的方案，有些则仅涉及某些环节。\n首先，解决如何构建 Jest 和 Puppeteer 的服务端测试运行环境（我称之为 Test Runner Server）。服务器的环境大多都是 Linux 系统，Puppeteer 官方文档也提供了如何在 Linux 中安装和使用，事实是要比在本地的 Windows 环境中麻烦得多，当然这个麻烦也源于另一个事实：Puppeteer 版本和 Chromium 的版本严格相关。那么问题又变得复杂了起来，如何构建支持多个 Puppeteer 版本的测试运行环境？隔离多个版本测试运行环境之间的影响可以利用虚拟机，在如今云的时代，Docker 则成了最佳选择，官方文档也有提及，谷歌官方也用 Docker 构建了 Puppeteer 的测试运行环境作为 CI/CD 的流程。在社区也找到了有人维护的 Puppeteer 的 Docker 镜像：\nhttps://github.com/buildkite/docker-puppeteer\n由于我们用的是 node:lts-alpine 基础镜像，所以根据 Puppeteer 官方文档安装了相应依赖，但依赖包在国外所以更换了镜像源，这里要注意的是刚开始换的是 HTTP 源，发现安装总是失败，最终换了 HTTPS 源后，安装几秒完成：\n# https://mirrors.ustc.edu.cn/help/alpine.html RUN sed -i \u0026#39;s/http:\\/\\/dl-cdn.alpinelinux.org/https:\\/\\/mirrors.ustc.edu.cn/g\u0026#39; /etc/apk/repositories 安装好环境后，运行测试又出现了问题，参考官方文档在启动参数中添加了 --no-sandbox 参数后在 root 用户下测试可以运行成功，但因为安全原因，很少会在 docker 中使用 root 用户运行程序，换成非 root 用户运行测试也是成功的。但是，官方文档提到在 root 用户环境下 必须使用--no-sandbox 禁用沙箱，而且是有安全风险的，想着在非 root 用户环境下去掉该启动参数应该就行了，发现测试会运行失败，根据官方文档的解决方案和调研，发现很多人都遇到该问题，而且最终没有很好的解决方案，暂时就把这个问题搁置了。\n接下来，第二个技术难点在于运行用户提交的测试脚本是有风险的，所以在运行测试脚本代码时必须有沙箱机制保证一定的安全。刚开始发现社区有人使用了 vm2 这个 npm 包来解决运行不可信任代码的安全问题，而且恰好也有人用该模块来尝试结合 Docker 在云端运行 puppeteer 测试：\nhttps://github.com/ebidel/try-puppeteer\n但最终发现这并非最佳的解决方案，而且在编码上略显复杂，服务端代码与测试运行环境在同一个系统环境下，有安全风险，也耦合严重。所以，为了实现可以将多个版本的测试运行环境隔离，同时降低安全风险，采取将测试运行环境与后端服务拆分，采用 Node Server + Test Runner Server 的技术架构。这样的好处是，如果测试任务较多，可以很方便的横向扩展 Test Runner Server 节点，不同的节点也可以部署不同版本的 Puppeteer，方便后期维护迭代过程中不断升级测试运行环境又不影响已有的测试任务运行。\n这个过程中也了解了 Jest 运行测试的底层原理，实际上 Jest 运行测试时为了隔离上下文环境也利用了 Node.js 的核心模块 vm。\nhttps://cpojer.net/posts/building-a-javascript-testing-framework\n接下来就是数据传输通信的协议选择，通常我们会用 HTTP(S) 的常规方案，但是经过分析，测试代码用户可能以文件的形式提交，后端服务需要将测试代码保存成文件，后续又需要把测试代码文件发送到 Test Runner Server 运行测试，最终又需要把运行日志发送到后端服务保存成文件，涉及到 Buffer 数据的传输，还有可能需要传输实时的日志到客户端（Web UI），看起来选用 WebSocket 是再合适不过了。\n最后就是定时运行测试脚本的任务调度了，经过调研发现成熟的方案也有很多，包括持久化，最终决定采用类 Cron 的方案。\n在调研过程中，还发现一篇文章介绍了利用 puppeteer-cluster 这个 npm 包来搭建测试集群完成性能任务，对于我来说也很有参考价值。\nhttps://stackchat.com/blog/puppeteer-cluster-performance-testing\n技术架构 在经过详细的市场调研后，最终确定了一个比较理想和完整的系统技术架构。\nWeb 端到端自动化测试平台系统技术架构\n系统实现 完成技术预研后，就需要进行实际的编码实现了，在本地开发过程中为了方便和不污染本地环境，也是直接将 Puppeteer 安装在 Docker 内运行一个 Runner Server 来进行开发。目前，仅仅是完成了一个测试 Demo，具备用户在 Web UI 可以编辑代码进行提交直接运行和查看运行结果日志，以及提交测试代码创建任务，Node Server 服务负责任务调度定时运行测试脚本，并管理测试日志，Web UI 浏览任务列表和历史测试日志的基本功能。Web UI 与 Node Serve 的 WebSocket 通信使用了 socket.io npm 包，因为其继承了 Event 模块，可以很方便的管理不同类型的事件，比起在 message 事件的传输数据中维护额外通信类型要方便的多，而且也提供了开箱即用的鉴权功能；Node Server 与 Test Runner Server 的 WebSocket 通信使用了 ws npm 包，因为其通信较为简单，而该模块也足够简单轻量；任务调度则使用的 node-schedule npm 包，其提供了类似 Cron 的定时任务机制，但是其无法持久化，目前也是仅作为测试 Demo 的方案。\n以下是 Test Runner Server 的 Dockerfile：\n# see docs: https://docs.docker.com/engine/reference/builder/ FROM node:lts-alpine # https://mirrors.ustc.edu.cn/help/alpine.html RUN sed -i \u0026#39;s/http:\\/\\/dl-cdn.alpinelinux.org/https:\\/\\/mirrors.ustc.edu.cn/g\u0026#39; /etc/apk/repositories # install dependencies RUN apk update \\ \u0026amp;\u0026amp; apk add --no-cache --virtual .build-deps curl \\ \u0026amp;\u0026amp; curl -sf https://gobinaries.com/tj/node-prune | sh \\ \u0026amp;\u0026amp; apk del .build-deps # https://github.com/nodejs/docker-node/blob/main/docs/BestPractices.md#handling-kernel-signals # https://github.com/krallin/tini#using-tini # Add Tini RUN apk add --no-cache tini ENTRYPOINT [\u0026#34;/sbin/tini\u0026#34;, \u0026#34;--\u0026#34;] # puppeteer start -------------------------------- # https://github.com/puppeteer/puppeteer/blob/main/docs/troubleshooting.md#running-on-alpine # https://github.com/puppeteer/puppeteer#q-which-chromium-version-does-puppeteer-use RUN apk add --no-cache \\ chromium \\ nss \\ freetype \\ harfbuzz \\ ca-certificates \\ ttf-freefont # Tell Puppeteer to skip installing Chrome. We\u0026#39;ll be using the installed package. ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true \\ PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser # # Puppeteer v6.0.0 works with Chromium 89. # RUN yarn add puppeteer@6.0.0 # # Add user so we don\u0026#39;t need --no-sandbox. # RUN addgroup -S pptruser \u0026amp;\u0026amp; adduser -S -g pptruser pptruser \\ # \u0026amp;\u0026amp; mkdir -p /home/pptruser/Downloads /app \\ # \u0026amp;\u0026amp; chown -R pptruser:pptruser /home/pptruser \\ # \u0026amp;\u0026amp; chown -R pptruser:pptruser /app # # Run everything after as non-privileged user. # USER pptruser # puppeteer end -------------------------------- ENV NODE_ENV=production ENV WS_RUNNER_PORT=8081 EXPOSE 8081 WORKDIR /home/node/app COPY package.json package-lock.json ./ RUN npm ci --production --registry=https://registry.npm.taobao.org/ \u0026amp;\u0026amp; npm cache clean --force RUN node-prune COPY . . RUN chown -R node:node /home/node/app/ # https://github.com/nodejs/docker-node/blob/main/docs/BestPractices.md#non-root-user USER node # https://github.com/nodejs/docker-node/blob/main/docs/BestPractices.md#cmd CMD [ \u0026#34;node\u0026#34;, \u0026#34;index.js\u0026#34; ] 此外，在 Node 项目中我们采用了 ECMAScript modules 编写整个项目代码，而 jest-puppeteer npm 包不支持 ES Module，最终发现可以配置环境变量指定配置文件来解决：\nJEST_PUPPETEER_CONFIG=jest-puppeteer.config.cjs 而且，目前 Jest 默认也是以 CommonJS 方式运行的，需要额外指定 Node 参数（flag）才行，这个官方文档也有提及：\nnode --experimental-vm-modules node_modules/.bin/jest 其次为了日志管理和处理的方便，生成结构化数据才是比较理想的，可以通过 Jest 的 --json 命令行选项将其输出的日志由纯文本更改为 JSON 格式；加上 --passWithNoTests 选项可以保证没有测试可运行时不报错。\n其它参考资源 https://jestjs.io/ https://developers.google.com/web/tools/puppeteer/ https://github.com/smooth-code/jest-puppeteer https://en.wikipedia.org/wiki/Cron "},{"section":"Blog","slug":"/blog/computer-technology/web/web-performance-core-concepts/","title":"Web 前端性能优化：核心概念与指标","description":"在一些较为复杂的 Web 应用中可能会出现性能瓶颈，导致用户体验急剧下降，做优化之前更应该了解一下相关的核心概念，从而在出问题时确定优化路径。","date":"July 19, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 性能优化, 核心概念","tags":"计算机技术, Web前端, 性能优化, 核心概念","content":"说到 Web 的性能优化，可能很多时候我们采取了一些措施，看到了肉眼可见的改进，如果我们可以对其进行测量，确定我们改进的效率（百分比）是不是会更有意义？换句话说，如果我们了解性能瓶颈可能发生的位置，衡量用户体验好坏的指标，做到实时追踪性能变化，我们是不是可以更迅速的采取优化措施？在应用上线前，我们就可以做一些低成本而有高收益的优化工作，进一步提升用户体验。\n所以，这里主要介绍一下 Web 性能相关的核心概念和相关指标。\n谷歌作为力推 Web 技术的科技巨头，不仅提供了出色的 Chrome DevTools，更是贡献了高质量的开发文档，为业界引进了众多先进的理念，先来拜读一下下面这篇文章，搞明白为何我们需要对 Web 网站做极致的优化？\nWhy does speed matter?\nRAIL 性能模型 RAIL 是一个由谷歌提出的以用户为中心的性能模型，将用户体验分解为关键操作，帮助开发者为每个操作定义性能目标。RAIL 代表\nWeb 应用程序生命周期的四个方面：\nResponse（50 毫秒内处理事件） Animation（10 毫秒内生成一帧） Idle（最大化空闲时间） Load（交付内容并在 5 秒内可交互） 括号中表示推荐的性能目标，是我们在开发 Web 应用时务必要满足的，这样才能保证良好的用户体验。RAIL 性能模型本质上是提出了一个简单而有效的衡量性能的方法，并给出一个推荐的目标，至于可能发生性能瓶颈的关键点和如何去达到优化目标则没有提及太多。\nhttps://web.dev/rail/\n关键渲染路径 关键渲染路径（Critical rendering path）是一个核心且基础的概念，描述了浏览器将 HTML、CSS 和 JavaScript 转换为屏幕上的像素所经历的一系列步骤。其影响最大的是页面首次加载的渲染性能，其次是页面复杂交互的渲染性能。\n简单的来说，关键渲染路径主要为以下几个步骤：\n下载完 HTML 文件开始解析，构建文档对象模型（DOM）和 CSS 对象模型（CSSOM）； 将 DOM 和 CSSOM 树合成渲染树（Render tree），DOM 代表内容，CSSOM 代表样式； 构建好渲染树，开始布局（Layout ）计算，确定元素在页面上的位置和尺寸，以及元素之间的位置，输出“盒模型”； 完成布局计算后，就可以将渲染树中的每个节点转换成屏幕上的实际像素，即**“绘制（Paint）”或者“光栅化（Rasterization）”**。 理解了有哪几个步骤之后就可以围绕这些来做优化了，各个步骤具体的内容以及可能带来的性能瓶颈看下方文档更能容易理解一些，在这里不再赘述。\nhttps://developer.mozilla.org/en-US/docs/Web/Performance/Critical_rendering_path\nhttps://developers.google.com/web/fundamentals/performance/critical-rendering-path\n能深刻理解关键渲染路径的概念，就会对 Web 性能优化有了一个比较清晰的认识，因为页面完成初始化后，后续用户交互造成的页面结构布局发生的变化主要就体现在布局（Layout ）计算与**重绘（Repaint）**这两个方面，性能瓶颈也由此产生。\npixel pipeline 现代 Web 网站或者应用具备丰富的动态交互能力，这就意味着页面是随时间和用户交互触发在动态变化，其中某一时刻的状态我们称之为帧（frame），多个连续的帧状态组合在一起就实现了动态效果（动画）。而要保证交互的流畅性，我们就得了解帧率（frame rate）这个概念，它表示连续帧的变化速率，尽可能与显示设备的刷新率（通常为 60 次/秒）保持一致，理想情况下每一帧花费的时间为 16 毫秒左右（1 秒 / 60 = 16.66 毫秒），实际上由于系统有额外的工作要做，时间会更短。为了优化帧率达到理想状态，我们需要了解浏览器在每一帧都涉及哪些工作，即像素管道（pixel pipeline）：\n执行 JavaScript 样式计算（Style） 布局（Layout） 绘制（Paint） 合成（Composite） 以上步骤就是每一帧所要做的工作，优化的手段就是降低每个步骤的耗时。可以看出，实际上这是关键渲染路径中提到的布局与重绘更细化的表示。不过值得注意的是，并不是每一帧都要历经以上所有的步骤，在某些情况下可以跳过某些步骤，这就给了我们优化帧率的一个突破口。详细的内容查看下面谷歌开发者文档，图文介绍直观易懂，还有参考文档也值得收藏。\nhttps://developers.google.com/web/fundamentals/performance/rendering#the_pixel_pipeline\nhttps://csstriggers.com/\nhttps://gist.github.com/paulirish/5d52fb081b3570c81e3a\n动画性能 谈到帧率的时候，我们很容易会想到动画，60 FPS（frame per second）是实现动画的一个核心性能目标。实现动画有两种方式：CSS 和 JavaScript。\nCSS 实现动画较为简单，一般来说性能也最佳，有几个值得注意的地方：\n尽量用 transform（3d）和 opacity 实现动画，在大多数渲染引擎中它们不会触发布局和绘制 可以利用 will-change（或者 translateZ）CSS 属性来触发创建新的 GPU 层，优化性能，但不要滥用 减少绘制区域和降低绘制的复杂性 而利用 JavaScript 实现动画灵活性更大，也能实现更复杂的动画效果，也有几个需要注意的地方：\n用 requestAnimationFrame 实现动画，避免使用 setTimeout 或 setInterval 避免发生强制同步布局和布局抖动 对 JS 处理函数进行去抖动和节流优化 可以把复杂的 JS 计算放入 Web Worker 线程执行 以上只是对一些核心要点的总结，具体的内容查看下列文章进行了解。\nhttps://developer.mozilla.org/en-US/docs/Web/Performance/Animation_performance_and_frame_rate\nhttps://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas\nhttps://developer.mozilla.org/en-US/docs/Web/Performance/CSS_JavaScript_animation_performance\nhttps://developers.google.com/web/fundamentals/performance/rendering/optimize-javascript-execution\nhttps://developers.google.com/web/fundamentals/performance/rendering/avoid-large-complex-layouts-and-layout-thrashing\nhttps://developers.google.com/web/fundamentals/performance/rendering/debounce-your-input-handlers\nWeb Vitals Web Vitals 是谷歌提出的一项计划，用来量化现代网站的用户体验，是对网站性能的一种侧面但又直接有效的反映。换句话说，谷歌对纷繁复杂的性能指标进行了综合分析，最终抽象出了 Web Vitals 所包含的多个简化指标。其中最被重视的有三个指标，称为 Core Web Vitals，也就是核心指标：\nLargest Contentful Paint (LCP)：测量加载性能； First Input Delay (FID)：测量交互性； Cumulative Layout Shift (CLS)：测量视觉稳定性。 **核心指标更多的反映的是网站初始化加载过程的用户体验（性能），**谷歌作为搜索巨头，其提出的 Web Vitals 主要目的是为搜索业务服务。其余指标也主要以测量加载性能为主，算是作为核心指标的一种辅助决策工具。\n当然，谷歌不仅提出了分析指标，还提出了优化方案，以及提供了众多工具，详细内容查看下方官方文档即可。\nhttps://web.dev/vitals/\nhttps://github.com/GoogleChrome/web-vitals\n布局偏移（LS） 累积布局偏移（Cumulative Layout Shift，CLS）作为核心指标之一，其特殊的是在页面初始化完成后也可以继续追踪用户交互过程中的布局偏移（Layout Shift，LS）现象。\n如何理解布局偏移现象？最典型的例子就是，当用户打开一个页面向下滚动过程中遇到一个还未加载完成的图片资源（此时图片没有高度），继续向下滚动时图片加载完成的瞬间页面高度被撑开，用户就会有瞬间的页面下坠感，而这种感觉会随着图片高度的大小成正比增长。有时候我们也称之为“页面抖动”，其对用户体验带来巨大的伤害，必须被重视。\nCLS 相关的详细内容阅读下面的文章了解即可，文末也对如何改进 CLS 问题提供了一些建议。虽然目前提供了一些可以用来测量 LS 的 API，但终究还是调试起来不方便，好消息是 Chrome 88 版本在 DevTools 中加入了对 LS 现象的测量功能，查看下面第二篇文章了解。\nhttps://web.dev/cls/\nhttps://developer.chrome.com/blog/new-in-devtools-88/#web-vitals\n缓存 缓存（Cache）对 Web 应用是至关重要的，因为 Web 应用对网络状况的好坏异常敏感，利用缓存可以降低网络波动带来的用户体验下降的影响。\nWeb 应用不像原生应用程序那样，用户安装到本地后，后续使用大部分资源将直接从本地加载，不受网络状况的影响；而 Web 应用在用户每一次使用时所有的资源都必须重新从网络获取，这就导致过于依赖网络状况，不过利用缓存我们可以做大量的优化工作，根据 Web 应用的生命周期来划分，缓存也可以分为以下几类：\nHTTP 缓存：请求缓存，主要依赖于浏览器客户端（Cache-Control 和 Expires） 版本缓存：利用 webpack 等打包工具对特定版本的静态资源做长期缓存策略 数据缓存：有一系列 API 提供了在客户端进行临时或者持久化的数据缓存（例如 localStorage、sessionStorage、indexedDB 等） 当然，以上列举的只是一些典型的缓存手段，针对不同的场景可以灵活运用多种缓存策略做优化。\nhttps://developers.google.com/web/fundamentals/performance/get-started/httpcaching-6\nhttps://web.dev/http-cache/\nhttps://developers.google.com/web/fundamentals/performance/webpack/use-long-term-caching\nhttps://developers.google.com/web/fundamentals/instant-and-offline/web-storage\n渐进式 Web 应用 渐进式 Web 应用（Progressive Web Apps，PWAs） 的目标是为跨平台的 Web 网络应用带来类似原生应用程序的用户体验，是一种应用的设计模式。其主要依赖于 Service Worker API 实现资源缓存，在离线的网络状况下也能正常为用户提供部分功能，且能将 Web 应用以类似原生应用的方式安装到用户桌面。一个复杂的 PWA 的资源缓存并不好处理，鉴于此 Chrome 团队开发了 Workbox 工具来简化这部分工作，以帮助开发者更容易的构建和管理 PWA。具体详细内容查看下方文档。\nhttps://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps\nhttps://web.dev/progressive-web-apps/\nhttps://developers.google.com/web/tools/workbox\nWorkbox 工具的缓存策略值得探究，可以作为实现其它缓存方案的思想借鉴。\nPRPL 模型 PRPL 模型是一种交互设计模式，目标是让网页加载的更快，其建议：\n（Push）预加载或者推送最重要的资源 （Render）初始的路由页面渲染应该尽可能快 （Pre-cache）预缓存后续将要加载的资源 （Lazy load）延迟加载其它路由页面和非关键性资源 可以说，PRPL 模型是对整个 Web 站点生命周期中核心路径上所做优化的总结，对设计优化的 Web 站点具有指导意义。\nhttps://web.dev/apply-instant-loading-with-prpl/\n参考资源 https://developer.mozilla.org/en-US/docs/Web/Performance https://developers.google.com/web/fundamentals https://web.dev/user-centric-performance-metrics/ "},{"section":"Blog","slug":"/blog/computer-technology/nodejs/nodejs-fastify/","title":"Fastify框架 - 专注于性能和低内存消耗","description":"Fastify 作为一个 Node.js Web 框架，是如何实现高性能和低内存消耗的呢？?","date":"June 27, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Node.js, Fastify","tags":"","content":"最近在做 Node.js 技术相关的调研，需要选定一个 Web 框架作为基础来构建业务。一般来说，首选开源方案，对于我来说，比较关注框架背后的开发团队情况、项目活跃度、是否有足够多的商业案例、文档是否完整可读、框架的设计理念、技术架构是否灵活可扩展、技术社区生态是否完整等方面。目前，我比较倾心的是 Fastify 这个新兴框架，根据官网介绍，其专注于高性能和低消耗，并且公开的基准测试表现相当不错，项目足够活跃，更重要的是属于 OpenJS 基金会的孵化项目。本文主要介绍 Fastify 的设计理念和探究其是如何提高性能和降低内存消耗的。\nFastify 官网：https://www.fastify.io/\nFastify v1.0.0 发布是在 2018 年的 3 月份，相比于业内广为熟知的 Express / Koa 等框架还很年轻，其项目发起者和核心维护者之一 Matteo Collina 也在开源社区很有声望，是 Node.js TSC 成员，目前 Fastify 项目已经加入 OpenJS 基金会。\nFastify 到达 1.0.0 LTS！\nFastify 作为孵化项目加入 OpenJS 基金会\nFastify：毕业、性能和未来\n设计理念 一般来说，一个开源项目会在文档中阐述自己的设计理念和技术架构等理论层面的思考，以帮助开发者更快的了解项目的核心思想和目标人群，或者说解决的关键性问题。官网首页首先给出了标题为 Why 的一段话，然后列举了核心功能点（Core features），文档中没有找到具体阐述设计理念之类的东西。不过，在看了官方博客文章以及相关的资料之后，Fastify 的设计理念大体可以总结：\n高性能 灵活可扩展 开发人员友好（例如内置日志系统、TS 支持等等） 纵观众多 Node.js Web 开源框架，大多都做到了后两点，例如 Express 项目利用中间件提供了足够的灵活性，内置了开箱即用的功能；而 Koa 为了改进开发人员的体验，引入 async/await 替代回调函数，以及所谓的 “洋葱模型” 提供了更高的灵活性，精简了框架核心，只提供必要的功能，从而有了比 Express 更好的性能。而 Fastify 除此之外，对性能有极致的追求，同时也提出了很多不一样的思想，值得学习。\n其实，Web 开发框架还有一个较为严峻的问题就是项目的工程化标准，最著名的就是 MVC 模型，而对应的也有解决此类问题的 Node.js 框架，近年来发展前景比较好的应该就是 nest.js 了。\nIntroducing Fastify, a Speedy Node.js Web Framework\nFastify 的实现细节 了解了 Fastify 的设计理念之后，接下来要看看开发团队是如何实施的，探索其技术细节。\nJSON 序列化 Fastify 项目的历史故事背后是 fast-json-stringify 模块的诞生，该模块比 JSON.stringify() 这种原生 JavaScript 方法快很多，可以达到 2 到 3 倍的性能优势。其背后的原理主要是 依赖 JSON Schema 对 JSON 数据进行校验，避免了类型判断的过程，从而提高了性能。根据其公开的基准测试，其优势主要体现在处理的目标数据为复杂对象时，可以达到 4 倍的性能优势。\nGitHub: fast-json-stringify\nJSON Schema\n其中有两个细节我们值得注意。第一个便是项目 README.md 文件中提到的安全方面需要注意的问题，是由于 在初始化时利用 Function 构造函数预编译了函数体，以此达到优化性能的目的。\nresult = new Function(\u0026#39;schema\u0026#39;, code)(root); 而这个原理其实也是比较好理解的，通过把一个函数体内包含循环迭代的代码预先“编译”成字符串再交给函数来执行，在函数的“运行时”就不需要再做额外的“解释翻译”以及迭代工作，从而提高性能。下面有一篇相关的比较有趣的文章可以看看：\nFaster than C? Parsing binary data in JavaScript.\n我们也可以通过以下示例代码来进行简单的测试：\nfunction a() { for (let i = 0; i \u0026lt; 3; i++) { console.log(i); } } const code = [0, 1, 2].map((i) =\u0026gt; `console.log(${i})`); // 函数体预编译后 b 等价于 // function b() { // console.log(0); // console.log(1); // console.log(2); // } const b = new Function(code); console.time(\u0026#39;a\u0026#39;); a(); console.timeEnd(\u0026#39;a\u0026#39;); // a: 0.136962890625 ms console.time(\u0026#39;b\u0026#39;); b(); console.timeEnd(\u0026#39;b\u0026#39;); // b: 0.05908203125 ms 第二个细节便是 README.md 文件中有提到可以和 flatstr 模块很好的配合使用，因为该模块会触发 V8 的优化机制，把字符串最终转换成了 Buffer。 其项目的 README.md 文件中 How does it work 段落详细解释了底层机制，简单的来说，V8 会在某些情况下针对 String 数据做特定优化，而该模块的主要作用就是主动去触发这种 V8 的优化机制以达到提高性能的目的。\nGitHub: flatstr\n路由（Routing） Fastify 的路由是依赖 find-my-way 模块实现的，在公开的基准测试中相比于 express 和 koa-router 有数倍的性能优势。\n根据 find-my-way 模块的 README.md 文件中所介绍，其 底层采用了基数树（Radix tree，亦称 compact prefix tree）的数据结构，并非通常的路由数组和迭代正则匹配方案。基数树是一种空间优化的前缀树（即紧凑前缀树），具有前缀树的搜索性能同时尽可能小的占用内存。前缀树的应用场景比较常见，常用于字符串检索，例如字典查找、字符统计、公共前缀匹配等等，要比遍历数组和正则匹配的查找性能好数倍。但前缀树的内存消耗比较大，所以通过将只有一个子节点的与其父节点合并从而减少内存消耗，形成了“基数树”数据结构。\nGitHub: find-my-way\nRadix tree\nKoa 的官方路由 @koa/router 从源码中可以看到，是将每个路由的路径 path 转换成正则表达式存储在数组中，此后遍历该数组通过正则匹配来完成路由映射，这种方案实现起来相对简单，但性能要低得多。不过也有一个同样基于基数树结构实现的 koa-tree-router 模块，性能比前者高数倍，当然它的功能还是相当简单的。Express 的官方路由实现也大致相同，@koa/router 应该是参考了前者的实现。\n闭包（Closure） 闭包是 JavaScript 一个很有用的语言特性，利用它可以实现很多东西，最常见的则是模块封装了，在没有类（Class）概念的情况下，要实现类似类的效果必然会用到闭包，很多第三方库就是这样做的，例如著名的 jQuery。但另一方面需要注意的是，闭包极易引起内存泄漏，同时造成不必要的内存消耗；而且，在闭包中如果嵌套太深，作用域递归解析也会有一定的开销。\nfunction process(bigData, cb) { remoteCall(bigData, function (err, something)) { storeSomething(something, function (err, res) { // 该函数是暂时的，但是难以被优化 // bigData 一直驻留在作用域中，无法被 GC cb(null, res * 2) }) } } // ------- function process(bigData, cb) { remoteCall(bigData, function (err, something)) { // bigData 在这里退出了作用域，可以被 GC callStoreSomething(something, cb) } } function callStoreSomething(something, cb) { // 该函数可以被优化 storeSomething(something, function (err, res) { cb(null, res * 2) }) } 基于此，Fastify 团队在框架内部基本上杜绝了利用闭包实现功能，从而保证了低内存消耗。\nJavaScript: Closures and the Call Stack\nScope\n调用栈（Call stack） Fastify 内部优化之后，调用栈也小很多，作者利用 0x 工具进行了分析，从生成的栈火焰图来看，Express 的图形中有两个高峰，说明调用栈特别大；相对的，Fastify 的图形总体较为平缓。更小的调用栈也降低了内存消耗，详细信息可以在下面的视频讲解中查看。\nTake your http server to ludicrous speed\nGitHub: 0x\nCall stack\n服务器的生命周期（Server Lifecycle） 大多数 Web 框架的生命周期是相似的：服务器启动，路由处理程序注册，服务器侦听请求并调用适当的函数来处理它们。如下图所示，Fastify 做了特殊处理，在服务器启动之后执行预初始化阶段（preinitialisation ），该阶段做了一些优化工作，使用 fast-json-stringify 模块处理 JSON schemas，以及用 reusify 模块优化处理函数（handler functions）。\n这里提及的 reusify 模块是如何来优化处理函数的呢？首先，请求的处理函数属于频繁被执行的代码块，也就是所谓的\u0026quot;热代码路径（hot code paths）\u0026quot;。reusify 的源码非常简单，主要作用是 将对象或者函数进行缓存，降低高并发场景下热代码路径上的 GC 压力。\nReaching Ludicrous Speed with Fastify\nGitHub: reusify\nAvoid allocations in compiler hot paths” Roslyn Coding Conventions\n不过，在 reusify 模块给出的示例代码中有一个细节值得注意：\n// ... function MyObject () { // you need to define this property // so V8 can compile MyObject into an // hidden class this.next = null // ... 作者注释到你要重用的对象内部第一个属性应该定义为 next，因为可以触发 V8 的优化机制 “隐藏类（hidden class）”。首先，隐藏类是 V8 内部为了优化非整数索引属性（命名属性）的访问速度的机制，每一次对对象命名属性的增删操作都会导致新的隐藏类被创建，而具备同样的命名属性定义顺序的对象可以共享隐藏类，减少开销。接下来，通过查看 reusify 模块的源码便可知道，模块内部为了实现缓存队列给被重用的对象添加了一个 next 属性，由此便可以明白作者的注释是告诉我们如何利用好 V8 的内部优化机制 —— 隐藏类。\nFast properties in V8\nV8 Hidden class\nClearing up the hidden classes concept of V8\nShould I put default values of attributes on the prototype to save space?\n插件模型（Plugin Model） Fastify 的灵活扩展主要依赖于其插件系统，同时也支持 Express 中间件（需要 middie 插件），可以说是 Express 与 Hapi 的组合。在探究 Fastify 的插件模型之前，先来看看 Koa 的中间件模型的源码实现：\n// https://github.com/koajs/compose/blob/25568a36509fefc58914bc2a7600f787b16aa0df/index.js#L42 function compose(middleware) { // ... return function (context, next) { // ... return dispatch(0); function dispatch(i) { // ... // 遍历嵌套迭代（类递归）的方式执行 return Promise.resolve(fn(context, dispatch.bind(null, i + 1))); } }; } 我们可以看到 koa-compose 模块实现了 Koa 的中间件模型，是一种通过遍历嵌套迭代（类递归）的方式来逐个执行中间件函数，而且引入上下游（upstream / downstream）的概念，这种方式会导致调用栈会非常的大，性能很难优化。而查看 Express 的源码，发现其会把中间件函数当作路由函数来对待，存储在数组中，后续也会以类似的方式执行，同样也会有调用栈过大的问题。\nFastify 依赖于 avvio 模块 建立了一种基于可重入（reentrant ）和有向无环图（directed acyclic graph）的插件模型，可以正确处理异步代码，保证插件的加载顺序，避免了前面提到的调用栈过大的问题。建立一个有向无环图的插件系统可以保证不会创建交叉依赖，并且实现了可以在应用程序的不同部分使用相同插件的不同版本。\n有向无环图\n由于这种架构模式，带来的另外一个好处就是很容易将应用拆分为多个微服务。\n有向无环图服务\n那么，可重入带来了什么？可重入性是代码的一种属性，指其没有共享状态，可以安全的在多个线程中或者递归地调用执行；换句话说，代码因为具备某些状态，在多个线程或者递归调用时因为改变了该状态而导致逻辑出错，表明代码是不可重入的，不具备可重入性。常见的应用场景就是在遍历图形的算法中，可能会多次到达同一个节点，可重入性保证了遍历过程中是安全的。\n具体实现，在 Fastify 官方文档的 Encapsulation 章节有关于其基本特性 \u0026ldquo;封装上下文（encapsulation context）\u0026rdquo; 的介绍，示例代码形象易懂，核心是围绕 register API 构建的自上而下继承的上下文模型，并可以通过 fastify-plugin 模块打破这种限制完成特定场景下的应用。在 Fastify 中一切皆插件，形成的这种插件系统，也正是上面提到的可以将应用方便的拆分为微服务的基础。\nGitHub: middie\nGitHub: avvio\nDirected acyclic graph\nWhat is the Re-entrant lock and concept in general?\n其它方面 除了上面所介绍的 Fastify 特点外，还有其它一些方面值得关注。\n第一个，Decorators API 提供了一个在整个应用的请求链路中共享数据的机制，此 API 也体现了 Fastify 对性能的关注，其与 V8 内部优化机制“隐藏类”和“内联缓存”相关。\nJavaScript engine fundamentals: Shapes and Inline Caches\n第二个，Hooks API 允许监听一些应用生命周期事件，提供了更高的灵活性，给特定场景下的应用提供了较好的实现机制。\n第三个，内置了依赖于 Pino 模块实现的日志系统，日志作为后端应用针对错误分析、性能分析等的原始信息是相当重要的，可见 Fastify 团队关注点还是相当准确的。\n最后，Fastify 的插件生态目前可能还不算很丰富，但官方提供的核心插件基本上也覆盖了常见的各种场景，例如消息队列、WebSocket、鉴权、缓存等。\n结语 可以看得出来，Fastify 对性能的追求是极致的，涉及到很多 V8 内部对代码的优化机制，通过了解还是收获颇丰的。回过头来，Node.js Web 框架虽然层出不穷，但根据 NPM Trends 的下载量统计来看，Express 依然高居榜首，说明 Node.js Web 框架在重业务场景下的应用其实不多，更多的应该是作为一些小项目的后端或者类似 BFF 层这种轻量的场景下应用。从 Express 到 Koa 再到 Fastify，这是向更轻量更高性能的方向发展，技术的发展趋势也从侧面反映了该技术在业务场景中的价值体现。\n参考资源 What if I told you that HTTP can be fast? Fastify - Fast and low overhead web framework for Node.js - Interview with Tomas Della Vedova 附：对比表 对比项(2021-06-01) express koa Fastify nestjs 当前版本 v4.17.1(2019-05-26) v2.13.1(2021-01-04) v3.17.0(2021-05-29) v7.6.17(2021-05-18) 设计理念/哲学 小型、强大的 HTTP 服务器工具 更轻量、高性能、“洋葱模型” 高性能、低开销，开发友好 提供 Node Web 应用的”架构规范“ 技术架构 核心简单，具备路由等常见功能，其它需依赖中间件扩展 核心极简，不包含任何额外功能，路由等其它功能需要依赖中间件扩展 核心简单，提供路由、日志等必要组件，其它依赖插件扩展 底层核心可替换，上层 MVC 模型 扩展机制 中间件 中间件 插件 插件 项目活跃度（近一年平均每周 GitHub commits） 0-2 0-2 5-10 20 维护团队的 roadmap 4.x -\u0026gt; 5.0（缓慢） 2.x -\u0026gt; 3.0（缓慢） 3.x -\u0026gt; 4.0（积极） v8.0 计划完成，待发布 是否支持 ts 社区维护 @types 社区维护 @types 官方维护 @types 官方内置支持 公开的基准测试 QPS 最低 QPS 高 QPS 最高 技术生态（官方+社区） 丰富 丰富 较丰富 较丰富 常见业务场景解决方案 社区中间件 社区中间件 官方插件 官方文档，内置适配器 商业案例 有 有 有 有 上手难易程度 容易 容易 容易 中等 可查阅的资料 多 较多 较多 较多 官网文档（中文） 有 有 有 有 OpenJS 基金会项目 是 是 附：基准测试 这里做了一个简单的基准测试，在 windows 10 平台下采用 autocannon 测试工具，依赖版本如下：\n\u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;4.17.1\u0026#34;, \u0026#34;fastify\u0026#34;: \u0026#34;3.18.1\u0026#34;, \u0026#34;koa\u0026#34;: \u0026#34;2.13.1\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;autocannon\u0026#34;: \u0026#34;^7.3.0\u0026#34;, }, 测试代码如下：\n// express const app = express(); app.get(\u0026#39;/\u0026#39;, function (req, res) { res.send({ hello: \u0026#39;world\u0026#39; }); }); app.listen(3002); // koa const app = new Koa(); app.use(async (ctx) =\u0026gt; { ctx.body = { hello: \u0026#39;world\u0026#39; }; }); app.listen(3001); // fastify const fastify = Fastify({ // logger: true, }); fastify.get(\u0026#39;/\u0026#39;, async (request, reply) =\u0026gt; { reply.type(\u0026#39;application/json\u0026#39;).code(200); return { hello: \u0026#39;world\u0026#39; }; }); fastify.listen(3000, (err, address) =\u0026gt; { if (err) throw err; }); 测试结果如下：\n# express \u0026gt; autocannon http://127.0.0.1:3002/ Running 10s test @ http://127.0.0.1:3002/ 10 connections ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐ │ Stat │ 2.5% │ 50% │ 97.5% │ 99% │ Avg │ Stdev │ Max │ ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤ │ Latency │ 0 ms │ 1 ms │ 2 ms │ 3 ms │ 0.84 ms │ 0.61 ms │ 10 ms │ └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘ ┌───────────┬─────────┬─────────┬─────────┬────────┬─────────┬─────────┬─────────┐ │ Stat │ 1% │ 2.5% │ 50% │ 97.5% │ Avg │ Stdev │ Min │ ├───────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤ │ Req/Sec │ 4675 │ 4675 │ 8199 │ 8287 │ 7838.37 │ 1017.07 │ 4672 │ ├───────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤ │ Bytes/Sec │ 1.07 MB │ 1.07 MB │ 1.88 MB │ 1.9 MB │ 1.79 MB │ 233 kB │ 1.07 MB │ └───────────┴─────────┴─────────┴─────────┴────────┴─────────┴─────────┴─────────┘ Req/Bytes counts sampled once per second. 86k requests in 11.01s, 19.7 MB read # koa \u0026gt; autocannon http://127.0.0.1:3001/ Running 10s test @ http://127.0.0.1:3001/ 10 connections ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬──────┐ │ Stat │ 2.5% │ 50% │ 97.5% │ 99% │ Avg │ Stdev │ Max │ ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼──────┤ │ Latency │ 0 ms │ 0 ms │ 0 ms │ 0 ms │ 0.01 ms │ 0.12 ms │ 9 ms │ └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴──────┘ ┌───────────┬─────────┬─────────┬────────┬─────────┬────────┬────────┬─────────┐ │ Stat │ 1% │ 2.5% │ 50% │ 97.5% │ Avg │ Stdev │ Min │ ├───────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┤ │ Req/Sec │ 17743 │ 17743 │ 20111 │ 20335 │ 19496 │ 964.55 │ 17731 │ ├───────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┤ │ Bytes/Sec │ 2.91 MB │ 2.91 MB │ 3.3 MB │ 3.33 MB │ 3.2 MB │ 159 kB │ 2.91 MB │ └───────────┴─────────┴─────────┴────────┴─────────┴────────┴────────┴─────────┘ Req/Bytes counts sampled once per second. 214k requests in 11.01s, 35.2 MB read # fastify \u0026gt; autocannon http://127.0.0.1:3000/ Running 10s test @ http://127.0.0.1:3000/ 10 connections ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐ │ Stat │ 2.5% │ 50% │ 97.5% │ 99% │ Avg │ Stdev │ Max │ ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤ │ Latency │ 0 ms │ 0 ms │ 0 ms │ 0 ms │ 0.01 ms │ 0.13 ms │ 13 ms │ └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘ ┌───────────┬─────────┬─────────┬─────────┬─────────┬──────────┬─────────┬─────────┐ │ Stat │ 1% │ 2.5% │ 50% │ 97.5% │ Avg │ Stdev │ Min │ ├───────────┼─────────┼─────────┼─────────┼─────────┼──────────┼─────────┼─────────┤ │ Req/Sec │ 19759 │ 19759 │ 27631 │ 27903 │ 26960.73 │ 2284.47 │ 19752 │ ├───────────┼─────────┼─────────┼─────────┼─────────┼──────────┼─────────┼─────────┤ │ Bytes/Sec │ 3.24 MB │ 3.24 MB │ 4.53 MB │ 4.58 MB │ 4.42 MB │ 375 kB │ 3.24 MB │ └───────────┴─────────┴─────────┴─────────┴─────────┴──────────┴─────────┴─────────┘ Req/Bytes counts sampled once per second. 297k requests in 11.01s, 48.6 MB read 根据测试结果来看，仅 Req/Sec 这一项的平均值（Avg），Express 只有 7838.37，Koa 有 19496，约为前者的 2.4 倍，而 Fastify 达到了 26960.73，是 Express 的约 3.4 倍，Koa 的约 1.4 倍。除此之外，Bytes/Sec 指标也有差距，综合起来 Koa 和 Fastify 的表现要好的多，而 Fastify 要比 Koa 表现更好一些。\n"},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-programming-language/","title":"理解编程语言的设计与实现","description":"编程语言为开发者提供了诸多便利，那么它是如何被发明的，不同的语言设计理念有什么不同呢？","date":"May 2, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 工具","tags":"","content":"编程语言本质上是给开发者使用的工具，不同的业务领域使用不同的编程语言去实现具体的业务，是基于语言本身的设计理念与实现方式来做选择，那么作为开发者应该了解一下编程语言是如何被发明的，且其设计理念是什么。\nRuby 是我大学期间课余接触且实际使用过的一门语言，目前我甚是喜爱，其作者松本行弘设计 Ruby 的初心是：为开发者服务，注重简洁和效率。这篇文章主要也是为了记录在拜读了松本行弘先生新书《编程语言的设计与实现》之后掌握的一些相关的关键知识点和其它收获。由于该书主要是围绕作者在设计 Ruby 和新语言 Streem 过程中的一些思考和经验，有些东西可能不太具备普适性，而我在这里主要还是关注一些通用性的知识点和概念。\n为什么要创造编程语言 在过去，计算机信息技术行业还不够发达，在没有成为主流的时候，编程语言一般是作为商业化附属品出现的，普通人很难能免费且容易的获取到编程语言作为工具使用。所以，基于需求创造自己的编程语言就显得很合理了。然而，当今由于开源技术的盛行，很多编程语言都以开源的形式存在，作为开发者现在很容易就能获取到不同的编程语言作为自己的工具进行业务开发，那为什么还要创造新的编程语言？或者说，为什么现如今新的语言仍然层出不穷？\n软件编程本质上是“人机交互”，开发者使用编程语言设计业务逻辑，然后交由机器具体来执行，编程语言作为开发者与机器之间交流的媒介存在。随着时代的发展，业务需求和场景日益复杂，开发者与机器之间的交流也日趋复杂，为了让开发者“更轻松”地与机器交流，抽象度更高且更简洁的新编程语言作为新的交流媒介被发明。回忆一下计算机发展史，软件编程正是遵循从“汇编语言”（指令、0 和 1）到“低级语言”（例如 C/C++，语句、函数、数据类型）再到“高级语言”（例如 Java/Go，面向对象、并发、自动 GC）的发展路径。\n对于个人来说，创造编程语言，或者说深入了解如何创造编程语言，可以提升自己的技术能力和设计能力，也能在一定程度上打造自己的个人品牌（提高个人声望）。\n编程语言的设计与实现 对于现今的大多数编程语言来说，都属于“低级语言”和“高级语言”的范畴，而机器只能直接理解汇编语言。那么，设计编程语言是在设计什么？\n语言和语言处理器 编程语言在使用过程中可大致分为两个阶段：编写代码和运行代码。前者注重的是语言本身，而后者具体要解决的就是语言代码如何让机器能理解进而执行。\n语言是由语法和词汇构成的。语法是一种规则，规定了在该语言中如何表述才能使程序有效；而词汇是能从使用该语言编写的程序中调用的功能的集合，之后会以库的形式逐渐增加。 在设计语言的场景中说起词汇，就是指该语言一开始就具备的内置功能。\n我们可以用不同的编程语言实现同样的功能，但有的语言实现起来复杂繁琐，但有的语言实现起来简单容易，这就是语言层面的直观体现。可以想象的是，很多新出现的编程语言首要解决的就是该问题，如何设计让语法规则更简单易用，内置功能更加强大。\n另一方面，用语言编写的代码如何在机器上实际运行？\n语言处理器是能够使语法和词汇在计算机上实际运行的软件。 要想使编程语言成为真正的语言，而非仅仅停留在一个想法上，是离不开语言处理器的。无法运行的编程语言在严格意义上不能称为编程语言。\n我们通常所说的“编译器”、“解释器”、“虚拟机”、\u0026ldquo;JIT（即时编译）\u0026ldquo;等概念，均属于语言处理器相关的内容。\n所以，编程语言的设计是在设计：语言本身和语言处理器。\n语言处理器的构成 先来看看语言处理器相关的内容。\n语言处理器大体上可分为解释语法的“编译器”、相当于词汇的“库”，以及实际运行软件所需的“运行时（系统）”。 这三大构成要素的比重会因语言和处理器性质的不同而发生变化。\n如何理解后一句，来看看具体的实例即可。\n早期的 TinyBASIC 语言很简单，编译器做的工作很少，主要的处理集中在运行时完成，对于这样的语言处理器可称之为”解释器“（interpreter）。现在这些复杂的语言的处理器都是先将程序编译为内部代码，再在运行时执行内部代码，这种“编译器＋运行时”的组合形式，看起来像源代码未经转换就被直接执行了，因此有时也被称为“解释型”，例如 Ruby。然而，像 C 语言这种在与机器非常接近的层面上追求效率的语言，几乎不存在运行时，只有解释语法的编译器部分非常突出，这样的语言处理器被称为“编译型”。\n在 C 语言这类语言中，作为转换结果的程序（可执行文件）是可以直接运行的软件，所以不需要负责运行的运行时。部分运行时的工作，比如内存管理等，由库和操作系统的系统调用负责。\n对于如今市场上主流的 Java 语言，其语言处理器设计较为复杂，首先通过编译器将源代码转换为虚拟机的机器码（JVM 字节码），并由虚拟机（JVM）来执行。而且，为了提高效率，运行时采用了将字节码转换为机器码的即时编译（Just In Time Compiler）等技术。\n######### 编译器（Compiler）\n**编译器的工作是将编程语言的源代码（原始语言）转换为可执行的形式（目标语言）。**其大致按顺序会执行多个或所有以下流程：预处理、词法分析、语法分析（解析）、语义分析（语法导向翻译）、将输入程序转换为中间表示（IR）、代码优化和代码生成。\n编译器设计一般分为三个阶段，前端、中端和后端。编译前端包括生成中间表示（IR）之前的流程，这个 IR 通常是程序相对于源代码的较低级别的表示，在该阶段主要做一些静态分析工作，例如类型检查。编译中端则是对前端生成的 IR 做进一步处理，该阶段主要做与 CPU 架构无关的优化，例如去除无用（消除死代码）或无法访问（可达性分析）的代码。编译后端对中端生成的优化 IR 基于特定的 CPU 架构做进一步的分析、转换和优化处理，最终生成依赖于特定平台的汇编代码。\n编译器这种前/中/后的设计方式使得不同语言的前端与不同 CPU 架构的后端相结合成为可能，同时共享中端的优化。例如，GNU 编译器集（GCC）、Clang（LLVM）等。\n############# 提前编译（AOT）与即时编译（JIT）\n目前根据编译的时机可将其分为静态编译和动态编译。其中静态编译通常称为提前编译（Ahead-of-time compilation），是指在程序执行之前将高级编程语言编译成低级语言的行为，减少需要在运行时执行的工作量，通常性能最优。而动态编译技术目前最具代表性的则为即时编译（Just-in-time compilation），是指在程序执行期间（在运行时）而不是在执行之前进行编译，是对两种传统的机器代码翻译方法（提前编译和解释）的结合，具有编译代码的速度和解释的灵活性，当然也引入了解释器的开销和编译及链接的额外开销。\n############# 词法分析\n词法分析器构成了现代处理中编译器前端的第一阶段。词法分析（Lexical analysis）简单来说就是“将源代码由字符序列转换为有意义的单词（token）序列”的工序。将只是字符串的源代码整理为有些许意义的单词序列，后续阶段的处理就会变得简单。\n以 C 语言为例说明：\nx = a + b * 2; 上面的表达式经过词法分析后生成如下内容：\n[(identifier, x), (operator, =), (identifier, a), (operator, +), (identifier, b), (operator, *), (literal, 2), (separator, ;)] 我们可以借助 lex 工具根据编写单词的规则自动生成词法分析函数。\n############# 语法分析\n语法分析（Syntax analysis）是检查在词法分析阶段准备好的单词是否符合语法，并进行符合语法的处理的工序，最终结果是生成一个解析树（parse tree）数据结构。语法分析的方法有好几种，其中最有名、最简单的方法是使用别名为“生成编译器的编译器”的语法分析函数生成工具，比如 yacc（yet another compiler compiler）。\n############# 抽象语法树\n抽象语法树（Abstract syntax tree）是用编程语言编写的源代码的抽象语法结构的树表示，树的每个节点表示源代码中出现的一个构造。语法是“抽象的”，因为它不代表真实语法中出现的每个细节，而只是结构或与内容相关的细节。例如，分组括号在树结构中是隐含的，因此不必将它们表示为单独的节点。\n抽象语法树在语义分析期间被大量使用，其中编译器检查程序和语言元素的正确使用。编译器还在语义分析期间根据 AST 生成符号表。树的完整遍历允许验证程序的正确性。验证正确性后，AST 作为代码生成的基础。AST 通常用于为代码生成生成中间表示 (IR)，有时也称为中间语言。\n抽象语法树多用于程序分析和程序转换系统。\n######### 标准库（Standard Library）\n**语言的标准库通常被其用户视为语言的一部分，包括常用算法、数据结构和输入输出机制的定义。**标准库为程序员利用该语言实现更复杂的功能提供了必要的依赖。\n那么，标准库中应该包含什么？对于标准库的设计哲学，可以参考 C/C++ 和 Java/Python，前者只提供在实现程序功能时必要且合理的数据结构和算法，规模相对较小，而后者旨在提供更多的便利、易于编码，封装了较为复杂和强大的功能，规模相对来说更为庞大。因此，Python 成为了目前主流的用来科学研究的语言，它可以很方便的完成复杂的数学计算和科学分析工作。\n######### 运行时（Runtime）\n每种编程语言都指定了一个执行模型，并且许多语言在运行时系统中至少实现了该模型的一部分。运行时系统为程序提供了运行的环境，这种环境可以解决许多问题，包括应用程序内存的管理、程序如何访问变量、在子程序之间传递参数的机制、与操作系统的接口等。换句话说，编译器根据具体平台的运行时系统产生正确的代码，运行时系统将负责设置和管理堆栈和堆，并且可能包括诸如垃圾收集、线程或其他内置于语言中的动态特性。\n############# 执行模型（Execution model）\n编程语言由文法/句法加上执行模型组成。执行模型指定语言元素的行为。通过应用执行模型，可以推导出用该编程语言编写的程序的行为。\n例如，当程序员“阅读”代码时，在他们的脑海中，他们会浏览每一行代码的作用。实际上，他们模拟了他们头脑中的行为。程序员正在做的是将执行模型应用于代码，这会导致代码的行为。\n虚拟机（Virtual Machine） 虚拟机是运行时的一种技术实现，是用软件实现的（无实际硬件的）计算机，区别于系统虚拟机，将其称之为“进程虚拟机”。进程虚拟机最初是作为中间语言的抽象平台出现的，中间语言被编译器用作程序的中间表示（IR）。它的目的是提供一个独立于平台的编程环境，抽象出底层硬件或操作系统的细节，并允许程序在任何平台上以相同的方式执行。因此，虚拟机最大的优点就是拥有可移植性。\n配合各种各样的 CPU 生成机器语言的代码生成处理是编译器中最复杂的部分，适配新出现的 CPU 架构重新开发代码生成处理，对语言处理器的开发者来说是很大的负担，虚拟机在减少这类负担上起到了很大作用。另一方面，与在硬件上直接执行相比，模拟虚拟的 CPU 运行的虚拟机在性能上有很大损失，但可以通过引入即时编译（JIT）技术来弥补。\n虚拟机性能相关的实现技术可以了解一下：\nRISC 与 CISC 栈与寄存器 指令格式 RISC 是 Reduced Instruction Set Computer（精简指令集计算机）的缩写，是通过减少指令的种类、简化电路来提高 CPU 性能的架构。具有代表性的 CPU 有 MIPS 和 SPARC 等。在移动设备上广泛使用的 ARM 处理器就属于 RISC。\nCISC 是与 RISC 相对的一个词汇，是 Complex Instruction Set Computer（复杂指令集计算机）的缩写，简单来说就是“不是 RISC 的 CPU”。CISC 的每个指令执行的处理都非常大，而且指令的种类繁多，因此实现起来也比较复杂。\n对用软件实现的虚拟机来说，我们就不能忽视取指令（Instruction Fetch，IF）处理所需要的成本。也就是说，做同样的处理时所需的指令数越少越好。好的虚拟机指令集是类 CISC 架构的指令集，它的全部指令都是高粒度的。\n虚拟机架构的两大流派是栈式虚拟机和寄存器式虚拟机。栈式虚拟机原则上通过栈对数据进行操作，而寄存器式虚拟机的指令中包含寄存器编号，原则上对寄存器进行操作。\n与寄存器式虚拟机相比，栈式虚拟机更为简单，程序也相对较小。然而，由于所有的指令都通过栈来交换数据，所以对指令之间的先后顺序有很大的依赖，很难实施交换指令顺序这样的优化。而寄存器式虚拟机由于指令中包含寄存器信息，所以程序相对较大。\n用哪种架构取决于具体场景，著名的 Java 虚拟机（JVM）采用的是栈式虚拟机架构，而谷歌为优化移动设备性能，为 Android 提供的 Dalvik 虚拟机则采用的是寄存器式虚拟机架构。\n虚拟机解释的中间语言（指令序列）被称为“字节码”，源于 Smalltalk 的指令是以字节为单位的。当然，不是所有虚拟机都拥有字节单位的指令集，例如 mruby 的指令集就是用 32 位整数表示的，可以称之为“字码”，但因为 JVM 比较出名且其采用的是字节码，所以一般将虚拟机解释的中间语言称之为“字节码”。字码与字节码的优缺点不在这里赘述。\n参考 《松本行弘：编程语言的设计与实现》，[日] 松本行弘，郑明智 译 https://en.wikipedia.org/wiki/Compiler https://en.wikipedia.org/wiki/Ahead-of-time_compilation https://en.wikipedia.org/wiki/Just-in-time_compilation https://en.wikipedia.org/wiki/Abstract_syntax_tree https://en.wikipedia.org/wiki/Library_(computing) https://en.wikipedia.org/wiki/Runtime_system https://en.wikipedia.org/wiki/Virtual_machine "},{"section":"Blog","slug":"/blog/computer-technology/web/javascript/debouncing-and-throttling/","title":"Web 前端性能优化：解析函数节流与防抖的实现","description":"前端开发中广泛采用的优化技巧，函数节流与防抖。","date":"April 25, 2021","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, JavaScript, 性能优化, 节流与防抖","tags":"","content":"前端开发中，有一个使用较为普遍的性能优化技巧，即函数节流（Throttle）和防抖（Debounce），其主要作用是根据时间对函数调用做以限制。最常见的业务场景是监听页面的 scroll 事件，浏览器可以在 1s 内触发该事件数次（甚至达数十次），如果事件处理程序在这 1s 内多次执行，必然会造成一定的性能问题，影响用户体验。\n本质上，函数节流和防抖并不是控制事件源的触发次数，而是在事件短时间内连续多次触发之后控制相应事件处理程序的调用频率。\n节流：在一段连续时间内，限制函数在一定时间间隔内仅能调用一次。（例如，时间间隔为 1s，那么 10s 内至多被调用 10 次。） 防抖：在连续的函数调用中，限制两次函数调用的时间间隔应大于一定时间。（例如，时间间隔为 1s，连续调用函数多次且每次间隔小于 1s，那么 10s 内至多被调用 1 次。） 推荐阅读：通过示例解释防抖和节流\n解析代码实现 在这里，主要是分析一下如何用代码实现函数的节流和防抖功能。当然，并不打算自己手写实现，以目前比较成熟的工具库（Lodash）所提供的实现为基础来进行分析。\n大致的实现思路基本上一样，都是利用闭包，维护内部状态，根据内部状态来对函数调用做具体控制。如下所示：\nfunction debounce(func, time_interval) { // ... return () =\u0026gt; { func.apply(thisArg, arguments); }; } // 对函数进行防抖处理包装 const debounced = debounce(() =\u0026gt; {}, 1000); debounced(); // 调用 n 次 防抖（Debounce） _.debounce 源码\n我们首先看一下其源码主体结构：\nfunction debounce(func, wait, options) { // 内部状态 let lastArgs, lastThis, // 保存最后一次函数调用传入的参数列表和 this 指向 maxWait, result, // 函数执行结果 timerId, lastCallTime; // 关键：主要用来限制函数调用 // ... // wait 没有指定时，默认利用 requestAnimationFrame API 做了性能优化 const useRAF = !wait \u0026amp;\u0026amp; wait !== 0 \u0026amp;\u0026amp; typeof root.requestAnimationFrame === \u0026#39;function\u0026#39;; // 闭包结构 function debounced(...args) {} // 工具方法 debounced.cancel = cancel; debounced.flush = flush; debounced.pending = pending; return debounced; } 这是符合利用闭包实现的思路的，其中还接受第三个参数 options，lodash 库对该防抖功能做了增强，同时也添加了三个工具方法 cancel、flush、pending。很有意思的是，lodash 默认利用 requestAnimationFrame API 做了性能优化。\n防抖的核心思想是：限制两次函数调用的时间间隔应大于一定时间。来看看具体的实现：\nfunction debounce(func, wait, options) { // 实际调用函数 function invokeFunc(time) { const args = lastArgs; const thisArg = lastThis; lastArgs = lastThis = undefined; lastInvokeTime = time; result = func.apply(thisArg, args); // 关键：利用 apply 调用，保证 this 指向和参数列表正确 return result; } // 关键：创建超时器，异步调用函数 // 异步调用的目的是在两次调用之间时间间隔过短（不符合限制条件）时，延后调用直至满足条件 function startTimer(pendingFunc, wait) { if (useRAF) { root.cancelAnimationFrame(timerId); return root.requestAnimationFrame(pendingFunc); } return setTimeout(pendingFunc, wait); } // 判断是否可以调用函数 function shouldInvoke(time) { const timeSinceLastCall = time - lastCallTime; const timeSinceLastInvoke = time - lastInvokeTime; // 关键：这一行的判断条件，限制两次函数调用的时间间隔应大于一定时间 return ( lastCallTime === undefined || timeSinceLastCall \u0026gt;= wait || timeSinceLastCall \u0026lt; 0 || (maxing \u0026amp;\u0026amp; timeSinceLastInvoke \u0026gt;= maxWait) ); } function timerExpired() { const time = Date.now(); // 关键：超时器到期后，需要再次检查是否满足条件 if (shouldInvoke(time)) { return trailingEdge(time); } timerId = startTimer(timerExpired, remainingWait(time)); } function debounced(...args) { const time = Date.now(); const isInvoking = shouldInvoke(time); lastArgs = args; // 每次调用都更新保存的参数列表和 this 指向 lastThis = this; lastCallTime = time; // 关键：记录每次函数调用的时间，在下一次调用时对时间间隔进行判断 // 关键：进行两次调用时间间隔判断，并创建超时器异步执行函数 if (isInvoking) { if (timerId === undefined) { return leadingEdge(lastCallTime); } if (maxing) { timerId = startTimer(timerExpired, wait); return invokeFunc(lastCallTime); } } if (timerId === undefined) { timerId = startTimer(timerExpired, wait); } return result; } } 源码中像 trailingEdge()、leadingEdge() 、remainingWait() 等可以暂时忽略掉，这些函数主要是 lodash 为结合 options 对防抖功能做的一些增强功能。\n依据源码，防抖的实现思路是：利用闭包返回一个待调用函数 debounced，实际要调用的函数 func() 采用异步调用的方式，在我们每次调用函数时，利用 shouldInvoke() 函数（主要是利用 Date.now() 与 lastCallTime）判断是否满足时间间隔条件，在满足条件时利用 startTimer() 函数创建一个超时器去异步调用 func() 函数，而在每次超时器到期后要调用 func() 函数时都要通过 shouldInvoke() 函数再次检查是否满足条件，不满足则继续延迟调用，直至满足条件后执行 func() 函数（主要为 invokeFunc() 函数）。\n这里要注意的是实际要调用的 func() 函数是被异步调用的，并且为了保证 this 指向和参数一致，使用 apply() 方法去调用。\n######### 防抖增强\nlodash 对防抖功能做了增强，先来看看之前提到的三个工具方法。\nfunction cancelTimer(id) { if (useRAF) { returnroot.cancelAnimationFrame(id); } clearTimeout(id); } function cancel() { if (timerId !== undefined) { cancelTimer(timerId); // 清除超时器，即取消异步的 func() 函数调用 } // 将状态初始化 lastInvokeTime = 0; lastArgs = lastCallTime = lastThis = timerId = undefined; } cancel() 这个工具方法提供了将要执行的 func() 调用取消掉的功能，实现该功能也得益于其异步调用的实现方式。\nfunction trailingEdge(time) { timerId = undefined; // 关键：虽然丢弃了引用，但没有清除超时器 if (trailing \u0026amp;\u0026amp; lastArgs) { // 关键：利用 lastArgs 在调用 func() 函数前做了判断 return invokeFunc(time); // 关键：该函数内部也清除了 lastArgs } lastArgs = lastThis = undefined; // 关键：将参数列表清除，意味着将不会再次调用 func() 函数 return result; } function flush() { return timerId === undefined ? result : trailingEdge(Date.now()); } flush() 这个工具方法提供了立即调用 func() 函数的功能，但要注意的是其内部实现中只是丢掉了 timerId 对已经发起的超时器任务的引用，并没有清除超时器，那么会不会造成对 func() 函数的重复调用呢？根据源码来看，在超时器到期之后的 func() 函数调用之前用 lastArgs 做了判断，而在调用 flush() 过程中清除了 lastArgs 的值，也就避免了重复调用 func() 的问题。\n至于为何不直接清除掉超时器，而只是丢弃引用？不得而知。但我猜测应该是基于模块设计上的考虑，因为 trailingEdge() 函数被调用的时机就是超时器到期之后，所以它只负责清除掉 timerId 的值即可。\nfunction pending() { return timerId !== undefined; } pending() 这个工具方法就比较简单了，仅提供了获取目前是否处于等待调用 func() 函数的状态的功能。\n接下来看看 options 这个参数带来了哪些功能上的增强。\nlet maxWait; let leading = false; // 默认 false let maxing = false; let trailing = true; // 默认是 true if (isObject(options)) { leading = !!options.leading; maxing = \u0026#39;maxWait\u0026#39; in options; maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait; // 关键：取 maxWait 和 wait 最大值 trailing = \u0026#39;trailing\u0026#39; in options ? !!options.trailing : trailing; } { leading, maxWait, trailing } 有三个选项字段。先来看看 maxWait 选项：\nfunction remainingWait(time) { const timeSinceLastCall = time - lastCallTime; const timeSinceLastInvoke = time - lastInvokeTime; const timeWaiting = wait - timeSinceLastCall; // 关键：maxWait 决定了超时器的超时时间 return maxing ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke) : timeWaiting; } function shouldInvoke(time) { const timeSinceLastCall = time - lastCallTime; const timeSinceLastInvoke = time - lastInvokeTime; return ( lastCallTime === undefined || timeSinceLastCall \u0026gt;= wait || // 关键：maxWait 决定了该不该调用 func() 函数 timeSinceLastCall \u0026lt; 0 || (maxing \u0026amp;\u0026amp; timeSinceLastInvoke \u0026gt;= maxWait) ); } function timerExpired() { // ... timerId = startTimer(timerExpired, remainingWait(time)); } function debounced(...args) { // ... const isInvoking = shouldInvoke(time); // ... if (isInvoking) { // ... if (maxing) { timerId = startTimer(timerExpired, wait); return invokeFunc(lastCallTime); } } // ... return result; } 虽然代码看起来很多，但实际 maxWait 只提供了一个很简单的功能：在对函数进行防抖处理中，两次 func() 函数实际调用间隔至多为 maxWait，也就是说只要两次调用时间间隔达到该时间，无论 wait 限制如何，均会执行 func() 函数调用。\n这个其实解决了因为函数调用频率过高，func() 长时间得不到实际调用的业务问题。\n接下来，需要把 leading 和 trailing 两个选项放在一起看，因为它们刚好是对立的一组值，本质上解决的是同一个问题：func() 函数实际调用的时机。\nfunction leadingEdge(time) { lastInvokeTime = time; timerId = startTimer(timerExpired, wait); // 关键：利用 leading 判断 return leading ? invokeFunc(time) : result; } function timerExpired() { const time = Date.now(); if (shouldInvoke(time)) { return trailingEdge(time); // 关键：超时器到期后总是调用 trailingEdge() 函数 } timerId = startTimer(timerExpired, remainingWait(time)); } function trailingEdge(time) { timerId = undefined; // 关键：利用 trailing 进行判断 if (trailing \u0026amp;\u0026amp; lastArgs) { return invokeFunc(time); } lastArgs = lastThis = undefined; return result; } function debounced(...args) { // ... if (isInvoking) { if (timerId === undefined) { return leadingEdge(lastCallTime); } // ... } // ... return result; } 首先说结论：当 leading=true 时决定对 func() 函数的实际调用在创建超时器时（提前调用），而 trailing=true 时决定对 func() 函数的实际调用在创建的超时器到期后（延后调用）。\n其实要搞懂其中的思路，只要理解了以上几个函数在实际调用中的执行顺序即可：\ndebounced() -\u0026gt; leadingEdge() -\u0026gt; timerExpired() -\u0026gt; trailingEdge() -\u0026gt; debounced() 这里其实是一个调用循环，无论 leading 和 trailing 值如何，其相应的函数 leadingEdge() 和 trailingEdge() 都参与其中，只不过在不同值的情况下，这两个函数所扮演的角色不同而已。这里举一个简单的例子即可说明问题：\n// 当 leading=true，且 trailing=false 时： // leadingEdge() 函数主要作用是调用 invokeFunc() 函数来实际调用 func() 函数 // trailingEdge() 函数主要作用则是超时器到期后清除掉内部状态，主要是 timerId 的值 那么这里有个值得考虑的点，按照常规的实现思路不应将 leadingEdge() 和 trailingEdge() 函数放在一起同时处理逻辑，而应该按照条件判断独立成两条线去处理逻辑。根据源码分析来看，我猜测是因为 lodash 所提供的 leading 和 trailing 两个选项并非完全对立的一组值，可能存在它们同时为 true 的情况（在函数的顶部注释中有所说明）。当然这里不能同时为 false，因为分析下源码的实现，你会发现 func() 函数将永远得不到实际调用。\n节流（Throttle） _.throttle 源码\n之所以先解析防抖的实现，是因为节流的源码实现中引用到了防抖的源码实现，这样反而让节流的源码实现看起来相当简洁。源码如下：\nfunction throttle(func, wait, options) { let leading = true let trailing = true if (typeof func !== \u0026#39;function\u0026#39;) { throw new TypeError(\u0026#39;Expected a function\u0026#39;) } if (isObject(options)) { leading = \u0026#39;leading\u0026#39;inoptions ? !!options.leading : leading trailing = \u0026#39;trailing\u0026#39;inoptions ? !!options.trailing : trailing } return debounce(func, wait, { leading, trailing, \u0026#39;maxWait\u0026#39;: wait }) } options: { leading, trailing, maxWait } 选项中的 leading 和 trailing 不再细说，参考防抖的理解即可。而 maxWait 选项则是关键，它没有对外暴露，而是直接默认使用了 wait 的值（实际上这也是让节流可以利用防抖来实现的主要原因）。\n接下来，我们主要分析下 maxWait 选项是如何让节流可以利用防抖来实现的核心思路。回过头来，我们看看函数的节流和防抖的概念，就可以发现它们本质上都是对函数调用频率做了限制，唯一不同的是函数防抖会在函数调用过快时（不满足限制条件时）无限期的延迟函数的实际调用，而函数节流必须要保证函数的实际调用要在限制时间内至少发生一次。\n而在前面我们分析防抖的功能增强实现时，maxWait 选项为函数防抖提供的正是在达到 maxWait 时间时实际的函数调用必须发生一次的功能。那么，当 wait === maxWait 时恰好满足了节流的要求。所以，lodash 在增强防抖的时候，同时利用防抖也实现了节流的功能。\n结语 函数的节流和防抖是个很常用的性能优化技巧，实现思路也比较简单，但 lodash 对基本的逻辑进行了增强，以适应更多的业务场景。另一方面，在源码实现层面来看，lodash 对防抖的增强逻辑反而降低了节流实现的复杂性，这在开发过程中可能是更值得借鉴的一种思路。\n"},{"section":"Blog","slug":"/blog/computer-technology/nodejs/tools-npm/","title":"使用 npm","description":"npm 是 Node.js 的一个包管理器，Web 前端工程师也经常利用它构建前端工作流，来看看如何愉快的使用 npm。","date":"July 6, 2019","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Node.js, npm","tags":"","content":"npm 是 Node.js 的一个包管理器，Web 前端工程师也经常利用它来简化开发流程，看看如何愉快的使用 npm ，并且发布自己的包，让 npm 成为我们的开发利器。\nnpm **Node.js：**https://www.npmjs.com/\n**npm：**https://www.npmjs.com/\nnpm 通常是伴随着 Node.js 一起安装的，只要安装了 Node.js，那么 npm 也就已经安装好了，可以在命令行运行以下命令查看版本：\nnode -v npm -v 换源 这是作为墙内的开发者必须掌握的一项技能，将 npm 的官方源替换为国内源，这样下载 npm 包速度也会更快，更不容易出错。\n运行以下命令查看 npm 配置，其中有仓库源 registry 一项：\nnpm config list npm config get registry // 只查看 registry 配置 更换仓库源：\nnpm config set registry \u0026lt;source\u0026gt; npm config set registry https://registry.npmjs.org/ // 换回官方源 npm config set registry https://registry.npm.taobao.org/ // 换到国内淘宝源 更换掉仓库源之后，再查看下是否更换成功。\n请勿使用 cnpm 等其它类似工具，用官方 npm 换到国内源即可。\n常用源切换工具 nrm\n常用命令 通常来说，我们只会利用 npm 来安装、卸载依赖包，或者在项目启动时进行初始化。\nnpm init [-y] // 在当前文件夹初始化，生成一个 package.json 文件，-y 选项为全部默认 # https://docs.npmjs.com/cli/v6/commands/npm-install npm install --global|-g \u0026lt;package_name\u0026gt; // 在全局安装指定包 npm uninstall --global|-g \u0026lt;package_name\u0026gt; // 卸载安装在全局的指定包 npm install [-P|--save] \u0026lt;package_name\u0026gt; // 在当前项目本地安装生产环境依赖包，会列在 dependencies 中 npm uninstall [-S|--save] \u0026lt;package_name\u0026gt; // 卸载安装在项目本地的 dependencies 中指定包 npm install -D|--save-dev \u0026lt;package_name\u0026gt; // 在当前项目本地安装开发环境依赖包，会列在 devDependencies 中 npm uninstall -D|--save-dev \u0026lt;package_name\u0026gt; // 卸载安装在项目本地的 devDependencies 中指定包 这里值得一提的是，在 npm 5.2+ 之后，附带了一个 npx 命令，作用是执行包的二进制文件：\n# https://www.npmjs.com/package/npx npx [options] [-p|--package \u0026lt;pkg\u0026gt;]... \u0026lt;command\u0026gt; [command-arg]... npx create-react-app my-app // 执行 create-react-app 包的主命令 通过 npx 命令执行包的二进制文件有一个优点：不需要安装包，即可执行包的命令，对本地环境无污染。\n而且，在 npm 6.0+ 之后，init 命令可以接收一个新的选项：\n# https://docs.npmjs.com/cli/v6/commands/npm-init npm init \u0026lt;initializer\u0026gt; npm init react-app my-app // same as : npx create-react-app my-app 其中 \u0026lt;initializer\u0026gt; 是一个以 create- 开头命名的包，算是对这种特殊命名的包的 npx 命令的简写方式。\nNode 版本管理 作为一名 Node.js 开发，如何在自己的设备上管理多个 Node 版本是一个相当重要的技能，而 npm 库中的 n 模块就为我们提供了最佳解决方案，使用它可以在同一台设备上安装多个不同版本的 Node，并随时进行切换，同时也可以方便的升级、降级。\n作为一个管理 Node 的工具，建议将其安装在全局：\nnpm install -g n 安装完成后，执行以下命令安装相应版本的 Node：\nn \u0026lt;version\u0026gt; // eg: n 10.16.0 n latest // 安装最新版 node n lts // 安装最新的 LTS 版本 node 查看已安装的所有版本的 Node：\nn // 貌似只能查看通过 n 模块安装的 node 切换 node 版本来执行命令：\nn use \u0026lt;version\u0026gt; [args ...] // 切换到已安装的另一个版本的 node 并执行命令 卸载 node：\nn rm \u0026lt;version\u0026gt; // 卸载指定版本 node n prune // 卸载所有已安装 node 版本，但当前正在使用的 node 版本不会被卸载 Windows 平台用户可以使用 nvm-windows\nnpm 升级 虽然 npm 是随 Node 一起安装的，但在之后通过 n 模块升级 Node 的过程中，npm 不会也跟着升级，需要我们手动升级：\nnpm install -g npm[@latest|\u0026lt;version\u0026gt;] 发布 npm 包 通常，我们只是下载安装 npm 库中的包来使用，辅助我们进行开发，但去了解如何利用 npm 发布包也是有必要的，这样我们也可以写一些自己的模块并进行发布供自己和他人使用。\n注册 首先需要去 npm 官网注册一个账号（无需翻墙）。如果想更换头像的话，还要去注册一个 Gravatar 并上传一张照片，才可以将这张照片作为头像。\n**npm：**https://www.npmjs.com/\n初始化 在本地新建一个文件夹，并初始化：\nnpm init [-y] 然后，修改生成的 package.json 中的必要字段，例如 name、author、homepage 等等，具体的字段以及含义可以去查 npm 的官方文档。\n这里需要注意的是，如果你将要发布的包，是别人通过 require('package_name') 来使用的话，请指定 package.json 中的 main 字段为该包的入口文件。或者，也可能你将要发布的包只是一个命令行工具，那么删除掉 main 字段，指定 bin 字段即可。当然 main 与 bin 是可以共存的。\n编码 初始化完成后，就主要是我们编码了，建议将入口文件放在项目根目录下，其余代码文件都放在相应文件夹下：\nPackage/ - build/ // 编译后用于生产环境的文件 - config/ // 项目开发环境配置文件 - bin/ // 项目命令行脚本文件 - scripts/ // 项目 npm 脚本文件 - src/ // 项目源码文件 - index.js // 项目入口文件 这里需要注意，bin/ 中的命令行脚本文件，必须在每个文件的第一行指定 #!/usr/bin/env node，表明这是一个 node 脚本，以及执行该脚本的二进制文件系统路径。\n发布前本地测试 在编码完成并完善 package.json 文件后，我们可能需要测试才能确保最终发布后能被自己或者他人通过 npm 安装正常使用。\n我们不需要反复进行发布\u0026ndash;测试\u0026ndash;修复\u0026ndash;撤销发布\u0026ndash;重新发布这个过程，npm 官方为我们提供了便捷的本地测试工具，也就是 link 命令。\n# https://docs.npmjs.com/cli/v6/commands/npm-link npm link // 在你将要发布的包根目录下执行该命令，如同将其安装到全局一样，更改文件及时生效，不需要重新 link npm link \u0026lt;package_name\u0026gt; // 在另外一个测试目录中执行该命令，如同 install npm unlink // 测试完成后，在你将要发布的包根目录下执行该命令，unlink 会将其从全局卸载 本地测试还是相当简单和方便的，也是无污染的。但是， npm link 并不是最好的方案，查看以下文章：\n4 reasons to avoid using npm link\n####### 小技巧\n这里有个小技巧可以不使用 npm link 命令就能在本地测试，而且是真的无污染：\n\u0026#34;dependencies\u0026#34;: { \u0026#34;my-dev-module\u0026#34;: \u0026#34;file:../my-dev-module/index.min.js\u0026#34; } 登录 发布前需要在命令行登录 npm 官方仓库：\n# https://docs.npmjs.com/cli/v6/commands/npm-adduser npm login [--registry=url] [--scope=@orgname] 注意：如果替换了官方源，一定要指定 --registry=https://registry.npmjs.org/，这样才能登录到官方仓库进行发布。--scope则是命名空间，例如 @babel。\n登录成功后，可以查看已登录用户：\n# https://docs.npmjs.com/cli/v6/commands/npm-whoami npm whoami [--registry \u0026lt;registry\u0026gt;] 发布 登录后，即可通过 publish 命令发布包：\n# https://docs.npmjs.com/cli/v6/commands/npm-publish npm publish [--access public] // 在将要发布的包根目录执行 需要注意，如果发布的包带有命名空间，例如 @babel/core，需要指定发布限制范围 --access，默认为 restricted（受限制），如你的 npm 帐户不是付费帐户，必须指定为 public。\n撤销发布 通常，是在本地测试无误后进行发布，如果真的在发布后发现问题，导致不能正常使用，可以撤销发布：\n# https://docs.npmjs.com/cli/v6/commands/npm-unpublish npm unpublish [\u0026lt;@scope\u0026gt;/]\u0026lt;package_name\u0026gt;[@\u0026lt;version\u0026gt;] **事实上，npm 官方不建议开发者使用 unpublish 命令来撤销发布，因为如果其它用户已经安装了该包作为依赖，并能正常使用的情况下该包被撤销，会导致其它用户无法再次安装该包。**所以，尽可能用 deprecate 命令来表明该包已被弃用，即便用户安装成功，也会有醒目的提示告知用户已被弃用，用户则会及时寻找替代包。\n# https://docs.npmjs.com/cli/v6/commands/npm-deprecate npm deprecate \u0026lt;package_name\u0026gt;[@\u0026lt;version\u0026gt;] \u0026lt;message\u0026gt; 退出登录 如果不是在自己的机器上工作，建议完成发布后退出登录，保证数据安全。退出登录与登录一样简单，同样需要指定 --registry 与 --scope 参数。\n# https://docs.npmjs.com/cli/v6/commands/npm-logout npm logout [--registry=url] [--scope=@orgname] 最佳实践 以上，是使用 npm 工具本身的过程，但 npm 工具本质上是为维护和发布 Node 模块/包服务的，开发 Node 模块/包有一些很好的社区实践，这里大致记录一下开发 Node 模块/包过程中一些注意的关键点。\n模块/包的类型 根据用途，模块/包的类型大致可以分为以下几种，不同的类型需要做对应的处理。\nNode 包 Web 包 Node 包一般来说发布时是不需要压缩的，JavaScript 代码也不需要编译，但需要标记一些特殊字段（如 engines）表明包所依赖的 Node 版本限制。\n// https://docs.npmjs.com/cli/v6/configuring-npm/package-json#engines { \u0026#34;engines\u0026#34;: { \u0026#34;node\u0026#34;: \u0026#34;\u0026gt;=0.10.3 \u0026lt;0.12\u0026#34; } } 而用于 Web 的包在发布前通常需要进行编译和压缩，目的是解决兼容性问题和资源加载优化，而这些工作一般借助 Babel、Rollup 等工具配合使用即可。另一方面，用于 Web 的包在开发过程中为了便于调试，所以引入的应该是未经编译和压缩的源码版本，而打包时再引入经过编译和压缩的版本，实现这个目的社区有一个比较通用的做法就是在入口文件使用 NODE_ENV 进行判断并导出相应版本文件，以下是 React 的入口文件示例：\nif (process.env.NODE_ENV === \u0026#39;production\u0026#39;) { module.exports = require(\u0026#39;./cjs/react.production.min.js\u0026#39;); } else { module.exports = require(\u0026#39;./cjs/react.development.js\u0026#39;); } 通过下面这篇文章即可了解实现细节。\nhttps://overreacted.io/how-does-the-development-mode-work/\n支持多个环境 纵观 Node.js 的发展历史，其生态中出现过多种模式，例如 AMD、CommonJS、ESM(ECMAScript modules)，以及 UMD，这种情况给包的开发带来一定困难，不过经过多年的发展社区已经形成一个约定（共识），可以很方便的解决该问题从而同时支持所有环境。\n主要是通过对应字段导出不同的入口文件来实现，下面是一个示例：\n{ \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;index.esm.js\u0026#34;, \u0026#34;browser\u0026#34;: \u0026#34;index.umd.js\u0026#34; } 具体实现可以通过下面这篇文章进行了解。\nhttps://2ality.com/2017/04/setting-up-multi-platform-packages.html\n####### 新的方案\n事实上，main 和 browser 字段在 npm 文档中有定义，查看文档：\nhttps://docs.npmjs.com/cli/v6/configuring-npm/package-json#main\n而 module 字段后来并没有被 Node 社区采用，而是推出了新的模块入口点定义字段 exports，配合条件导出我们就可以实现支持多个环境。查看文档：\nhttps://nodejs.org/dist/latest-v16.x/docs/api/packages.html#package-entry-points\n示例：\n{ \u0026#34;exports\u0026#34;: { \u0026#34;import\u0026#34;: \u0026#34;./index.esm.js\u0026#34;, \u0026#34;require\u0026#34;: \u0026#34;./index.cjs.js\u0026#34;, \u0026#34;browser\u0026#34;: \u0026#34;./index.umd.js\u0026#34; }, \u0026#34;main\u0026#34;: \u0026#34;./index.cjs.js\u0026#34; } 类型定义 JavaScript 并不是一个强类型语言，所以 IDE 要做类型推断和代码智能提示是比较困难的，尤其是编译、压缩、混淆后的代码对于用户使用有诸多不便，要不断的查询文档。然而，TypeScript 的出现使这一状况得到了改善，如果源代码直接使用 TypeScript 编写，最终编译时生成类型定义文件，在发布 npm 模块/包时指定一个 types 字段即可，查看文档：\nhttps://www.typescriptlang.org/docs/handbook/declaration-files/publishing.html\n对于使用 JavaScript 编写的源代码，事实上也可以利用 TypeScript 工具生成相应的类型定义文件，并随之一起发布，查看文档：\nhttps://www.typescriptlang.org/docs/handbook/declaration-files/dts-from-js.html\n在使用第三方库时，如果作者发布时没有附带类型定义文件，我们则可以去社区维护的 DefinitelyTyped 仓库中看看，使用 npm 命令即可查询：\nnpm info @types/react 参考资料 https://github.com/sarbbottam/write-an-open-source-js-lib https://reactjs.org/blog/2017/12/15/improving-the-repository-infrastructure.html "},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-vscode-sync/","title":"IDE：VS Code 配置同步","description":"利用一款插件来同步 VS Code 的配置到 GitHub 的 gist 上，实现多个设备间共享一套配置。","date":"August 15, 2018","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 工具, 编辑器, IDE, 配置同步","tags":"","content":"利用一款插件来同步 VS Code 的配置到 GitHub 的 gist 上，实现多个设备间共享一套配置。\nVS Code Visual Studio Code 是由微软出品的一款轻量级编辑器，兼有部分 IDE 功能。在之前，Sublime Text 是最受欢迎的编辑器（开源），也为多数前端开发者所推崇，当然说到底它依然是个编辑器。随着时间的推移，GitHub 打造了自家的编辑器 Atom，微软的 VS Code 也横空出世，更有其它优秀的轻量级编辑器在市场上展开角逐。不过，到现在来看，VS Code 可能胜出了，已成为前端开发的利器。\n前端开发的工作流向来是个令人头疼的问题，虽然说现在利用 gulp、grunt、webpack 可以解决大部分问题，但要换台电脑重新配置一遍那真的是令人不敢想象的事情。而且，开发过程中大量依赖了 VS Code 插件提高了开发效率，但要换台电脑重新配置一遍编辑器，装一遍插件那也是相当头疼，时间都浪费在了重复性工作上。\nSetting Sync Setting Sync 插件恰好就是为了解决多个设备间编辑器和插件配置同步难题的。\nSetting Sync : https://marketplace.visualstudio.com/items?itemName=Shan.code-settings-sync\n这个插件大概的原理就是将本地的 VS Code 的配置文件和插件配置同步到 GitHub 的 Gist 服务器上，然后在另一台设备上可以通过 Gist ID 和 Token ID 下载配置，即实现了多个设备间配置共享。\n插件的使用步骤在它的说明页面很详细，大概就是以下几步：\n在 GitHub 上新建一个 Personal access tokens，保存 token id 在 VS Code 中安装 Setting Sync 插件，然后输入 token id，上传配置信息，得到 gist id 在另一台设备上的 VS Code 中安装 Setting Sync 插件，然后输入 token id 和 gist id 即可同步配置 总结 现在vscode官方登录功能已经上线了，所以这个插件已经没有太大意义了，不过可以了解一下。\n"},{"section":"Blog","slug":"/blog/computer-technology/web/web-front-end-architecture/","title":"Web 前端架构设计","description":"Web 前端开发是一个零散化的过程，基本上没有专业的 IDE 来为我们提供一整套的自动化流程解决方案，如何从需求到实现一步步快速推进形成完整的工作流，在后期如何高效的进行测试和优化，让前端开发可持续化、可扩展显得极为重要。","date":"March 28, 2018","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 程序架构设计","tags":"计算机技术, Web前端, 程序架构设计","content":"让 Web 前端开发可持续化、可扩展，关注四个核心代码、流程、测试、文档。\n代码 HTML 模块化标记 构建模块化标记原则：标签表达结构，类名控制外观。这样做的好处就是，对相同类型结构的模块可以复用标签模版，同时又可以通过改变类名来灵活的控制模块的外观。例如：\n```html \u0026lt;section class=\u0026quot;theme-container-card\u0026quot;\u0026gt; \u0026lt;nav class=\u0026quot;theme-nav-block-items\u0026quot;\u0026gt;\u0026lt;/nav\u0026gt; \u0026lt;header class=\u0026quot;theme-title-xxx\u0026quot;\u0026gt; \u0026lt;h2\u0026gt;\u0026lt;/h2\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main class=\u0026quot;theme-content-xxx\u0026quot;\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer class=\u0026quot;theme-endnote-fluid\u0026quot;\u0026gt;\u0026lt;/footer\u0026gt; \u0026lt;/section\u0026gt; ``` 在这里，类名其实对应的是不同的主题样式。\n构建一个完整的页面，应该将其分解为一些更细小的可复用的单元，也就是组件模块。\n编码规范 文档类型 HTML5 的文档类型申明：\u0026lt;!DOCTYPE html\u0026gt;\nHTML 验证 规范化的 HTML 是显现技术要求与局限的显著质量基线，它促进了 HTML 被更好地运用。\n推荐：\n```html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Test\u0026lt;/title\u0026gt; \u0026lt;article\u0026gt;This is only a test.\u0026lt;/article\u0026gt; ``` 不推荐：\n```html \u0026lt;title\u0026gt;Test\u0026lt;/title\u0026gt; \u0026lt;article\u0026gt;This is only a test.\u0026lt;/article\u0026gt; ``` 省略可选标签 HTML5 规范中规定了 HTML 等标签是可以省略的。但从可读性来说，在开发的源文件中不要这样做，因为省略标签可能会导致一些问题。\n资源加载 CSS 资源（\u0026lt;link\u0026gt;）在 \u0026lt;head\u0026gt; 标签中引入，避免 DOM 加载完后重复渲染；JS 资源（\u0026lt;script\u0026gt;）在文档尾部 \u0026lt;/body\u0026gt; 闭合标签前引入，避免过早的加载 JS 阻塞 DOM 渲染。例如：\n```html \u0026lt;head\u0026gt; ... \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;base.css\u0026quot;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; ... \u0026lt;script src=\u0026quot;common.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; ``` 慎用 \u0026lt;script\u0026gt; 标签的 async 和 defer 属性。\n语义化 使用 HTML 5 新标签，构建语义化标签模块，有利于理解和提高效率。\n推荐：\n```html \u0026lt;section\u0026gt; \u0026lt;nav\u0026gt;\u0026lt;/nav\u0026gt; \u0026lt;header\u0026gt;\u0026lt;/header\u0026gt; \u0026lt;main\u0026gt;\u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt;\u0026lt;/footer\u0026gt; \u0026lt;/section\u0026gt; ``` 不推荐：\n```html \u0026lt;div class=\u0026quot;section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;nav\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;header\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;main\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;footer\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ``` 多媒体回溯 对页面上的媒体而言，像图片、视频、canvas 动画等，要确保其有可替代的接入接口。图片文件我们可采用有意义的备选文本（alt），视频和音频文件我们可以为其加上说明文字或字幕。\n推荐：\n```html \u0026lt;img src=\u0026quot;imgs/banner.png\u0026quot; alt=\u0026quot;Prairie and Horse\u0026quot;\u0026gt; ``` 不推荐：\n```html \u0026lt;img src=\u0026quot;imgs/banner.png\u0026quot;\u0026gt; 或 \u0026lt;img src=\u0026quot;imgs/banner.png\u0026quot; alt=\u0026quot;Banner image one\u0026quot;\u0026gt; ``` 这些替代文字应该描述媒体资源的内容，而不是这些媒体资源的作用、类型等。\n关注点分离 严格地保证结构（HTML）、表现（CSS）、**行为（JS）**三者分离，并尽量使三者之间没有太多的交互和联系。遵循：\n不要引入太多零散的样式表，合并成大文件。 不要使用内联样式（\u0026lt;style\u0026gt; … \u0026lt;/style\u0026gt;）、和行内样式。 不要引入太多零散的脚本文件，合并成大文件。 不要使用内联脚本（\u0026lt;script\u0026gt; … \u0026lt;/script\u0026gt;）。 不要使用表象元素（例如 \u0026lt;b\u0026gt;、\u0026lt;u\u0026gt;、\u0026lt;font\u0026gt; 等）。 不要使用表象类名（例如 center、red、left）。 这样做的好处是，代码干净整洁，利于维护。\n内容至上 不要让非内容信息污染了你的 HTML。遵循：\n不要引入一些特定的 HTML 结构来解决一些视觉设计问题。 不要将 \u0026lt;img\u0026gt; 元素当做专门用来做视觉设计的元素。 这些是什么意思呢？HTML 结构应该表达的是文档内容，而非设计要素。例如，列表 元素 \u0026lt;li\u0026gt; 前面的原点、空心圆等修饰性的东西不应该用额外的标签去实现，可以借助伪元素实现。同样地，\u0026lt;img\u0026gt; 引入的图片应该是内容相关的，而非修饰性东西。\nTab Index 在可用性上的运用 依据元素的重要性来重新排列其 tab 切换顺序。你可以设置 tabindex=\u0026quot;-1\u0026quot; 在任何元素上来禁用其 tab 切换。\n当你在一个默认不可聚焦的元素上增加了功能，你应该总是为其加上 tabindex 属性使其变为可聚焦状态，而且这也会激活其 CSS 的伪类 :focus。选择合适的 tabindex 值，或是直接使用 tabindex=\u0026quot;0\u0026quot; 将元素们组织成同一 tab 顺序水平，并强制干预其自然阅读顺序。\nID 和锚点 通常一个比较好的做法是将页面内所有的标题元素（h2、h3）都加上 ID。这样做，页面 URL 的 hash 中带上对应的 ID 名称，即形成描点，方便跳转至对应元素所处位置。\n格式化 块级元素应独占一行，内联元素放在同一行，子元素缩进使用制表符。\n推荐：\n```html \u0026lt;nav\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;span\u0026gt;Item\u0026lt;/span\u0026gt; one\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; ``` 不推荐：\n```html \u0026lt;nav\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;span\u0026gt;Item\u0026lt;/span\u0026gt; one\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;/nav\u0026gt; ``` 引号 HTML 标签属性值应该用双引号，而不是单引号。\n推荐：\n```html \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; ``` 不推荐：\n```html \u0026lt;div class='container'\u0026gt;\u0026lt;/div\u0026gt; ``` 注释 在 HTML 页面进行必要的注释是应该的，尤其是 SPA 单页面应用，标明不同的模块位置，便于维护和扩展。\n```html \u0026lt;body\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1\u0026gt;Single Page Web Application\u0026lt;/h1\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;!-- container 容器 --\u0026gt; \u0026lt;main id=\u0026quot;content\u0026quot;\u0026gt; \u0026lt;!-- Module-1 --\u0026gt; \u0026lt;section\u0026gt; ... \u0026lt;/section\u0026gt; \u0026lt;!-- Module-2 --\u0026gt; \u0026lt;section\u0026gt; ... \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;CopyRight 2018\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; ``` CSS（Sass） 模块化 CSS 构建模块化的 CSS 有多种方法，这里推荐三种：\nOOCSS 方法 Object-Oriented CSS，即面向对象的 CSS，主要有两个原则：分离结构和外观，分离容器和内容。\n分离结构和外观，意味着将视觉特性定义为可复用的单元，最简单的例子就是以主题形式定义 CSS。\n分离容器和内容，指的是不再将元素位置作为样式的限定词，定义可复用的 CSS 类名，无关于标签内容位置。\n例如：\n```html \u0026lt;div class=\u0026quot;toggle simple\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;toggle-control open\u0026quot;\u0026gt; \u0026lt;h1 class=\u0026quot;toggle-title\u0026quot;\u0026gt;Title\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;toggle-details open\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; ... \u0026lt;/div\u0026gt; ``` SMACSS 方法 Scalable and Modular Architecture for CSS，即模块化架构的可扩展 CSS，它将样式系统划分为五个类别：\n基础\n如果不添加 CSS 类名，标记会以什么外观呈现。\n布局\n把页面分成一些区域。\n模块\n设计中的模块化、可复用的单元。\n状态\n描述在特定的状态或情况下，模块或布局的显示方式。\n主题\n一个可选的视觉外观层，可以让你更换不同主题。\nOOCSS 与 SMACSS 有许多相似之处，它们都把样式的作用域限定到根节点的 CSS 类名上，然后通过皮肤（OOCSS）与子模块（SMACSS）进行修改，后者使用了 is 前缀的状态类名。例如：\n```html \u0026lt;div class=\u0026quot;toggle toggle-simple\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;toggle-control is-active\u0026quot;\u0026gt; \u0026lt;h2 class=\u0026quot;toggle-title\u0026quot;\u0026gt;Title\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;toggle-details is-active\u0026quot;\u0026gt; ... \u0026lt;/div\u0026gt; ... \u0026lt;/div\u0026gt; ``` BEM 方法 Block Element Modifier，即块元素修饰符，只是一个 CSS 类命名的规则，建议每个元素都添加带有如下内容的 CSS 类名：\n块名\n所属组件的名称。\n元素\n元素在块里面的名称。\n修饰符\n任何与块或者元素相关联的修饰符。\n例如：\n```html \u0026lt;div class=\u0026quot;toggle toggle--simple\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;toggle__control toggle__control--active\u0026quot;\u0026gt; \u0026lt;h2 class=\u0026quot;toggle__title\u0026quot;\u0026gt;Title\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;toggle__details toggle__details--active\u0026quot;\u0026gt; ... \u0026lt;/div\u0026gt; ... \u0026lt;/div\u0026gt; ``` 以上三种方法各有优势，提供给了我们构建模块化 CSS 的方式，也是三种思维方式，在实际开发过程中可以借鉴。\n编码规范 ID and class 命名 命名应该遵循语义化原则，表达其具体的用途和含义，这样做的好处是更容易理解，同时发生变化的可能性也很小。同时，单词的分隔符统一使用中划线 “-”。\n推荐：\n```css .bg-important { background-color: red; } ``` 不推荐：\n```css .bg-red { background-color: red; } ``` 命名不要出现表象词，比如颜色等，同时表达的含义应具体而不是通用化。\n避免使用 ID 通常，在样式文件中不应该出现 ID，所有的样式均应该由 class 来定义，因为 ID 会导致样式不可重用的后果。\n避免使用标签名 在选择器中不应该出现标签名，这样做的好处是可以提高样式的复用性。\n推荐：\n```css .container \u0026gt; .content \u0026gt; .title { font-size: 2em; } ``` 不推荐：\n```css div.container \u0026gt; main.content \u0026gt; h2.title { font-size: 2em; } ``` 选择器中出现标签名的话，会将外观（CSS）与结构（HTML）绑定在一起，不利于重用。\n精确匹配 在使用选择器时应该尽可能的精确匹配到目标元素，这样发生问题时更容易找到问题也有利于性能优化。\n推荐：\n```css .content \u0026gt; .title { font-weight: bold; } ``` 不推荐：\n```css .content .title { font-weight: bold; } ``` 如果匹配的是直接子代元素，就使用直接子代选择器，这样性能更好，也不容易影响非直接子代元素的后代元素样式。\n缩写属性 部分的 CSS 属性值是可以进行缩写的，这样编码效率也会提高，但缩写属性也应该慎用，因为缩写属性牵扯到顺序问题，像 font、background 这些顺序难记的属性不应该使用缩写，而像 padding、margin 这些常用并且顺序好记的属性应该使用缩写。\n推荐：\n```css .content { background: #000; background-image: url(\u0026quot;./imgs/bg.png\u0026quot;); padding: 0 20px 0 10px; } ``` 不推荐：\n```css .content { background: #000; background-image: url(\u0026quot;./imgs/bg.png\u0026quot;); padding-left: 10px; padding-right: 20px; } ``` 0 与 单位 如果属性值为 0，不在使用单位。\n推荐：\n```css { padding: 2px 0; } ``` 不推荐：\n```css { padding: 2px 0px; } ``` 十六进制表示法 当使用十六进制表示颜色值时，尽可能用更简短的方式，例如使用 3 位。同时，使用小写表示，不要使用大写。\n推荐：\n```css { color: #d8a; } ``` 不推荐：\n```css { color: #DD88AA; } ``` 声明顺序 采用统一的属性声明顺序，可以提高可读性。通常，应遵循以下顺序（依次从上至下）：\n结构性属性： display; position、left、top、z-index 等; overflow、float 等; width、height; margin、padding。 表现性属性： color、text; font; background、border 等。 分号 与 空格 CSS 属性值后必须用分号结束，每条属性声明都应该使用新的一行，并且在冒号与属性值中间空出一个空格，提高可读性。\n推荐：\n```css .content { width: 200px; margin-bottom: 10px; } ``` 不推荐：\n```css .content { width:200px; margin-bottom:10px } ``` 规格分隔 每个规则之间使用一行进行分割，每个选择器应该使用新的一行。\n推荐：\n```css .container { padding: 10px 20px; } .content, .item:hover { color: orange; } ``` 不推荐：\n```css .container { padding: 10px 20px; } .content, .item:hover { color: orange; } ``` 引号 属性值中的引号应该使用双引号，而不是单引号。\n推荐：\n```css { background-image: url(\u0026quot;./imgs/bg.png\u0026quot;); } ``` 不推荐：\n```css { background-image: url('./imgs/bg.png'); } ``` 使用 Scss 语法 SCSS 是 Sass 3 引入的新语法，其语法完全兼容 CSS 3，并且继承了 Sass 的强大功能。Scss 语法相较于 Sass 语法更接近 CSS 语法，所以统一使用 Scss 语法。\n选择器嵌套 使用 Sass 预处理器后，使得我们可以进行选择器嵌套，大幅度提高了编码效率，也使 CSS 代码变得更为简洁，结构更为清晰。\n推荐：\n```css .container { padding: 10px 20px; \u0026amp; \u0026gt; .content { border: 1px solid black; } } ``` 不推荐：\n```css .container { padding: 10px 20px; } .container \u0026gt; .content { border: 1px solid black; } ``` 选择器嵌套顺序 属性声明遵循一定顺序，同样地，选择器的嵌套也应该遵循一定的顺序以提高可读性。 通常，应该遵循以下顺序（依次从上至下）：\n当前选择器的样式属性； 父级选择器的伪类选择器 (:first-letter、:hover、:active 等)； 伪类元素 (:before and :after)； 父级选择器的声明样式 (.selected、.active、.enlarged 等)； 用 Sass 的上下文媒体查询； 子选择器作为最后的部分。 推荐：\n```css .item { // 1. 当前选择器样式属性 font-size: .8em; // 2. 父级选择器的伪类 \u0026amp;：hover { color: orange; } // 3. ::before \u0026amp;\u0026amp; ::after \u0026amp;::before { content: attr(\u0026quot;tip\u0026quot;); display: block; } // 4. 父级选择器声明样式 \u0026amp;.selected { background-color: red; } // 5. 上下文媒体查询 @media screen and (min-width: 768px) { font-size: 1.2em; } // 6. 子类选择器 \u0026amp; \u0026gt; .text { font-weight: 400; } } ``` 注释 在使用 Sass 写 CSS 时有很大的灵活性来组织代码结构，但注释也是很必要的。\n文档注释 通常写在文件的开始部分，涉及文档的概述以及版本号，及其依赖等。\n```typescript /*! normalize.css v8.0.0 | MIT License |github.com/necolas/normalize.css */ ``` 模块注释 模块的注释使用多行注释，标明该模块、代码块的作用等。\n```typescript /** * Remove the margin in all browsers. */ ``` 普通注释 对于一些比较关键的代码，要进行注释，写在单行即可。\n```typescript /* menu-1 */ ``` JavaScript 前后端分离后，前端需要写更多的业务逻辑代码，不再是单纯写 HTML 与 CSS 了，很多需求的实现都依靠于 JavaScript。\n基于 JS 的 Web 应用 创建可扩展且可持续的设计系统，并维护一套高质量的代码。\n选择框架 没有哪个 JavaScript 框架是完美的，任何一个框架都是基于 JavaScript 来实现的，框架提供给我们的是一种设计模式和更优的实现方式。\n选择哪个框架，首先我们要考虑业务需求是否复杂，大多时候使用框架反而会增加代码量和无畏的复杂逻辑。其实，很多时候我们是用不到框架的，我们更多时候用到的是一些例如 Jquery 库、Bootstrap CSS 库这些工具，当现有的业务手动实现遇到技术瓶颈时，我们才应该去考虑使用一些开源的框架和工具。\n永远保证采用最精简的方案做项目，而不是一开始就准备一大套工具和大规模的启动页，这对我们没有任何好处。\n维护整洁的代码 通常，开发一个项目，尤其是多人协作的过程中，应该遵循一定的“JavaScript”开发编码规范，这样整体代码具有相同的风格，利于后期维护，即便是再简单的项目也应该如此。\n保持代码的整洁性\nJavaScript 是一种脚本语言，而且语法相对松散，编写恰当的 JavaScript 代码非常关键，最好在项目中结合单元测试使用一些格式/错误提示，而且能帮助团队编写符合规范的代码。其实，JS Hint 是这些工具中一个很好的例子。\n创造可复用的函数\n编程语言最大的特点就是可复用性，在开发过程中应尽可能的将有类似行为的过程操作抽象出来，形成一个可复用的函数，这样做可以大幅减少整体代码量，也能够更好的组织代码结构。\n编码规范 缩进 保持良好的代码缩进习惯，缩进统一使用**“制表符”**。\nIIFE 将代码包裹在一个 IIFE（Immediately-Invoked Function Expression，立即执行函数）中，创建独立的作用域，保证每一个人的代码不会污染全局作用域。\n推荐：\n```typescript (function(window) { ... })(window); ``` 严格模式 使用严格模式保证 JavaScript 代码的健壮性，严格模式可以作用于整个脚本或者一段代码块中，为了尽可能的不引起冲突，请在代码块中使用严格模式。\n推荐：\n```typescript (function(window) { 'use strict'; ... })(window); ``` 变量声明 推荐：\n```typescript var a = 1, b = 2; ``` 不推荐：\n```typescript var a = 1; var b = 2; ``` == 与 === 比较时如果使用 == 的话，会忽略掉比较对象的类型，应该总是使用 === 进行精确的类型与值比较。\n推荐：\n```typescript 0 === '' // false ``` 不推荐：\n```typescript 0 == '' // true ``` 声明提升 JavaScript 中有声明提升的机制，因为不存在块作用域，在同一个作用域中不同代码块中声明的变量与函数最终都会被提升到作用域顶层声明。\n```typescript var a; a = 1; if (a) { var b = 1; } ``` 等同于：\n```typescript var a, b; a = 1; if (a) { b = 1; } ``` 因为存在声明提升的机制，所以在编码时应该将变量与函数声明写到作用域顶层。\n条件运算符 在逻辑比较简单时，应该使用条件运算符而不是 if…else 语句。\n推荐：\n```typescript a === 1 ? console.log('true') : console.log('false'); ``` 不推荐：\n```typescript if (a === 1) { console.log('true'); } else { console.log('false'); } ``` 函数声明 函数的声明应该在作用域的顶层，而不是某个语句块中，因为 JavaScript 没有块作用域的概念，并且由于声明提升的原因，最好将函数声明写在作用域的顶层。\n推荐：\n```typescript function foo() {} if(b){ var bar = function() {}; ... } ``` 不推荐：\n```typescript if(b){ function foo() {} function bar() {} ... } ``` 闭包 JavaScript 代码中大量的使用了闭包机制，这是一个很好的机制，但是应该时刻注意闭包所带来的内存泄漏的问题。应该在使用完变量后，尽可能将不再需要使用但存在内存泄漏隐患的变量手动释放。\neval() 函数 eval() 函数可以将字符串编译为 JavaScript 代码然后执行，但不应该使用它，一方面是效率很低，另一方面则是涉及到安全问题。\nthis 关键字 由于 JavaScript 的词法作用域机制，以及代码中大多时候都会存在多层嵌套的函数，this 关键字的指向很容易被搞错，如果要在内层函数使用外层函数的 this 引用对象，应该使用一个变量在外层函数作用域内将其缓存起来，然后使用该变量在内层函数中进行引用。\n数组初始化 数组的初始化应该使用字面量而不是构造函数，构造函数的参数容易引起误会。\n推荐：\n```typescript var a = [3]; // [3] ``` 不推荐：\n```typescript var a = new Array(3); // [undefined, undefined, undefined] ``` 引号 JavaScript 中引号统一使用**“单引号”**，因为这在书写 HTML 字符串模版属性时将非常有用。\ntoString() 可以自定义 toString() 函数来控制对象的字符串化，但要保证该方法始终能够正确执行。\n注释 JavaScript 是一个灵活性很大的语言，那么就会带来代码维护和阅读上的困难，良好的注释会帮助我们减轻这些负担。\n文档注释 通常写在文件的开始部分，涉及文档的概述以及版本号，及其依赖等。\n```typescript /*! jQuery v1.11.3 | (c) 2005, 2015 jQuery Foundation, Inc. | jquery.org/license */ ``` 方法注释 对于模块以及方法尤其要写明注释，这对于如何理解你的方法是至关重要的，应该遵循：为什么要写这个方法或者模块，解决了什么问题，而不是这个方法是用来干什么。\n```typescript /** * ... * * @description \u0026quot;...\u0026quot; * @author mrwang * @param {Jquery Object} $all_a * @returns */ ``` 普通注释 普通注释可分为多行注释和单行注释，在必要的地方进行注释即可。\n```typescript 单行： // somethings 多行： /* somethings */ ``` 流程 流程的核心是工作流。工作流指的就是把想法需求变成现实的过程，从产品的角度来看，就是修复 bug、迭代升级的一系列流程和方法。\n过去的工作流 在过去，Web 前端开发还是基于 PSD 文档编写标签和一堆页面的时代，但这个时代从几年前就已经结束了。前端开发不再只是单纯的为了做出好看漂亮的页面，而是更关注高效率开发、构建高性能应用以及快速迭代。\n过去的工作流： 需求 -\u0026gt; 线框图 -\u0026gt; 开发（设计）并行 -\u0026gt; 前端\n现代的工作流 过去的工作流根据角色逐级交付，前端开发通常是在项目最后阶段才参与的，这样的流程效率很低，而且前端的参与度太低，产品最终质量无法保证。现代的工作流则是相反地，前端将参与整个项目阶段，更大程度地保证产品质量和后期迭代速度。\n现代的工作流： 需求 -\u0026gt; 原型 -\u0026gt; 开发\n需求 工作流一般从收集需求开始，现代的工作流在这个阶段，将会改变需求所面向的人群，会让交互设计、视觉设计、后端开发以及前端开发人员共同参与。这样一个来自交叉领域的团队，意味着我们将注重创建一个完整的解决方案，而不是一个大概的线框图了。来自不同领域的人员共同参与需求收集的过程，能尽早的发现需求中存在的问题和不足。\n原型设计 以往的工作流偏向于在每个环节交付一个成品，而现代的工作流更注重在用户交互模型、视觉设计和前端解决方案中的持续迭代。\n原型设计则给我们提供了讨论和反馈的公共空间，在把我们丰满的想法通过在桌面和移动端浏览器中实现之后，我们可以基于原型进行讨论、修改、增删，直到开发人员和产品负责人对原型满意，就可以进入下一步开发环节了。\n相对来说，原型设计阶段实现起来成本要低得多而且更为灵活，要确保在这个阶段将产品原型确定，然后在开发环节将会节省不少时间成本。\n程序开发 实际上，在通过原型设计阶段之后，开发环节只需要关注数据处理和业务逻辑的实现即可。优秀的原型设计基本上可以直接拿来在开发环节中使用，不需要太多额外的修改，而且这对于测试人员来说也更为方便。\n前端工作流 前端开发是一个零散化的过程，没有专业的 IDE 工具为我们处理繁多复杂的任务，一个流畅、高效率的前端工作流显得格外重要。\n开发工具 我们要安装很多必要的工具来搭建一个适合我们的开发环节和软件运行环境，包括代码编辑器、常用浏览器、版本控制工具等等。这个过程要尽可能的流畅，这样开发人员才能更快的进入实际编码工作中。\n本地部署 进入到实际编码工作过程中，首先就是要将项目源码使用版本控制工具从版本库中下载下来，然后部署在本地，成功运行后才可以开始编码。这个过程实际上不复杂，例如，如果采用了前后端完全分离的开发/部署方案，我们可能会在前端使用一个 nginx 服务器作为代理服务器，这反而是增加了本地部署的复杂度。所以，在这个过程中，涉及到的流程中的细节必须完整的写在README.md文件中，帮助任何一个开发人员都能流畅、快速地搭建好本地环境，成功部署应用。\n开发 在开发过程中，如果需求发生了微小的变动，我们应该尽可能对系统做最小的改动来实现这个需求。通常好的做法是，加入新的实现方案，去覆盖掉原有的实现方案；而比较糟糕的做法是，在原有的实现方案上进行更改。\n发布 项目源码通常使用版本控制工具来进行管理，而编译之后的生产环境代码如何发布也是一个值得关注的问题。\n提交编译之后的代码 在使用的大多数 github 开源项目中，我们会发现通常会有一个dist目录，而这个目录中其实就是编译之后的代码。这样做的好处是，其它人可以很方便的将这些编译之后的代码复制到本地成功运行，而不需要经过漫长的搭建编译工具的过程。\n然而，这么做也有不好的地方，其中比较重要的就是合并代码时的冲突问题，当然最简单的解决方法就是将整个项目重新编译一遍进行提交，但这也意味着不同分支将不会有合并请求。\n持续集成的服务器 使用类似 Jenkins 或 Travis CI 的服务可以避免出现以上问题，它们可以在我们将代码发布到服务器之前，先对代码做一些处理。这意味着我们可以在版本库中忽略编译后的资源文件，CI 服务器会自动执行我们的编译任务，然后将代码发布到服务器。\n这样做的好处不仅可以保持代码库的整洁，也不会出现提交编译后代码合并冲突的情况。\n标签分支 Git 有个强大的功能就是创建标签分支，我们可以在任何分支上创建便签，便于我们进行选择性的发布。\n例如，有时候我们创建了一个分支版本，并添加了一些功能或者修改了一些 bug，但我们并不希望将这些改动合并到主干上去，这个时候则可以在这个分支上创建标签，并进行发布即可。\n发布渠道 如果我们的项目被其他人的项目广泛地引用，发布渠道则是比较重要的。这些渠道有很多，下面列举一些常见的包管理器：\nNPM（Node Package Manager） Bower Ruby Gems RPM Sublime Text Package Control 使用这些包管理器的好处如下。\n发布不同的版本\n用户可以选择性的使用某一版本，而不是跟随开发者升级。\n版本更新通知\n良好的通知机制和内部升级系统，可以让用户很方便的获知新版本的发布信息。\n从私有库中发布代码\n更多的时候我们的项目源码是维护在私有库中的，包管理器允许我们将代码发布到公共空间，让更多的普通用户来使用。\n任务处理器 对于前端开发者来说，每次修改文件都要手动刷新浏览器，验证改动效果；在生产环境中部署时，要手动使用工具压缩代码和图片，减小文件体积；没办法很好的利用语言的新特性（ES6、ES7 等）来提高编码效率等等，这些场景下的任务实际上占用了开发者大量的编码时间，去做一些与编码无关的事情，但这些事情又能很好的优化我们的应用性能或者开发工作流。\n于是出现了一些任务流管理工具，例如 gulp、grunt、webpack 等等，这些任务处理器工具 实现了一些功能：\n清理文件夹 编译 Sass 编译 ES6、ES7 代码 合并文件 文件压缩 自动生成浏览器厂商的 CSS 属性前缀 监听文件改动自动刷新浏览器 启动静态的 Node 服务器 这些任务处理器提供的功能远远不止这些，但这些都是比较常用的功能，能很好的优化我们的开发工作流。将与编码无关的事情交给任务处理器自动化处理，然后开发者专注于编码，实现业务即可。\n无论选择哪一种工具，gulp 还是 grunt，实际上它们每个都能替代对方，实现所有功能，只不过配置的代码风格不同，以及优势不同。我个人比较推荐的是 gulp + webpack 相互配合来构建一个自动化的任务流，gulp 负责编译 Sass、压缩图片等任务，而 webpack 负责打包 JavaScript 模块代码，编译 JS 文件等任务。\n测试 在一个大型项目，尤其是多人参与的前端项目中，每一次提交、合并都很有可能会影响到原有的系统功能，团队开发者并不会太多地去关注这些问题，而作为一个架构师或者负责人，对于这种问题应该重视，而解决方案就是：测试。一个人并没有太多的精力和时间去评估每一段代码对原有系统所造成的影响，但可以借助自动化的测试工具来验证我们的应用程序是否能够正常的运行。\n在规划测试过程中，有以下几点应该尽可能的去遵守：\n测试用例应该在建站的同时，甚至是在建站之前就开始编写。 测试代码是可运行的真实代码，应该一起提交到系统代码库中。 必须在所有的测试用例都通过之后，才能把代码合并到主干中。 在主干上运行测试工具，结果应该都为通过。 因此，与其将时间花费在评估每一段代码上，不如去关注如何构建高质量的系统和完整的测试。\n单元测试 单元测试是最普遍、最常见的软件测试方法，是将应用程序分解为尽可能小的函数，并创建可重复的、自动化的测试用例的过程。在条件不变的情况下，单元测试应该总是产生相同的结果，它为今后所有应用程序的代码提供构建的基础。\n如果没有单元测试，不常用的函数可能长达数月都不会被发现有 bug；相反，通过使用单元测试，我们可以在任何代码合并到主干之前就验证每个系统函数的功能，不会等到代码实际应用的产品中时还会出现问题。\n无论是前端还是后端语言，都有一套成熟完整的单元测试框架，例如 Java 的 JUnit，PHP 的 PHPUnit，Node 的 NodeUnit 以及 JavaScript 的 QUnit。\n单元 **“一次只做一件事，并把它做好”是构建基于单元测试的应用程序的原则。**开发者在写函数时，应该尽可能的抽象、分解成更小的函数单元，如果在一个函数中融入太多的业务逻辑以实现更多的功能，这样不仅开发效率降低，而且增加了测试和维护的难度，因为这样的函数无法复用。\n这有一个例子：通过客户地址，计算出将产品从最近的分拨中心运输给客户的运费。\n如何编写函数来实现这个功能，并将其分解为更小的单元，一般可以将其分解为以下三步，也就是三个函数单元：\n根据地址找到最近的分拨中心； 计算两个地址之间的距离； 根据距离计算运费。 这样的话，编写三个函数要比编写一个函数来实现这个功能好得多，因为 2、3 步的函数复用的概率是相当大的，这样也符合“一次只做一件事，并把它做好”的理念。\n更好的测试 **在测试过程中，我们可以测试每个独立且可重用的函数，而不是测试应用程序所能计算的每一条运输线路。**编写单元测试在开发的前期可能显得工作量变大了，但这为避免以后产品上线出现大量 bug 来说是值得的；而且越到后期，开发新功能所需要的新函数会越来越少，有大量可复用的函数提供给我们来实现新的、高复杂度的功能。\n测试驱动的开发（TDD） 通常来说，我们的思路应该是先编写业务代码，再去编写测试代码。但测试驱动的开发（test-driven development，TDD）则颠倒了这一思路，它将单元测试放在第一位，之后才是编写业务代码。\n但如果为还没有创建的函数编写测试用例，岂不是肯定无法通过测试？实际上，**测试驱动的开发的目标是，通过测试用例来描述一个正确编写的系统应如何工作，并为实现这个系统来铺平道路。**所以，这样反而会提高编写业务代码的效率。\n如何进行单元测试 我们可以使用 QUnit 来为 JavaScript 进行单元测试。单元测试的核心理念非常简单，它的基本思路就是调用要测试的函数，传递一些预设的参数，并描述结果应该是什么。\n根据单元测试工具反馈的结果，我们可以及时修复应用程序中出现的 bug，并能以比较细小的粒度获取到出现 bug 的精确位置。\n测试覆盖率 一个产品的开发过程中，实际上很难做到 100% 的测试覆盖率（大多数的产品都不是基于 TDD 的开发模式），在这种情况下做到多少测试覆盖率才合适也是很难把握的一件事。如果要测试所有的代码，很可能将会导致开发进度停滞不前；但同样地，测试覆盖率不够，将会遗漏很多关键性问题。\n解决分歧点 为已有的项目设计单元测试，大部分情况下，你没有充足的时间为先有的功能编写 100% 覆盖率的测试集。但测试覆盖率的好处是，即使一个单一的测试也能够为系统建设贡献价值。因此，在决定从哪开始编写单元测试时，可以从能够获得最大收益的地方开始。有时候，最大的收益就是为系统最简单的部分编写单元测试。\n一旦有了能提供基本覆盖率的测试集，就可以寻找系统中最关键的部分，或者过去频繁出问题的部分，在需求列表中为它们分别创建需求，并确保尽快推动这些需求。\n从测试覆盖率开始 **如果能在新项目的启动阶段就开始规划单元测试工作，除了设置好测试框架之外，更重要的是要确保开发流程本身为单元测试做好了准备。**就像写文档和代码审核一样，写单元测试也要花费不少时间，你需要确保任何需要测试的需求都有额外的时间来编写单元测试，并且确认所需的测试覆盖率。\n在开发每个系统功能的过程中，应该至少留出 1/3 到 1/4 的时间来编写测试用例，剩下的时间则用来实现业务代码。所以作为一个前端架构师应该争取更多的时间，虽然会花费多一点的时间，但是这其实会节省很多后续回头追查 bug 的时间。\n并不是所有的功能都需要同样的测试覆盖率，但所有的需求都是以测试覆盖率的相关任务开始的，只有当所有人都认为给这些任务写测试用例没有必要时，才考虑去掉它。这样我们才能确信，对于任何需要测试的功能，都已经安排了足够的时间去完成它们。\n性能测试 任何测试都是为了避免不流畅的用户体验，而网站是严重依赖于网络的，鉴于网络情况浮动较大，糟糕的网站性能正是导致用户体验不流畅的主要原因之一。性能测试虽然不是针对系统或视觉问题的测试，却也是测试库的重要组成部分。\n性能测试衡量的是影响用户使用网站的流程程度的关键指标，包括页面大小、请求数量、首字节时间（time of first bite，TTFB）、加载时间和滚动性能等等。\n性能测试的关键是制定合适的性能预算并坚持下去。\n制定性能预算 制定性能预算是指为每个关键指标设定目标值，然后在所有代码合并或部署之前持续测试这些指标。若有任何一个指标没通过测试，则需要调整新增的功能，或删除一些其它功能。\n作为一个前端开发者，很多人习惯了使用例如 JQuery、BootStarp、Angular 等库和框架，一旦离开这些工具，就觉得开发工作无法进行下去。但这些工具通常非常耗费流量资源，会显著的增加应用程序大小，实际上我们用到这些工具提供的功能可能连三分之一都不到。所以，用最简洁的方案实现我们的需求是首要选择。\n竞争基线 制定性能预算的一种方法是参考竞争对手。虽然“至少我比某某更好”不能作为网站性能不佳的借口，但是这种方法可以保证你有一定的竞争优势。\n通过对竞争对手的网站性能进行分析，你的目标不是要达到竞争对手的水平，而是要确保领先竞争对手至少 20% 甚至更多。这 20% 的优势，是用户将你和竞争对手区分开来所需要的。\n优化关键指标不能一劳永逸，它需要的是持续监控。可以确定的是，在你进行不断的优化过程中，你的竞争对手也不会坐以待毙，他们也在寻找更优的方法来改善他们自己的网站。\n平均基准 不管你的竞争对手是谁，把你的网站性能基线与行业平均水准和通用的最佳实例相比较总是必不可少的。我们没有理由因为竞争对手的落后而保持平庸。\nHTTPArchive 是个不错的服务，它测试并记录了几十万个网站的各种性能指标。\n原始指标 网站性能最基本的测试是看渲染页面所需要的资源，包括这些资源的大小和总数。\n页面大小 随着网络的发展，用户需求的提升，网站页面正在变得越来越大。虽然网站大小并非影响网站加载速度的唯一因素，但它确实对此影响重大。而且，在现在移动优先的时代，越来越多的用户通过移动设备来访问我们的网站，而他们要为数据流量付费，页面越大则意味着用户要花更多的钱。\n我们一些显而易见的地方缩减页面的大小：\n图片\n优化 PNG 图片，降低 JPEG 图片的质量。 利用新的响应式的 \u0026lt;picture\u0026gt; 标签和 srcset 属性来下载大小合适的图片。 制定一个预算，如果没有移除任何图片，就不增加图片的大小。 自定义字体\n制定一个字体预算，不考虑增加第二种或第三种字体。 考虑必要的字体粗细，因为每增加一种粗细变化，都会使字体文件增加几千个字节。 虽然字体图标不错，但要注意文件大小，尽可能只引入需要的字体文件，不要将全部的字体文件引入。 JavaScript 库和框架\n针对现代浏览器，尽可能的不要使用 JQuery，因为它的文件非常的大。 能用 CSS 实现的一些效果，不要引入其它的 JS 插件来实现。 像 Angular 这样大型的框架，要慎重考虑，如果可以使用更轻的框架例如 React 来实现你的需求，则要进行替换。 CSS 框架很多，但实际上框架提供的样式我们能使用到的并不多，而且基于已有的 CSS 样式表来编写我们自己的样式很可能会陷入困境。 使用压缩\n对文件和图片进行压缩，在服务器上开启 gzip 压缩，这些都是缩减页面大小的关键步骤。 HTTP 请求次数 浏览器对页面渲染的所需的每个文件都要进行 HTTP 请求。**因为每个浏览器对 HTTP 请求的次数有但域名限制，所以大量单独的文件意味着浏览器必须进行多轮并发请求。**在速度较慢的网络环境中，这么多并发请求会造成很复杂的影响。因此，减少获取所需文件的并发请求次数，效果会更显著。\n可以通过以下方法减少并发请求次数：\n减少 HTTP 请求次数\n将多个单独的 CSS、JavaScript 文件合并成一个文件。 把多个单独的图片文件合并成一个图片。 延迟加载最初不需要加载的资源文件。 增加浏览器每次并发请求的资源个数\n分拆静态资源到不同的服务器（CDN），可以使得浏览器单次并发下载更多的资源，因为浏览器的并发请求数量限制是针对单个服务器的。 计时度量 除了站点的资源数量和大小，还有其他的计时度量会影响用户对网站性能的体验。\n首字节时间\n首字节时间是指从浏览器请求网站页面开始，到浏览器接收到第一个字节之间的毫秒数。这个数值用来测量浏览器和服务器之间的连通路径，包括 DNS 查询、初始连接和数据接收。它并不是判断站点性能的最佳标准，却是一个值得关注的指标。\n开始渲染时间\n更有价值的计时度量是“开始渲染时间”。这个度量是指用户开始在页面上看到内容的时间。这意味着所有阻塞渲染的文件都已经加载完成，浏览器已经开始渲染文档模型了。可以通过以下方式优化开始渲染时间：延迟加载阻塞渲染的 JavaScript 和 CSS 文件、将关键的 CSS 代码内联到页面头部、用数据 URI 代替图片资源，以及延迟加载所有在文档模型渲染完成后才下载的资源。\n文档完成时间\n只要最初请求的资源已经加载成功，就可以认为文档“完成”了。文档完成时间不包括 JavaScript 中拉取资源消耗的时间，因此延迟加载的资源不会影响到这个指标。\n混合度量标准 混合度量标准不是度量离散的值，而是根据多个性能指标综合打分得出。\nPageSpeed 分数 PageSpeed 是 Google 开发的网站工具和 Chrome 浏览器的扩展程序，用来分析站点的性能和网站的可用性，它给出一个用百分比表示的分数，并解释了提高分数的方法。测试包括：\n是都存在阻塞渲染的 JavaScript 或者 CSS 重定向至登录页 图片优化 文件压缩 服务器响应时间 服务器端压缩 服务器端缓存 点击目标的大小 窗口可见区域的配置 清晰的字体大小 Speed Index 指标 根据 Speed Index 项目主页上的描述，Speed Index 指的是页面可见部分展示完成的平均时间，该指标通过用毫秒表示，并取决于视图端口的大小。\n混合度量标准的分数考虑了上述多个单一的度量标准，并将这些标准和页面加载时用户可以实际看到的标准结合起来。Speed Index 是度量终端用户实际体验的最好标准之一。\n设置性能测试 性能测试涉及的指标繁多，我们不可能也不愿意去手动进行测试，我们可以借助一些自动化工具插件来完成这些工作，例如 Grunt PageSpeed 插件，Grunt PerfBudget 插件。\n视觉还原测试 对于前端开发者来说，尽可能的高度还原 Photoshop 设计稿是我们的责任，也是评价我们工作的一项重要因素。在一个多人合作的团队中，很有可能会出现这种情况：一段时候后你发现原来已经做好的界面却出现了问题，于是你开始调整。但是，这样的情况会频繁的反复发生，其中很大一部分原因在于项目过大，团队开发者过多，很难让普通开发者去关注整个系统的设计，往往就会出现一个人写的样式影响了另一个人写的样式，从而导致界面发生变化。\n因此，确保每一次的提交、合并都不会影响已经完成的界面效果是至关重要的，除了提高开发者的专业素养之外，我们需要进行视觉还原测试来帮助我们解决这个问题。\n常见的质疑 为何已经完成的页面界面会在后来发生变化，通常有这么几种原因：\n不了解情况的开发者\n即使你的代码完美无缺，但很难确保和你同步进行开发的其他人，或者说后期维护的开发者，他们写的 CSS 类名、样式不会影响到你写的代码。\n不一致的设计\n通常一个比较大型的项目中，Photoshop 设计稿文件也非常得多，如果后期发生了一些全局性的细微变动，很难确保设计师会将变动更新到每一个文件，这就会出现不一致的设计稿。\n举棋不定的决策者\n通常来说，改动是不可避免的，但是如果决策者仔细研究足够多的功能，进而频繁的进行改动，一次又一次的进行原型开发会大大降低开发效率，原型开发应该是基于设计快速迭代之后的最终设计稿做出。\n一个经过测试的解决方案 以上的场景中都突出了更深刻的组织层面的问题，它们可以通过适当的测试覆盖率来缓解。我们不去测试 JavaScript 函数的有效返回结果，而是抓取已授权的设计系统的视觉外观，从而验证我们没有偏离该系统。在提交之前抓取这些视觉还原是保证设计系统一致性的关键。\n视觉还原测试让我们可以将正在开发的版本或者即将部署的版本（新版本）与正确的版本（基线版本）进行视觉对比。这个过程只不过是抓取基线版本的截图，与最新版本进行对比，并找出像素层面的差异。\n通过把这些基线图片提交到仓库，或者在测试库里将其标记为通过，我们就对任何特定的功能在像素级别的视觉表现有了签名确认并一致认同的核对记录。在任何代码提交到主分支之前，视觉还原测试提供了一种测试网站所有功能的方法，以确保没有出乎意料的视觉改变。\n这样，我们通常也会分辨出到底是设计师更新设计稿的疏忽还是正常的需求变更。\n视觉还原测试的多面性 借助于多种技术和流程，视觉还原测试可以有多种风格。虽然新的工具不断地被发布到开源社区，但他们通常是一小部分功能的组合。大多数工具可以归属为以下几类。\n基于页面的比较\nWraith 是一个基于页面的比较的例子。它使用 YAML 作为设置文件，因此可以很轻松地比较来自两个不同来源的一大串页面列表。当你不期望两个不同来源的页面有任何差异时，比如需要比较线上页面和在工作中即将部署的页面时，这个方法会很合适。\n基于组件的比较\nBackstopJS 在基于组件或者基于选择器的比较方面，是一个绝佳的选择。基于组件的比较工具使你可以抓取独立的页面片段进行对比，这样可以写出更有针对性的测试，并防止误报。\nCSS 单位测试\nQuixote 是一类比较独特的比较工具，用于比较 CSS 单位的差异，而不是视觉上的差异。Quixote 可以设置 TDD 模式的测试用例，这些用例会设置好预期的 CSS 数值（比如字体大小为 1em，侧边栏的内边距是 2.5%），然后检测页面是否满足这些条件。它还可以诊断页面是否遵守品牌的视觉规范，比如 logo 的尺寸是否正确，以及 logo 与其它内容是否保持恰当的距离。\n基于无头浏览器的测试\nGemini 是一款可以使用无头浏览器 PhantomJS 的比较工具，它可以在抓取截图之前加载 Web 页面。PhantomJS 是 JavaScript 实现的 WebKit 内核的浏览器，这意味着它速度非常快，并且具有跨平台的一致性。\n基于桌面浏览器的测试\nGeimin 非常独特，它支持在在传统的桌面浏览器上运行测试用例。为了达到这个目的，Gemini 使用 Selenium 服务器打开并操作系统中安装的浏览器。这种方式没有基于无头浏览器的方式快，而且也受到系统安装的浏览器版本的影响。但是它更接近真实情况，并且可以发现某个特定浏览器引入的 bug。\n包含脚本库文件\nCasperJS 是一个导航脚本库，可以和 PhantomJS 等无头浏览器协同工作。该工具可以和在浏览器中打开的页面进行交互。使用它，你可以点击按钮，等待模态窗口，填充并提交表单，最终对结果进行截图。CasperJS 还可以在 PhantomJS 打开的页面中执行 JavaScript，你可以隐藏元素、关掉动画，甚至还可以使用静态模拟内容替换掉动态真实内容。\n基于图像用户界面的比较工具，支持更改确认\nDiffux 项目存储了测试历史数据，并可以在基于 Web 的用户界面中提供测试结果的反馈。基准图像存储在数据库中，任何对它的改动都必须在该应用界面中标记为接收或者拒绝。\n基于命令行的比较工具，支持更改确认\nPhantomCSS 是一款基于组件的比较工具，借助于 PhantomJS 和 CasperJS，它可以仅通过命令行来运行。测试是通过命令行终端运行的，无论测试是否通过，其结果都会输出到命令行终端里。这种类型的工具尤其适合通过 Grunt 或者 Gulp 运行，而其输出也很适合 Jenkins 或者 Travis CI 等自动化工具。\n文档 前端项目日益变得复杂，但这并不是一件坏事，只是说前端在快速的发展过程中也出现了许多问题。\n前端开发不像服务器端，桌面端开发一样，后者无论是使用 Java、PHP 还是 C++ 等语言开发，其语言本身就提供了很清晰的类式结构特性，而且框架发展成熟，因此将一个复杂的功能需求代码拆分、抽象从而实现可重用看起来都是很平常的事情；然而，前端开发却不一样，长期夹杂于 JSP 与 PHP 页面的前端代码要实现这些其实要困难的多。那么，随之而来的问题就是，庞大的前端项目没有清晰的代码结构，没有清晰的开发文档，导致后期维护的工作量可想而知。\n不过，随着前端的发展，现今普遍采用了前后端完全分离的开发模式，页面由 JSP 与 PHP 这些夹杂着后端逻辑的页面转变为纯粹的 HTML 页面，为前端的代码拆分、抽象从而实现可复用提供了更多的可能性。与此同时，前端的框架也层出不穷，参考服务器端的开发模式，为前端如何规划项目结构和撰写文档提供了基石。\n何为文档 **文档是系统化设计的蓝图。没有文档，我们将难免重复解决已经解决过的问题，而且花大量时间查看代码来寻找最简单的答案。**没有文档，对新员工也很不友好，没有办法让其快速融入项目组。\n写文档是开发工作的一部分，而不是等重要工作完成之后才开始的事情。\n文档不只是简单地写下代码如何工作，但其主要作用记录我们的开发过程以及开发的代码是如何工作的，帮助其他开发者更好地理解我们所开发的代码。\n文档有多种形式，其中有很多只有在架构支持时才能成型。虽然有些文档只是用于描述每个函数的普通文本，但这种文档的背后往往有一套基于搜索、导航和视觉呈现的构建系统。其他的文档用于展示系统的资源，由我们所写的样式、脚本、模版和模式来驱动。\n静态文档 Hologram 是基于 Ruby 的通用文档工具，支持 CSS、Sass、JavaScript 文件中内联注释、块注释，而且其注释可以使用 Markdown 格式，从而生成静态的 HTML 页面文档，功能比较全面和强大。\nSassDoc 是基于 Node 的系统文档工具，它宣称 “SassDoc 对于 Sass 的意义，就像 JSDoc 对于 JavaScript 的意义一样”，而且它的确如此！如果你正在构建一个大型的 Sass 框架，或者复杂的栅格或者颜色系统，SassDoc 正是你想要的工具。\n代码驱动的文档 Pattern Lab 是多平台模式库工具，它可以使你模块化地开发设计系统，并将模板和 CSS 转换成可浏览的模式库。在模块化的系统中，你可以先开发每个单独的模式片段，然后通过组合这些片段产生更复杂的模式。可预览的组件库是开发者、设计师、用户体验师、质量工程师和产品所有者聚在一起时可以使用的完美工具。它为设计系统中每个部分创建了一门通用的语言和稳定的参照系。\nJSON 模式是用于描述数据格式的语言，同时也可以说明数据的验证方式。在前端架构的领域中，可以用 JSON 模式来描述模板和模式所需要的数据。JSON 超模式甚至可以描述能够通过 HTTP 协议与设计系统交互的方法，包括验证、渲染和测试。JSON 超模式是一种代码驱动的文档工具，因为它提供了验证和驱动编辑工具的功能。JSON 模式还提供了可读性很强的系统手册，取代了开发者实现一个功能所需的一大堆手写说明。\n参考 《前端架构设计》- Micah Godbolt 著 "},{"section":"Blog","slug":"/blog/computer-technology/nginx/nginx-config/","title":"Nginx 配置","description":"Nginx 作为一个轻量、高性能的服务器，近年来颇受欢迎，无论是生产环境还是开发环境都有其发挥作用的地方，其配置文件相对来说还是较为简单的。而且，现在 nginx 也支持 Windows 环境了，利用不同的配置可以满足我们不同的需求。","date":"March 15, 2018","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 服务器, Nginx","tags":"","content":"建议主要参考官网英文文档。\n具体指令直接可以在官网文档的 Alphabetical index of directives（按字母顺序排列的指令索引）中搜索即可。\n官方文档：http://nginx.org/en/docs/\nNginx Nginx 是一位俄罗斯开发者（伊戈尔·赛索耶夫）开发的服务器，于 2004 年 10 月 4 日公开发布。Nginx 的优势在于轻量级和高性能，尤其是高并发的场景下，相对其它服务器来说表现比较好，因此现在颇受欢迎。Nginx 通常运行在 Unix/Linux 环境下，当然现在官方也发布了 Windows 环境下的应用，不过性能有所降低，这是受限于系统环境的影响。\nNginx 在生产环境下的应用场景通常作为负载均衡的前端服务器，对请求进行分发，实现极高的并发量。当然，在开发环境下，nginx 也可以作为一个工具来使用，提供给我们极大的便利，例如利用反向代理来实现前后端的完全分离开发。\nNginx 的架构被设计为模块化，从官方文档我们就可以明显的看出来，相应的配置需要在对应的模块中去查找。默认安装的情况下，官方文档中的所有模块并不会被全部安装，只会安装大部分满足常用需求的模块，至于一些特殊需求所要用到的模块，可以自己手动编译安装，当然模块化的好处就是可以自己开发模块来扩展 nginx 的功能。\nNginx 特定场景下的配置 不管 nginx 基于什么场景发挥什么作用，都是基于特定的配置来实现，nginx 的配置文件也相对比较简单。\n工作进程 Nginx 是基于异步非阻塞 IO 模型的，同时也支持多进程，通常将其工作进程数目设置为 CPU 的核心数，以发挥其最大作用，实现高并发。\n{ worker_processes 4; ... } 这个配置是写在配置文件顶部的，其值也可以为 auto。\n官网文档：Core functionality/worker_processes\n隐藏 nginx 版本号 隐藏掉版本号，可以降低被攻击的风险。\nhttp { ... server_tokens off; } 官网文档：ngx_http_core_module/server_tokens\n设置编码 通常来说，将编码设置为 UTF-8 是比较合适的。\nserver { ... charset utf-8; } 官网文档：ngx_http_charset_module/charset\n更改上传数据大小限制 Nginx 默认的数据上传大小为 2M，某些情况下我们需要将其更改的大一些，以符合业务需求。\nserver { ... client_max_body_size 20m; } 官网文档：ngx_http_core_module/client_max_body_size\n开启 gzip 开启 gzip 压缩可以在客户端请求文本文件时，将传输大小压缩至少**70%**左右，可以获得非常好的优化效果，通常都会开启 gzip 压缩配置。\nhttp { # ... # gzip gzip on; gzip_min_length 20; gzip_buffers 4 16k; gzip_comp_level 6; gzip_types text/plain text/xml text/css text/javascript application/x-javascript application/javascript application/json; gzip_http_version 1.0; gzip_disable \u0026#34;MSIE [1-6]\\.\u0026#34;; gzip_proxied off; gzip_vary on; # ... } 其中有几个配置需要特别注意：\ngzip_min_length\n文件大小小于该值的文件将不会被压缩，大于此值时才会被压缩。\ngzip_buffers\n设置用于处理请求压缩的缓冲区数量和大小。比如 32 4K 表示按照内存页（one memory page）大小以 4K 为单位（即一个系统中内存页为 4K），申请 32 倍的内存空间。通常默认即可。\ngzip_comp_level\n设置压缩级别，值为 1-9。压缩级别越高，压缩效果越好，但同时越耗费时间和 CPU 性能，所以通常设置为 6 即可。\ngzip_types\n设置要压缩的文件 MIME 类型，默认包含 text/html。gzip 只对文本文件的压缩效果较好，不建议设置非文本文件。\ngzip_http_version\n设置要进行压缩的 http 协议版本，默认设置为 1.0 即可，因为 nginx 和后端服务器（Server）默认采用 HTTP/1.0 进行通信的，防止出现不压缩的情况。\n官网文档：ngx_http_gzip_module\n路由匹配规则 nginx 像一个路由，客户端通过什么地址访问服务器，服务器则在配置文件中通过设置好的路由来匹配请求进行转发。\nnginx 的匹配规则分为 3 类：\n正则匹配：由 ~（不忽略大小写） 和 ~*（忽略大小写）开头 精确匹配：由 = 开头 前缀匹配：由 ^~ 开头或没有任何字符的规则 匹配顺序：首先检查精确匹配，匹配到则终止；其次，检查前缀字符串匹配，匹配到时，若是以 ^~ 开头的则终止，否则继续进行正则匹配；最后，检查正则匹配，顺序为配置文件中书写顺序（从上到下），匹配到第一条则终止，若没匹配到，则以匹配到的前缀匹配规则为最终结果。\n# 精确匹配，加速 / 请求的处理 location = / { # ... } # 前缀匹配，处理一些需要缓存的静态资源 location ^~ /static/ { root /Data/static/; expires 7d; } # 正则匹配，处理静态资源 location ~* \\.(html|js|css|png|jpg|jpeg|gif|json|ico|otf|eot|svg|ttf|woff|woff2|map)$ { root /Data/webapps/; } # 前缀匹配，默认处理（可以做反向代理，处理动态资源请求） location / { proxy_pass http://127.0.0.1:8080; } 在非精确匹配的规则内部是可以嵌套 location 规则的。\n官网文档：ngx_http_core_module/location\n####### 调试技巧\nnginx 本身是比较难调试的，不过在配置 location 指令时，可以利用 return 指令来进行调试。\nlocation /test/ { return 600; } 此时若访问 /test/ 路径，可以看到响应码为 600 时，说明路径匹配成功。同时，可以添加一些辅助文本信息：\nlocation /test/ { default_type text/html; return 600 \u0026#39;Hello\u0026#39;; } 官网文档：ngx_http_rewrite_module/return\n虚拟目录 虚拟目录解决了客户端请求资源的 URL 与服务器端对应资源存在位置不一致的问题。如下所示：\n# 虚拟目录 location /static/ { alias /DataDisk/resources/; } # 这样，客户端发送 example.com/static/bg.png 的请求实际映射到了服务器端 /DataDisk/resources/bg.png 的资源上 URL 作为统一资源定位符，代表的是资源所在的真实网络位置，但在某些情况下，出于安全性、降低逻辑复杂性等因素的考虑，给客户端提供一个虚拟目录可能更好，这个时候使用 alias 指令就可以实现。\n作为对比，我们使用 root 指令通常指定的是真实目录。如下所示：\n# 真实目录 location /static/ { root /DataDisk/resources; } # 这样，客户端发送 example.com/static/bg.png 的请求实际映射到了服务器端 /DataDisk/resources/static/bg.png 的资源上 可以看出，root 指令通常适合用在资源路径完全真实存在的情况下，而 alias 指令则更适合用在资源路径前缀部分不是真实存在的情况下。\n官网文档：ngx_http_core_module/alias\n文件列表浏览 静态资源服务器一般允许用户查看服务器上的文件列表，例如 CDN、镜像站等。nginx 出于安全考虑，默认是不允许客户端浏览器查看服务器上的文件列表的，可以通过以下指令来进行配置：\nlocation /static/ { autoindex on;\t# 开启客户端文件列表浏览 autoindex_exact_size off; # 默认显示的文件确切大小，单位 b，关闭后自动计算 KB/MB/GB 等 autoindex_localtime on; # 文件的改动时间以服务器时间为准 } 官网文档：ngx_http_autoindex_module\n允许跨域 有时候，比较大（几百兆以上）的静态资源需要在客户端使用异步方式加载（例如 Ajax），但是多个人合作开发时，拷贝这些静态资源到各自本地（如果不这么做，将会出现跨域问题）是最糟糕的解决方案，这个时候我们可以将静态资源放在一个服务器上，然后使用反向代理或者允许跨域的配置巧妙的解决这个问题。\nlocation /static/ { ... add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Headers' 'Content-Type'; add_header 'Access-Control-Allow-Credentials' 'true'; } Access-Control-Allow-Origin\n必选，这个响应头信息代表的是允许跨域请求的域名，* 则表示允许任意域名向此服务器发起跨域请求。\nAccess-Control-Allow-Credentials\n可选，这个响应头信息代表的是跨域请求是否需要携带 Cookie 信息，默认为 false，在需要利用 Session-Cookie 机制的情况下务必设置为 true。\n官网文档：ngx_http_headers_module/add_header\n反向代理 Nginx 可以作为一个反向代理服务器，来为我们提供一些场景下的解决方案，例如负载均衡、跨域、前后端完全分离开发场景等等。\nlocation / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_cookie_path /project/ /; proxy_pass http://127.0.0.1:8181/project/; } 这里有几点需要注意下：\nproxy_set_header\n目的是为了保证后端（被代理的）服务器获取到远程客户端的真实信息，相当于将前端（nginx 反向代理）服务器的信息隐藏，造成客户端直接访问后端服务器的“假象”。\nHost 应尽可能设置成 $http_host，这样会包含完整的 IP 和端口信息，设置为 $host 时将不会包含端口信息。\nproxy_cookie_path\n目的是为了在访问路径与代理路径发生改变（不一致）的情况下防止出现客户端 Cookie 丢失的问题。\nproxy_pass\n则是后端（被代理）服务器地址。\n####### 代理服务路径变化时\n如果说在反向代理过程中，路径没有差异，一般来说不会出现什么问题，但是如果路径有变化时，会出现两个问题，一个是 cookie 丢失，另一个则是 后端服务器重定向错误。 第一个问题可以用 proxy_cookie_path 指令解决，第二个问题则使用 proxy_redirect 指令解决。具体如下：\nlocation /test/ { proxy_cookie_path /project/ /test/; proxy_pass http://127.0.0.1:8181/project/; proxy_redirect ~(https?://[^/]+)?/project/(.*) $scheme://$http_host/test/$2; } 首先，proxy_pass 指令配置的代理服务在用户实际访问时路径发生了变化。用户以 /test/users 路径访问时，实际被 nginx 代理到后端的服务路径为 /project/users，可以明显的看到路径的前缀发生了变化。\n此时，proxy_cookie_path 指令告诉 nginx 将后端被代理服务的响应头中 cookie_path 进行转换，这样在客户端访问任意路径时，cookie_path 也会保持和访问路径一致，而不是实际代理的服务路径，否则 cookie 将会在客户端丢失。\n同时，如果说被代理的服务有重定向需求的话，不配置 proxy_redirect 指令，重定向的路径将会发生错误，需要告诉 nginx 将其路径中部分进行替换。例如，用户访问 /test/，被代理的服务路径为 /project/，此时被代理服务做一个重定向操作到 /project/index.html，如果不做转换，用户会直接访问该路径将发生错误。在这里，proxy_redirect 指令所做的就是将响应头中 Location字段的值由 /project/index.html 替换为 /test/index.html，这样用户将会正常访问到资源。\n官网文档：ngx_http_proxy_module\n重定向 重定向是一个比较常见的需求，nginx 的重定向指令（rewrite）还是相当简单的。例如，需要将所有 http 请求重定向到 https 下，官方推荐这么做：\nserver { listen 80; server_name localhost; return 301 https://example.com$request_uri; } 事实上，也可以用 rewrite 指令，不过官方不推荐：\nserver { ... rewrite ^/(.*)$ https://example.com/$1 permanent; } 注意： 301 重定向可能会导致 POST 请求被改变为 GET 请求，并可能丢失提交数据，此时使用 308 状态码替换即可。\n官网文档：ngx_http_rewrite_module\n####### 项目首页重定向\n大多数时候，我们在同一个域名下会部署多个 Web 应用，访问的话需要 WebAppName 来进行区分，例如 localhost:80/App，那么 App 其实就代表了一个 Web 应用，将会映射到相应的文件夹。这里有一个细节性问题，文件夹的路径必然以 / 结束，所以大多数服务器都会自动做一次重定向，将 localhost:80/App 重定向到 localhost:80/App/。如果 Nginx 没有配置，默认是不会做这个重定向的，为了用户访问方便，我们需要解决这个问题：\nlocalhost / { # 这是一个默认配置文件中的配置项 # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } 这个配置基本上解决了该问题，但在内外网端口不一致时，会出现问题。例如，我们通过 www.example.com:80/App 访问部署在内网 8080 端口上的 Nginx 时，Nginx 会将其重定向到 www.example.com:8080/App/，这里的差异在于，重定向时丢失了外网端口，用户此时将会访问失败。\n目前，还没找到比较优雅的解决办法，可以用以下配置暂时解决该问题：\nlocation ~ ^/[^/]+$ { return 301 $scheme://$http_host$uri/; } 日志分割 Nginx 的访问日志（access_log）默认是没有进行分割的，时间一长，日志文件就会有 GB 级别的大小，日志写入速度变慢，也会影响 nginx 的性能。我们可以通过很简单的方式，将访问日志设置为按天记录,将日志记录在不同的文件中。\nserver { ... # cut log by day if ($time_iso8601 ~ \u0026quot;^(\\d{4})-(\\d{2})-(\\d{2})\u0026quot;) { set $year $1; set $month $2; set $day $3; } access_log logs/access/host.access-$year-$month-$day.log main; } 官网文档：ngx_http_log_module\n"},{"section":"Blog","slug":"/blog/computer-technology/web/web-routing/","title":"Web 应用：单页面应用与路由","description":"现在，Web 技术不仅仅是局限于页面的开发技术，在应用的开发方面也是一种潮流，B/S 架构的技术是一种趋势。而像一般的管理型 Web 应用，不注重 SEO，非常适合单页面应用（SPA）的实现方式，而路由功能则是单页面应用的核心技术。","date":"October 25, 2017","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, SPA, 路由","tags":"计算机技术, Web前端, SPA, 路由","content":"现在，Web 技术不仅仅是局限于页面的开发技术，在应用的开发方面也是一种潮流，B/S 架构的技术是一种趋势。而像一般的管理型 Web 应用，不注重 SEO，非常适合单页面应用（SPA）的实现方式，而路由功能则是单页面应用的核心技术。\nSPA 单页面应用（Single page application, SPA）已经是目前实现 Web 应用的主流技术了，尤其是移动端的 Web 应用。SPA 使用 Ajax 技术异步加载页面内容，使用户能够在同一个页面流畅的进行交互，并将多个页面的内容根据需要在同一个页面在适当的时候进行展示。当然，SPA 技术采用动态加载 DOM 的方法，随之而来的就是 SEO 优化问题，搜索引擎不执行 JS 代码，页面内容无法被引擎检索到，也就不利于页面的排名和检索量提升。\n当然，SPA 技术主要应用于比较重的管理型 Web 应用等等，它们对 SEO 的优化需求不那么强，或者说根本就没有。在门户类网站，页面内容是非常重要的，SEO 优化的需求很强，使用 SPA 技术来动态生成 DOM 结构并不合适。但是，我们可以将多个相似模块的 DOM 结构写在同一个页面上，仅仅利用路由功能来将他们与用户的交互操作联系起来适时的进行展示即可，这也是不错的方法。\n单页面应用的业务逻辑要复杂得多，所以划分模块是很重要的，利于维护和管理。但如何来划分模块呢？我们通常实现单页面应用的方法是利用\u0026quot;锚点\u0026quot;，也就是 URL 后面的#index这一串字符。锚点的作用是将视角跳到当前页面中name值与锚点值相同的元素处，常见应用方式的就是点击导航跳转到页面某处。**然而，更重要的是改变页面的锚点，页面并不会刷新，也就是说不会向服务器发送新的请求。**而这正与我们实现单页面应用的需求相契合，锚点的信息则我们决定要展示什么内容。路由的功能则是帮助我们将某一模块的业务与锚点信息联系起来，进而实现交互。\n事实上，实现单页面应用的方法不仅可以利用锚点#，还可以使用 html5 的新 API，popState()与pushState()，但锚点兼容性更好一些。\n路由 路由（Router）功能是实现单页面应用的核心技术，也是我们进行业务划分的基础。常见的前端框架基本都提供了路由功能，但我们通常使用框架的机会不多，而路由功能又是实现单页面应用的核心，所以在这里自己写了一个简单的路由功能帮助我们简单实现单页面应用的业务管理。\n锚点值发生变化时，不会向服务器发送新的请求，但会触发window.onhashchange()事件，利用这个事件我们来将用户的交互操作与业务挂钩，路由则封装了这个事件，增加了一些工具方法，帮助我们管理代码，业务进行模块化划分。\n其实，根据在写这个路由功能的过程中，可以明显的感受到我们只不过在前端做了类似 Tomcat 的 Filter、Servlet、Listener 等等要做的事情，然后使用 Ajax 异步的加载页面，这也许就是单页面应用的核心。而这个路由功能提供了基本的业务模块划分功能同时，还增加了hash_url模糊匹配功能，目的是让我们可以实现过滤器的功能，从而帮助我们将业务逻辑划分的更清晰一些；也提供了手动切换路由的功能。\n使用路由 将 js 文件引入页面后就可以使用路由来进行业务逻辑的模块化开发了。\n// 引入 Router.js 后 /* 路由注册（过滤） */ !function(){ // 根过滤 router(\u0026#39;/*\u0026#39;, function(content){ ... }); }(); /* 路由注册（业务） */ !function(){ // 首页 router(\u0026#39;/index\u0026#39;, function(content){ ... }); // 默认加载首页 switch_routing(\u0026#39;/index\u0026#39;); }(); content参数是页面中id为content的 DOM 元素，用来提供加载页面内容的容器，可在源码中修改其id值。\nRouter.js // Router // IE8 以下不支持的数组方法 if (!Array.prototype.forEach) { Array.prototype.forEach = function (callback, self) { if (Object.prototype.toString.call(callback) != \u0026#39;[object Function]\u0026#39;) { return this; } var length = this.length; for (var i = 0; i \u0026lt; length; i++) { callback.call(self, this[i], i); } return this; }; } if (!Array.prototype.filter) { Array.prototype.filter = function (callback, self) { if (Object.prototype.toString.call(callback) != \u0026#39;[object Function]\u0026#39;) { return this; } for (var i = this.length - 1; i \u0026gt;= 0; i--) { !callback.call(self, this[i]) \u0026amp;\u0026amp; this.splice(i, 1); } return this; }; } /* 路由自动加载内容（单页面） ---content : 将页面容器标签的 id 设置为 content ---使用方法 router(url, function(content){ }) : 注册对应 url 需要执行的回调方法，content 参数为页面中 ID 为 content 的元素，可重复注册 -- url 单个模糊匹配 : \u0026#34;/*\u0026#34; (可作为过滤器使用，回调执行顺序优先级 : 模糊匹配 \u0026gt; 精确匹配) 单个精确匹配 : \u0026#34;/index\u0026#34; 多个混合匹配 : [\u0026#34;/*\u0026#34;, \u0026#34;/index\u0026#34;] ---工具方法 switch_routing(url, callback) : 手动切换 url 并执行回调 get_hash_url() : 获取当前的 hash_url get_url_array(url) : 获取当前 hash_url 或者传入参数的 url 数组，例如 \u0026#34;/index/index1/index2/index3\u0026#34; =\u0026gt; [\u0026#34;index\u0026#34;, \u0026#34;index1\u0026#34;, \u0026#34;index2\u0026#34;, \u0026#34;index3\u0026#34;] */ !(function (window) { // 管理 root var routings = {}, fuzzy_match = []; // 容器（ID） var content = document.getElementById(\u0026#39;content\u0026#39;); /* rooting 注册方法 */ function router(url, callback) { // 回调不存在 if (!callback) { return; } // url 是否是多个数组元素 if (Object.prototype.toString.call(url) == \u0026#39;[object Array]\u0026#39;) { return url.forEach(function (sub_url) { // 递归 router(sub_url, callback); }); } // 获取数据 var routing = routings[url]; // 未注册的情况下 if (!routing) { routings[url] = callback ? [callback] : []; // 如果存在模糊匹配的话，例如 /index/* url.match(\u0026#39;\\\\*\u0026#39;) \u0026amp;\u0026amp; fuzzy_match.push(url); } else { // 已注册 callback \u0026amp;\u0026amp; routings[url].push(callback); } } /* 执行回调 */ function apply_routing(url) { var routing = []; // 先遍历模糊匹配（可配置过滤器） fuzzy_match.forEach(function (fuzzy_url) { routing = routing.concat( url.indexOf(fuzzy_url.slice(0, -1)) == 0 ? routings[fuzzy_url] : [] ); }); // 精确匹配 routing routing = routing.concat(routings[url] || []); // 回调 routing \u0026amp;\u0026amp; routing.forEach(function (callback) { callback \u0026amp;\u0026amp; callback(content); }); } /* 主动切换路由 */ function switch_routing(url, callback) { // 检测当前路由 var now = location.hash.slice(1) == url; // 更改 hash location.hash = url; // 手动执行回调 now \u0026amp;\u0026amp; apply_routing(url); // 回调 callback \u0026amp;\u0026amp; callback(content); } /* 获取当前 hash_url */ function get_hash_url() { var hash_url = location.hash.slice(1), query_index = hash_url.indexOf(\u0026#39;?\u0026#39;); // 查询字符串存在的话 hash_url = query_index == -1 ? hash_url : hash_url.slice(0, query_index); return hash_url; } /* 检测自动加载 */ window.onhashchange = function () { // 执行回调 apply_routing(get_hash_url()); }; // 将路由注册方法暴露给全局 window.router = router; // 将路由切换方法暴露给全局 window.switch_routing = switch_routing; // 将获取当前 hash_url 方法暴露给全局 window.get_hash_url = get_hash_url; /* 获取 hash_url 数组 */ function get_url_array(url) { var url = url || get_hash_url(); // 去掉空字符元素 var url_array = url.split(\u0026#39;/\u0026#39;).filter(function (a) { return !!a; }); return url_array || []; } // 将获取当前 url 数组方法暴露给全局 window.get_url_array = get_url_array; })(window); "},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-junit/","title":"单元测试工具：Junit","description":"通常一个项目的代码量是比较大的，而且其中逻辑也较为复杂，在开发完成后再进行项目测试其实是比较耗费时间和精力的，因此边开发边测试是个很好的选择，而 JUnit 则为我们提供了这样的便利。","date":"August 30, 2017","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 工具, 测试","tags":"","content":"通常一个项目的代码量是比较大的，而且其中逻辑也较为复杂，在开发完成后再进行项目测试其实是比较耗费时间和精力的，因此边开发边测试是个很好的选择，而 JUnit 则为我们提供了这样的便利。\nJUnit JUnit 是一个用来对 Java 代码进行单元测试的框架，是 XUnit （一套基于测试驱动开发的测试框架）的一个子集，类似的还有 PythonUnit、CppUnit。\nJUnit 可以帮助我们进行自动化的单元测试，而不需要我们去编写 main 方法逐一测试，同时其使用断言（assert）机制可以将我们预期的结果和程序运行得到结果进行比对，确保对结果的可预知性。\n使用 JUnit4 JUnit 目前已经更新到第 4 个版本，也就是 JUnit4，当然第 5 版也在筹备之中，这里我们使用 Junit4 即可。其实 eclipse 已经集成了 Junit 单元测试框架，我们可以直接使用，而不需要去下载 jar 包导入。\n导入 JUnit4 在 eclipse 中新建一个 Java 项目，然后右键项目，选择 Build Path -\u0026gt; Add Libraries ,然后选择 Junit 即可将其添加到项目中。接下来我们创建一个被测试的类，然后再创建一个测试类用来使用 JUnit4 对被测试类进行单元测试。\n进行测试 Junit4 相对于第 3 个版本来说使用起来更为方便了，只需在测试类的测试方法前面加一个 @Test 注解即可。这里有一个 assertEquals() 方法很有用，其可以帮助我们对程序的期望结果和运行结果进行比对。\n@Test public void testXXX(){ /** * obj1 : 期望值（我们指定） * obj2 : 运行值（调用被测试类） */ assertEquals(Object obj1, Object obj2); } 测试代码编写完成后，Run As -\u0026gt; JUnit Test 即可，只要出现绿色的状态条则代表我们的测试全部成功，如果为红色说明我们有部分测试失败，在状态条下方的测试结果列表中，每一项前面都会标记出来，测试成功的则为对号，失败的为叉。\n代码规范 需要注意的是，我们应该将测试类和项目被测试类代码分开放置，通常会在项目下 New -\u0026gt; Source Floder 命名为 test 将测试类代码放入其中，测试类和被测试类的包名应一致，在项目部署时删除这个目录即可。\n另外，测试类的命名应遵循被测试类名加 Test 后缀的规则；而测试类的方法命名应遵循以 test 为前缀加被测试方法名的规则，比如 testXXX()，这样更为规范一些。还有就是，测试方法是公有（public）、无返回值（void）的，并且测试方法之间是相互独立的。\n这里有一个小技巧，通常被测试类的方法会很多，手动编写测试方法耗费时间，我们可以右键测试类，New -\u0026gt; Other 然后选择 JUnit Test Case，选中要测试的方法，设置好文件路径即可自动生成一个包含指定测试方法的测试类。\n测试失败分析 JUnit 的测试结果是非常直观的，红色状态条代表我们测试失败，其中又分为两种失败类型，分别为 Errors 和 Failures。导致测试失败的原因我们可以在下方的消息栈中看到，其说明了引起测试失败的具体原因。\nErrors\n是由于代码异常引起的，可能是测试代码本身的错误，也可能是被测试代码中的错误。\nFailures\n一般由单元测试的断言方法判断失败所引起的，也就是说程序的运行结果和我们的预期不一样。\nJUnit 运行过程 要使用好 JUnit4 这个测试工具，我们应该了解清楚其运行的过程。在 New -\u0026gt; Other 新建一个 JUnit Test Case 类时，可以勾选四个自动生成的方法：\nsetUpBeforeClass()\n@BeforeClass 标注的静态方法，测试类加载时运行一次，适合加载配置文件。\ntearDownAfterClass()\n@AfterClass 标注的静态方法，所有测试方法执行完成时运行一次，适合清理资源，例如关闭数据库连接。\nsetUp()\n@Before 标注的实例方法，每个测试方法执行前运行一次。\ntearDown()\n@After 标注的实例方法，每个测试方法执行后运行一次。\n以上四个方法可以帮助我们更好的进行单元测试，当然前提是这些方法运行的时机和作用我们应该知道。\nJUnit 常用注解 @Test @BeforeClass @AfterClass @Before @After @Ignore @RunWith @Test 注解标注一个方法为测试方法，除此之外我们还可以设置要捕获的异常和测试时间。\n/** * expected : 表明我们预期会发生的异常，使其不影响测试结果，类似于 throws 关键字 * timeout : 指定测试的时间（ms），可以用来测试程序性能 */ @Test(expected=ArithmeticException.class, timeout=2000) @Ignore 注解标注一个测试方法被运行器忽略，同时可以标识一些忽略信息。@RunWith 注解用来更改测试运行器。\nJUnit 深入使用 会利用 JUnit 进行基本的单元测试或许已经满足了我们的需求，然而 JUnit 为我们提供了更加便利的工具。\n测试套件 测试套件是用来同时测试一整套测试类的，New -\u0026gt; Other 然后 JUnit Test Suite 即可创建一个测试套件。\n// 测试套件类 @RunWith(Suite.class) @SuiteClasses({ taskTest1.class, taskTest2.class }) public class AllTests { } 在创建测试套件时可以勾选需要包含进来的测试类或者测试套件，当然也可以在 @SuiteClasses 注解中手动添加。要注意的是测试套件类必须是一个空类，不能包含任何方法；其次要使用 @RunWith 注解将运行器修改为 Suite.class。\n参数化设置 参数化设置可以帮助我们提高代码的重用度，减少类似的代码编写工作量。\n//被测试类 public class Calculate { // 除法 public int divide(int a, int b){ return a/b; } } // 参数化设置的测试类 @RunWith(Parameterized.class) public class ParameterTest { // 参数 int expected, input1, input2; // 用来返回一组参数 @Parameters public static Collection\u0026lt;Object[]\u0026gt; params(){ return Arrays.asList(new Object[][]{ {1,2,2}, {3,9,3}, {25, 625, 25} }); } // 构造器 public ParameterTest(int expected, int input1, int input2) { this.expected = expected; this.input1 = input1; this.input2 = input2; } // 测试方法 @Test public void testDivide() { assertEquals(expected, new Calculate().divide(input1, input2)); } } 参数化设置的测试类要使用 @RunWith 注解将运行器修改为 Parameterized.class。该类中要声明变量来存放预期值和结果值，声明一个 @Parameters 注解标注的返回值为 Collection 的公共静态方法来返回一组参数值，其次还要声明一个带参数的构造方法。\n"},{"section":"Blog","slug":"/blog/computer-technology/web/javascript/web-js-async/","title":"JavaScript 异步编程","description":"JavaScript 作为一门在 Web 开发中的主流语言，常常涉及到交互事件方面的应用，这不可避免的用到了异步编程的方法，而它本身则是单线程运行的。在以往的开发中，异步编程正变得越来越难管理，新的 Promise 标准 API 将使得异步编程更加方便、安全。","date":"March 22, 2017","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, JavaScript, 异步编程","tags":"","content":"JavaScript 作为一门在 Web 开发中的主流语言，常常涉及到交互事件方面的应用，这不可避免的用到了异步编程的方法，而它本身则是单线程运行的。在以往的开发中，异步编程正变得越来越难管理，新的 Promise 标准 API 将使得异步编程更加方便、安全。\n异步与并行 作为 Web 前端开发中的主流语言，JavaScript 需要实现诸多的交互动作，但是在宿主环境（例如 v8）中 JS 引擎只有一个主线程，所以多线程并行处理是不可能的。因此，异步编程显得尤为重要。\n异步是时间顺序上的概念，代表着现在与未来某一时刻。最典型的就是发送 Ajax 请求：\n$.ajax('', function(){ // do something }); 通常我们现在发送一个异步的 Ajax 请求，然后使用函数回调在未来某一时刻执行一些事情。而函数回调正是我们实现异步编程的一个重要途径。\n同时，并行又是一个重要的概念，它不同于异步，并行的意义在于同一时间发生什么。进程和线程独立运行，并可能同时运行，多个线程通常会共享单个进程的内存。这就意味着，具备多线程并发能力的话，同时也会带来诸多的问题。JS 的宿主环境浏览器仅提供了一个主线程，让 Web 开发的难度大大降低，不用考虑多线程并发所带来的诸多问题。\n任务队列 虽然，JS 没有多线程并发能力，但是并发却是非常有用的。在一个优秀的前端应用中，交互是非常流畅的，这得益于良好的编程能力所模拟出来的并发效果。\nJS 在浏览器中执行的模式是一种任务队列的形式，多个任务排成队等待主线程调用 JS 引擎执行自己的代码。这并不会出现多线程中的竞争状态，但这也意味着糟糕的编程方式可能会因为一个任务而导致整个任务链被阻塞。\nfunction response(data){ // data 是一个大数组，并要进行遍历处理 var temp = data; temp.map(function(val){ return val * 2; }); } 如果说 data 的大小在 1000 左右可以被瞬间处理完成，那么 data 的大小突然变成几十万呢？所以，这样的编程方式很容易因为单个任务导致其它任务被严重阻塞。\nfunction response(data){ // 一次只处理 1000 个 var temp = data.splice(0, 1000); temp.map(function(val){ return val * 2; }); // 剩余的稍后继续处理 if(data.length \u0026gt; 0){ setTimeout(function(){ response(data); }, 0); } } 经过特殊处理之后的程序，一次只处理一部分数据，将一个大任务分割成多个小任务来完成，就会避免阻塞任务链的情况。\nJavaScript 事件轮询机制 在 JS 引擎中，基于单线程采用了事件轮询（event loop）机制来实现高并发，与单核 CPU 处理多任务进程是相似的。主线程负责处理单个任务（macrotask）的所有流程（microtask），主线程会将同一个任务的所有流程处理完毕之后再去询问任务队列是否有新的任务需要执行，如果有则会将新的一个任务放到主线程去处理，如此往复循环。\nmacrotask\n我们可以将一个 macrotask 看作一个任务，多个任务存放在任务队列中，等待主线程处理。\nmicrotask\n而对于一个任务，我们可以有更细粒度的划分，即多个流程，我们可以将一个 microtask 看作任务的一个流程。\n**在此基础上，我们可以理解为任务队列包含多个任务（macrotask），而单个任务又包含多个流程（microtask）。**这样我们对业务逻辑的处理可以有更细粒度的掌控，同样地有以下 API 来为我们提供一些解决方案：\nmacrotask 系 setTimeout setInterval setImmediate I/O UI rendering microtask 系 process.nextTick Promise MutationObserver 举个简单的例子：\nsetTimeout(() =\u0026gt; console.log(1)); Promise.resolve(true) .then(() =\u0026gt; console.log(2)) .then(() =\u0026gt; console.log(3)) .then(() =\u0026gt; console.log(4)); setTimeout(() =\u0026gt; console.log(5)); // console 2 3 4 1 5 之所以输出顺序是 2 3 4 1 5，就是因为 Promise 属于 microtask 系，也就是说无论有多少个 then 回调，它们都属于同一个任务的不同流程，只有这些流程全部处理完，主线程才会处理下一个任务。\n因此，明白 JS 的事件轮询机制以及任务队列模型，并保持良好的编程习惯会让 Web 应用更流畅。\n函数回调 函数回调是实现 JS 异步编程的重要途径，基本上绝大多数异步代码都使用了函数回调。当然，事件监听也是我们用来进行异步编程的一种方式，只不过前者更广泛一些。\n// 最典型的函数回调依然是 ajax 请求 ajax('', function(){ // do something }); // 事件也是一种异步编程的方式 $('#id').onclick = function(){ // do something } 嵌套回调 但是，在较为复杂的应用中，非常有可能出现嵌套回调的情形，这时候代码维护会变的困难起来。\n// 嵌套回调 $('#id').addEventListener('click', function(){ $.ajax('', function(){ setTimeout(function(){ // do something }, 1000); }); }); 也许，在我们当时写的时候会很顺畅，但以后回过头来看，代码维护的工作量会骤升。这里的程序可能还不够复杂，一旦变得更复杂一些，应用的安全将变的脆弱。\n因此，嵌套的函数回调是非常严重的问题，我们期望有一种新的方式去改变这种现状，后面将会讲到 Promise API。\n信任问题 除此之外，函数回调还有一个非常隐秘的安全问题\u0026mdash;信任问题。在这之前，我们假设所有的回调函数最终都会被调用，但事实真是如此吗？\n还是以 jQuery 中 Ajax API 为例，我们都确信传入的回调函数最终会被调用，但这依然是作为 jQuery 团队的第三方来决定的。\n// 这是一个金融系统 function deal(userData, function(){ // 执行交易 }); 我们很难确保第三方提供的 deal() 方法会在将 userData 进行验证之后执行交易，也就是调用回调函数。万一回调函数被执行了多次，或者一次都没执行，这些都是我们不可预料的问题，但却是极易发生的。\n也许我们每次都能去合理地解决它，但为何不寻找一种一劳永逸又安全的方式呢，新的 Promise API 正是为此而来。\nPromise 我们可以通过以下方式创建一个 Promise :\nnew Promise(function(resolve, reject){ if (操作成功){ return resolve(value); } // 操作失败 reject(error); }); Promise 构造器接受一个方法，该方法有两个参数，一个为 resolve 表示完成，另一个为 reject 表示拒绝，在异步操作完成之后将会根据结果调用其中一个。\n一个 Promise 对象通常会处于三个状态之中的一种：等待（Pending）、完成（Resolved）、拒绝（Rejected）。而且这种状态的改变取决于异步操作，一旦改变将无法再次被改变，所以是不可逆的。同样地，如果 Promise 一旦创建，异步操作就会开始，并且我们是无法中途去中断的。\nPromise 本质上是一种异步编程的形式，运用的还是回调函数，只不过这种新的形式解决了单纯使用回调函数所存在的信任问题。将函数的调用权不再给予第三方，而是由我们自己来决定何时调用。\n基本 API Promise 有几个基本的 API 用来简化我们的异步编程操作，而不需要每次都去使用构造函数创建新的 Promise 对象。\n######### resolve() 和 reject()\n如果仅仅是需要一个拒绝状态的 Promise，以下方式是等价的：\nvar p1 = new Promise(function(resolve, reject){ reject('error'); }); var p2 = Promise.reject('error'); Promise.resolve() 通常用来创建一个已完成的 Promise，可能失败也可能成功，根据传入的值来决定。\nvar p3 = Promise.resolve(value); 传入的 value 如果是一个 Promise 对象，则它什么也不会做，只是简单的返回该 Promise 的状态值；但是，如果 value 是一个值，它会自动创建一个 Promise 对象并根据值做出决议，然后返回决议值。\n######### then() 和 catch()\n前面我们说过，回调函数的嵌套是不利于代码维护的，那么 Promise.then() 则提供了链式的异步操作方式。\nvar p4 = new Promise(function(resolve, reject){ // do something }); p4.then(fulfilled, rejected).then(fulfilled, rejected); then() 方法的两个参数类似于构造器中回调方法的两个参数，代表着完成和拒绝操作。我们之所以可以进行链式操作，是因为每一个 Promise 的 API 都会最终返回一个 Promise 对象，这样我们就可以更灵活的进行编码。\n有时候，我们只希望单纯的进行错误处理，则可以使用以下的等价方式：\np4.then(null, rejected); p4.catch(rejected); 这样并非是没有接收完成状态的决议值，而是将其传入下层的 Promise 对象中。\n######### all() 和 race()\n这两个 API 都是辅助性方法，它们都接受一个 Promise 对象数组作为参数。\nPromise.all() 则会在所有传入的 Promise 都处于完成（resolved）状态时，返回完成状态的 Promise，否则返回拒绝状态的 Promise。\nvar p1 = Promise.resolve(42), p2 = Promise.resolve('Hello World'), p3 = Promise.reject('Error'); Promise.all([p1, p2, p3]) .catch(function(err){ console.log(err); // 'Error' }); Promise.all([p1, p2]) .then(function(msgs){ console.log(msgs); // [42, 'Hello World'] }); Promise.race() 会在传入的所有 Promise 中第一个决议完成时，就返回该 Promise。\nPromise.race([p1, p2, p3]) .then(function(msg){ console.log(msg); // 42 }); 前者若传入一个空数组，它会立即决议完成，而后者会永远处于等待状态。\n局限性 首先，Promise 链的决议结果是顺序传递地，也就是说如果其中发生错误或变为拒绝状态，直到遇到第一个 rejected 方法，该错误才会被捕获。同时，因为第一个 rejected 方法已将该错误捕获并处理，此时后续的 Promise 链将失去作用，这在某些情况下不是我们想要的结果。\nvar p = new Promise(function(resolve, reject){ // do something }) .then(step1) .then(step2) .then(step3) 这个 Promise 链中没有 rejected 方法，因此一旦发生错误或转变为拒绝状态，决议值将永远得不到处理。\n每一个 Promise 只会产生一个决议值，所以我们应该遵循该规则，在需要返回多个值的程序中，我们尽可能的返回多个 Promise ，将其数组传入 Promise.all() 辅助方法会更好一些。\nfunction getY(x){ return new Promise(function(resolve, reject){ setTimeout(function(){ resolve(3 * x - 1); }, 100); }); } // 在此返回多个 Promise function foo(bar, baz){ var x = bar * baz; return [ Promise.resolve(x), getY(x) ]; } // 进行处理 Promise.all( foo(10, 20) ) .then(function([x, y]){ console.log(x, y); // 200 599 }); 这里，在最后使用了一个 ES6 中数组解构赋值的特性，使得程序更为简洁。\n在前面我们说过，一旦 Promise 的状态改变，就无法再进行改变了，Promise 是单决议的。这在很多时候有利于程序的安全，但在某些时候却是非常尴尬的，比如交互事件。click 事件每次触发都会进行响应，但 Promise 在第一次触发后就已经决议过，此后再也无法改变状态，这并不是我们想要的效果。\n其次，Promise 一旦创建就无法被终止，我们通过外部来终止一个 Promise 是非常不安全的，因为这会影响其它 Promise 的决议结果。在某些情况下，比如一旦请求超时，我们希望能立即终止 Promise，但目前还没有更安全的方法来解决这个问题。\nPromise 虽然相对于回调函数更方便、简单。安全一些，但其本质还是基于回调函数的，并且比回调函数要做的事情更多。这也就意味着 Promise 的性能可能并不比 回调函数高，但回过头来说，微小的性能损失与极大的便利和安全来说，相信后者是我们选择 Promise 的理由。\nFetch 基于 Promise API，现在为我们提供了简单、方便的 Fetch API 作为一种异步获取数据的备选方案。Fetch 并不能完全替代 Ajax，Fetch 只是简单的提供了异步获取数据的功能，而 Ajax 则提供了一系列的事件机制来帮助我们更细粒度的掌控数据获取过程的情况。\nAjax（XMLHttpRequest） 大多时候我们使用的 Ajax API 都是其它辅助库（例如 jQuery）为我们封装好的，而原生的 Ajax 使用是这样的：\nvar xmlhttp; if (window.XMLHttpRequest){ // IE7+, Firefox, Chrome, Opera, Safari 浏览器执行代码 xmlhttp = new XMLHttpRequest(); } else { // IE6, IE5 浏览器执行代码 xmlhttp = new ActiveXObject(\u0026quot;Microsoft.XMLHTTP\u0026quot;); } xmlhttp.onreadystatechange = function(){ if (xmlhttp.readyState == 4 \u0026amp;\u0026amp; xmlhttp.status == 200){ document.getElementById(\u0026quot;myDiv\u0026quot;).innerHTML = xmlhttp.responseText; } } xmlhttp.open(\u0026quot;GET\u0026quot;, \u0026quot;/api/getData\u0026quot;, true); xmlhttp.send(); 可以看出来，原生的 Ajax 使用起来是比较麻烦的，但同样地，XMLHttpRequest 对象提供了许多事件来为我们提供一些实际需求的解决方案，例如进度显示。\nFetch 更简洁的备选方案 然而，更多的场景下我们只是需要异步获取数据即可，不需要那么细粒度的控制，这时候使用 Ajax 反而显得非常麻烦了，于是出现了 Fetch 这种使用起来更简洁的备选方案。\nFetch 是基于 Promise 的，所以编码风格与其一致。来看看如何使用原生的 Fetch API 获取数据：\nfetch('/api/getData', { method: 'GET' }) .then(response =\u0026gt; response.json() ) .then(json =\u0026gt; console.log(json) ) .catch(err =\u0026gt; alert(err.message) ); 看起来，fetch 使用起来要简单不少，它是在客户端构造一个 Request 对象发送给服务器，然后服务器返回一个 Response 对象返回给客户端；而且也基于 Promise 解决了回调嵌套的问题。\n在使用 Fetch API 的过程中仍然要注意一些问题。\n######### 默认不携带 Cookie\nfetch 发送请求默认是不携带 Cookie 信息的，不管是同域还是跨域请求；因此，在需要使用 Session-Cookie 机制进行权限验证的场景下，务必配置 credentials 项：\nomit：默认值，请求不携带 Cookie 信息； same-origin：允许同域请求携带 Cookie 信息，跨域请求则不允许； include：同域或跨域请求皆携带 Cookie 信息 exp：\nfetch('/api/getData', { method: 'GET', credentials: 'same-origin' }) .then(response =\u0026gt; response.json() ) .then(json =\u0026gt; console.log(json) ) .catch(err =\u0026gt; alert(err.message) ); ######### 仅在请求不能完成时 reject\n因为 fetch 是基于 Promise 的，而服务器响应的 Response 对象中封装的信息（例如响应状态码 200、403 等）不会作为 reject 的条件，而是仅在客户端与服务器端发生网络错误不能顺利完成请求时才会 reject。\n所以，这就需要在服务器返回 Response 对象时我们做一些简单的检验工作。\nfetch('/api/getData', { method: 'GET' }) .then(response =\u0026gt; { // check status if(response.status === 200){ return response.json(); } else { throw new Error(response.statusText); } }) .then(json =\u0026gt; console.log(json) ) .catch(err =\u0026gt; alert(err.message) ); ######### GET 请求\n在发送 Get 请求时，参数一般就携带在 url 中。\nfetch('/api/getData?t=' + new Date().getTime(), { method: 'GET' }) .then(response =\u0026gt; response.json() ) .then(json =\u0026gt; console.log(json) ) .catch(err =\u0026gt; alert(err.message) ); ######### POST 请求\n**在发送 Post 请求时，参数只能携带在 body 中，而且即便没有参数，body 也不能为空。**参数通常使用 FormData 对象来构建。\nlet formData = new FormData(); formData.append('username', 'mrwang'); formData.append('password', '123456'); fetch('/api/postData', { method: 'POST', body: formData }) .then(response =\u0026gt; response.json() ) .then(json =\u0026gt; console.log(json) ) .catch(err =\u0026gt; alert(err.message) ); 更重要的是，现在（2018 年），Fetch API 已经在主流浏览器中获得了广泛的支持，所以不用太担心兼容问题。\n参考 《你不知道的 JavaScript》（中卷），[美] Kyle Simpson，单业 姜南 译 "},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-git/","title":"使用 Git","description":"Git 是一个分布式的版本控制工具，类似的版本控制工具还有 SVN ；由于 GitHub 平台的盛行，也使得 git 更加受欢迎，在 Windows 平台使用 git 也是非常方便的。","date":"December 31, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 工具, Git","tags":"","content":"Git 是一个分布式的版本控制工具，类似的版本控制工具还有 SVN ；由于 GitHub 平台的盛行，也使得 git 更加受欢迎，在 Windows 平台使用 git 也是非常方便的。\nGit Git 是一个非常强大的版本控制工具，所谓的版本控制即就是对一个项目的更改进行记录，随后可以进行撤销、查看等功能。对于大型的开源项目，版本控制工具提供了非常大的便利，可以多人同时协作开发。Github 则提供了这样一个平台，使用 git 进行项目维护，世界上大多数的开源项目都在 github 仓库中进行展示。而 github 对程序员也是友好的，因为我们个人也可以使用免费的仓库，来维护自己的项目。\nGit 源于 Linux ，但不仅仅限于 Linux 平台下的使用， Git for Windows 就是最好的选择：\n**Git for Windows：**https://git-scm.com/\n该网站的文档页面提供了很多有用的资源，例如 Git 相关的书《Pro Git》、常用 Git 命令备忘单、Git 命令可视化备忘单等等有用的免费资源。\nGit Bash Git 在 Windows 下提供了图形用户界面（Git GUI）和命令行（Git Bash）两种操作方式，不过我更推荐使用后者，命令行更快速、简单一些。\n安装好后，我们打开 Bash 终端，可以在界面上 右键\u0026ndash;\u0026gt;Options\u0026ndash;\u0026gt;Text，更改字体大小和字符编码，推荐将字符编码改为 UTF-8。\n配置 我们首先可以对 Git 进行简单的配置，使用 SSH 来避免重复提交时每次都要输入密码。\n######### 个人信息\n进行用户名和邮箱的全局配置：\ngit config --global user.name \u0026#34;LeeZChuan\u0026#34; git config --global user.email \u0026#34;mrLeeZChuan@126.com\u0026#34; 查看配置信息：\ngit config --global -l ######### SSH 密钥\n安装 SSH 密钥可以在我们进行项目提交时避免重复输入用户名密码，也更安全。可以直接查看 GitHub 官方文档：\n**Help：**https://help.github.com/articles/generating-an-ssh-key/\n检查是否已有 SSH 密钥文件：\nls -al ~/.ssh 如果不存在（或者想覆盖），可以生成一个新的 SSH 密钥文件：\nssh-keygen -t rsa -b 4096 -C \u0026#34;wangyuan230@163.com\u0026#34; 这里使用你的邮箱作为 SSH 密钥标签，该过程中直接全按回车即可。\n得到 SSH 密钥文件后，接下来应该将该密钥添加到 ssh-agent ：\n# 启动 ssh-agent eval $(ssh-agent -s) # 添加 SSH ssh-add ~/.ssh/id_rsa 最后将 SSH 添加到你的 GitHub 账户即可，先将密钥文件复制到剪切板：\nclip \u0026lt; ~/.ssh/id_rsa.pub 然后，打开 GitHub 网站登录你的帐户，右上角头像进入 Settings，左边导航选择 SSH and GPG keys，点击 New SSH key，自己命名一个 title，然后将 SSH 文件复制到 key 框中，然后需要输入你的 github 账户密码。\n最后，可以测试一下：\nssh -T git@github.com 回车后输入 yes，如果看到 Hi {你的用户名} 一串信息，就说明添加 SSH 密钥成功了。\n######### HTTPS\nSSH 虽然安全方便，但配置略显复杂。自从大部分网站从 HTTP 升级到 HTTPS 协议后，信息传输安全性也大大提高了，GitHub 目前全站采用了 HTTPS 协议。因此，现在 GitHub 推荐我们使用 HTTPS，即便捷又安全。\n在使用 HTTPS 协议进行一些 git 操作时，为了避免需要重复输入用户名和密码进行验证，git 提供了 credential.helper 配置项来使用第三方凭证管理工具保存用户名和密码，并在需要验证的时候自动进行调用。\n在 Windows 平台安装 git 的时候，默认配置了 credential.helper 为 manager，在 Bash 命令行输入以下命令即可查看到该配置项：\n\u0026gt; git config --system --list credential.helper=manager 该配置使得我们在进行 git 操作（push 等）时第一次输入用户名和密码，验证成功后，往后的所有操作不再需要进行重复的手动输入验证。在 Win 菜单搜索网络密码管理打开后即可看到保存的 git 服务的用户凭证；同时，登录你的 GitHub Web 客户端后，进入 Settings -\u0026gt; Developer settings -\u0026gt; Personal access tokens 即可看到这里增加了一个 token，在这里可以很方便的管理通过 HTTPS 验证的 PC。\n######### 其它配置\n除过以上必须的基本配置外，还有一些比较有用的可选配置。\ncore.ignorecase=false，开启文件名大小写检查。 git config --global core.ignorecase false 由于多个平台（Win/Mac/Linux）对于文件是否相同判断机制不同，部分平台认为文件名大小写不同仍然是同一个文件，而 Linux 却认为是不同的文件，Git 为了兼容默认是忽略掉文件名大小写检查的，这就导致我们重命名（仅修改大小写）文件之后发现提交到远程仓库没有变化，重命名未生效，更改该配置即可。\nfetch.prune=true，保持干净的本地分支列表。 git config --global fetch.prune true 通常，我们会在本地进行多分支开发，其中某些分支只是暂时的，后续会合并到其它分支（例如 master），尤其是一般提交的 PR 被合并后会自动删除远程仓库的被合并分支，那么对应的本地分支必须要手动删除，为了自动完成这一过程，保持本地分支列表干净可以配置此选项。\n使用 Git 下面来看看 git bash 中一些常用的 git 命令，介绍一下其简单的用法，利用 git 来管理我们的代码。\n初始化 在创建好一个新文件夹之后，进入该空白文件夹，我们在 git bash 中输入 init 命令即可初始化该文件夹为一个新的 git 仓库。\n# 初始化仓库 git init 初始化完成后，该文件夹会出现一个隐藏的 .git 文件夹，可以使用 ls 命令查看是否已生成该文件夹：\n# 查看文件 ls -a 该文件夹为仓库管理文件，并且是隐藏，一般情况下不要修改其中的文件。\n添加与提交 Git 的工作状态有 3 个，分别为 工作区（working directory）、暂存区（staging index） 和 版本库（Repository）。我们在个人仓库（本地文件夹）中修改代码时，就处于工作区中；修改完成后，需要使用 add 命令将修改好的文件添加到暂存区中；随后，确认无误后我们可以使用 commit 命令将已添加到暂存区的文件提交到版本库中。\n# 第一步：添加文件到暂存区 git add file_name # 例如 git add index.html # 第二步：将暂存区文件提交到版本库中 git commit -m \u0026#34;version_message\u0026#34; # 例如 git commit -m \u0026#34;1.0\u0026#34; 另外地，为了方便我们可以一次性将当前文件夹（工作区）的所有文件都添加到暂存区中：\n# 添加工作区所有文件到暂存区 git add . 当然了，我们还可以将添加与提交操作合二为一，跳过暂存区：\n# 一次性添加与提交工作区文件到版本库 git commit -am \u0026#34;version_message\u0026#34; ######### 调试技巧\n这里有一个小技巧，通常为了测试一些 hook 事件程序（例如 husky），我们会做一下某些文件的细微改动然后提交来触发相应事件，但 --allow-empty 选项可以让我们更方便一些：\n# 直接执行即可，不用改动任何文件 git commit --allow-empty -m \u0026#39;it works!\u0026#39; 查看信息 如果能随时查看仓库中文件的修改情况以及与版本库中文件进行对比的结果可以方便很多，其实使用 status 和 log 命令即可查看所需要的信息。\n# 查看目前文件修改情况（是否已添加、提交） git status # 查看已提交的文件日志 git log 撤销操作 当我们将文件修改后，如果发现更改并不恰当，需要回滚到修改之前的状态时，可以撤销我们的更改操作。\n# 撤销工作区改动，将暂存区文件覆盖到工作区 git checkout -- file_name 这个命令所做的就是用暂存区中的文件来覆盖工作区已被修改的文件，从而实现撤销工作区的修改操作。\n# 撤销暂存区改动，将版本库文件覆盖到暂存区 git reset HEAD -- file_name 而这个命令所做的则是用版本库中的文件来覆盖暂存区中已被修改的文件，从而实现撤销暂存区的修改操作。这里的 HEAD 指的是最近一次提交操作，可以将其更换为你需要撤销的提交操作的 ID 号，可以使用 log 命令查看提交信息中的 ID。\n实际上，先撤销暂存区改动，再撤销工作区改动，就可以将版本库中的文件恢复到工作区中。另外，还可以撤销提交操作并重新进行提交，这个命令可以用来修改提交信息和内容。\n# 第一次提交 git commit -m \u0026#34;version 1.0\u0026#34; # 撤销上次提交修改提交信息并重新提交 git commit --amend 删除操作 有时候我们可能把不需要添加到暂存区的文件给添加到了暂存区，这时候可以使用以下命令将其在暂存区中删除：\n# 仅删除暂存区中的文件 git rm --cached file_name 当然，也有可能我们想直接删除掉工作区和暂存区中的文件：\n# 同时删除工作区与暂存区中的文件 git rm -f file_name 除此之外，还有一种情况就是我们在工作区将同一个文件重命名后，需要删除原有在暂存区中的文件，添加新的文件到暂存区中，但是它们的文件内容是相同的。所以，直接可以进行重命名操作：\ngit mv old_filename new_filename 远程仓库 通常，我们会将代码库推送到远程的代码托管平台上进行管理，例如：\nGithub Gitlab BitBucket Gitee（开源中国） 在其它设备上就可以从远程仓库拉取代码：\n# 可指定文件夹名称，不指定的话与仓库同名 git clone \u0026lt;rep_url\u0026gt; [dir_name] # 查看本地仓库关联的远程仓库 git remote -v # 查看本地仓库分支关联的远程仓库分支 git branch -vv 在本地仓库完成开发后，经过 `add`、`commit` 之后，即可推送到远程仓库进行同步： # 推送到远程仓库，默认为 origin 仓库，当前分支 git push [origin] [current_branch] 如果是通过 git clone 从远程仓库拉取到本地的，可以看到会有一个默认的 origin 远程仓库；但是，如果是在本地建立的仓库，没有与远程仓库关联，可以先添加一个远程仓库，然后在推送时指定一个远程仓库，或者将本地仓库与远程仓库关联：\n# 添加远程仓库 git remote set-url \u0026lt;name\u0026gt; \u0026lt;rep_url\u0026gt; # or git remote add \u0026lt;name\u0026gt; \u0026lt;rep_url\u0026gt; 在推送时指定一个远程仓库 git push --set-upstream \u0026lt;remote\u0026gt; \u0026lt;remote_branch\u0026gt; 将本地分支与远程分支关联 git branch --set-upstream-to=\u0026lt;remote\u0026gt;/\u0026lt;remote_branch\u0026gt; \u0026lt;local_branch\u0026gt; 多仓库同步 鉴于一个平台可能存在风险，可以将代码托管在多个平台上，例如国外 Github，国内 Gitee，实现的具体方式就是将本地仓库同时与多个远程仓库关联，即可实现在 push 时给多个远程仓库同步推送更新：\n# 在某个 remote 下添加额外一个远程仓库 git remote set-url --add \u0026lt;name\u0026gt; \u0026lt;new_rep_url\u0026gt; 分支管理 Git 是一个版本控制工具，可以实现多人协作处理同一个项目的代码，同时又互不发生冲突。而要实现多人协作互不发生冲突，团队成员就不能同时操作同一个文件，于是 Git 中有一个分支（branch）的概念需要我们弄清楚，因为就是它解决了这个关键的问题。\n当首次提交文件到版本库时，会自动创建一个 主分支（master），多人协作时我们不能同时在主分支上操作，因为会发生冲突。所以，我们可以从主分支（master）上分出多个副分支来，就像从一颗树的主干上长出多个分叉枝节一样，我们在这些副分支上进行修改操作。当修改完成后，我们再将副分支上的更改合并到主分支（master）上即可，这样就不会出现多人同时操作同一个文件的冲突。\n查看分支 在项目第一次提交到版本库时，会自动创建一个主分支（master），随后就可以创建副分支了。当我们想查看该项目的分支情况时，使用 branch 命令即可。\n# 查看项目分支 git branch 创建分支 在 master 分支上我们可以创建多个副分支并自己命名，使用以下命令即可：\n# 创建新的分支，但不切换 git branch branch_name # 例如 git branch dev 切换分支 切换分支就是 checkout 命令：\n# 切换到另一个分支上 git checkout branch_name # 例如 git checkout dev 其实，我们可以直接在创建新分支时切换到新分支上去：\n# 创建新的分支，并切换到新分支 git checkout -b branch_name 重命名分支 可以使用以下命令来更改一个已有副分支（因为主分支是不能重命名）的名字：\n# 重命名已有的副分支 git branch -m old_branchname new_branchname 删除分支 当我们想删除一个分支时，先切换到其它分支上去，再使用以下命令：\n# 删除已有的副分支，注意先切换到其它分支 git branch -d branch_name 合并分支 当副分支上的工作完成后，就需要将副分支合并到主分支上去，此时应先切换到主分支上去，再使用 merge 命令：\n# 合并分支，注意先切换到主分支上去 git merge branch_name 对比差异 很多时候我们需要查看工作区与暂存区、暂存区与版本库、分支与分支等等之间文件的具体改动的差异信息，使用 diff 命令即可：\n# 对比工作区与暂存区的文件差异 git diff # 对比暂存区与版本库的文件差异 git diff --staged # 对比分支与分支的文件差异 git diff other_branchname 除此之外，还可以对比两次提交版本的文件差异，在 diff 命令后跟要对比的两次提交操作的 ID 号即可。\n保存工作区状态 当我们在一个分支上改动了工作区的文件，没有添加到暂存区并提交到版本库时，使用 checkout 切换分支时就会失败，因为这样会丢失工作区的更改。我们可以提交后再切换分支，当然也可以使用 stash 命令将此分支的工作区状态保存下来再切换到别的分支，之后回到该分支可以还原工作区的状态。\n# 保存当前分支工作区状态 git stash # 查看所有分支已保存的工作区状态及其序号 git stash list 保存了工作区状态之后，我们可以在任意分支下将保存的工作区状态与当前工作区状态合并，先查看保存的工作区状态序号：\n# 合并当前工作区与已保存工作区，不删除已保存状态 git stash apply stash@{num} # 例如 git stash apply stash@{0} 合并之后，可以删除掉已保存的工作区状态，同样地先查看保存的工作区状态序号：\n# 删除已保存的工作区状态 git stash drop stash@{num} 当然，为了方便我们可以一次性完成合并工作区与删除已保存的工作区状态：\n# 合并工作区状态，并删除已保存的工作区状态 git stash pop stash@{num} 参考资料 以上是对使用 Git 最常见场景的一些指导，这里再记录一些非常好的学习资料，方便学习和查阅。\nGit 命令学习 Learning Git Branching Git Command Explorer Git 工作流模型 Git Flow GitLab Flow GitHub Flow GUI 客户端 Sourcetree "},{"section":"Blog","slug":"/blog/computer-technology/linux/linux-cmd-vim/","title":"Linux-Vim 编辑器","description":"在 Linux 这样的命令行操作系统中，必须有一款功能强大的编辑器支持我们快速完成文本编辑，这就是 Vi 编辑器；通过对其加强和升级，Vim 编辑器比前者更为强大，拥有更多的功能和颜色高亮的特性，是程序员在 Linux 下编码的利器。","date":"October 28, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 计算机, Linux","tags":"","content":"在 Linux 这样的命令行操作系统中，必须有一款功能强大的编辑器支持我们快速完成文本编辑，这就是 Vi 编辑器；通过对其加强和升级，Vim 编辑器比前者更为强大，拥有更多的功能和颜色高亮的特性，是程序员在 Linux 下编码的利器。\nVim Vim 是基于 Linux 下 Vi 编辑器的升级版，经过多年来的不断更新，功能也越来越强大，Vim 除过具备常用文本编辑器的编辑操作以及颜色高亮特性外，还支持自动补全、多行批量操作、指定跳转等等功能，其中代码颜色高亮特性更利于我们在命令行中进行信息的阅览和查看。而且，Vim 支持大多数操作系统，只是我们经常在 Linux 下使用它而已。当然，在 Linux 下还有一款很著名的编辑器 Emacs 。\nVim 太过强大，导致学习曲线也是非常陡峭的，不过作为一个工具，我们首先只要掌握它的基本操作就行了，至于其他功能待我们在使用过程中去发掘就行了。首先，我们应该知道 Vim 有三种模式，即命令模式、插入模式、EX 模式。\n命令模式\n此模式是 Vim 的默认模式，我们可以做一些非输入操作，例如删除、复制等等，在此模式下可以进入插入模式和 EX 模式。\n插入模式\n此模式就是编辑模式，我们主要进行输入操作。\nEX 模式\n此模式则是当我们完成编辑后，可以进行退出、保存等操作。\n常用命令 接下来，就介绍一些常用的命令，通过这些命令我们可以很方便的快速完成大多数常用操作。\n模式切换 # 命令模式进入插入模式 i // 在当前字符前开始编辑 a // 在当前字符后开始编辑 I // 在当前行首开始编辑（Shift + I ，或者开启大写） A // 在当前行尾开始编辑（Shift + A ，或者开启大写） o // 在当前行下添加新行开始编辑 O // 在当前行上添加新行开始编辑（Shift + O ，或者开启大写） # 命令模式进入EX模式 : // （Shift + ;） # 插入模式或EX模式返回到命令模式 Esc // 至少按一次 Esc 即可返回命令模式 命令模式 命令模式是 Vim 的核心模式，大多数强大的功能命令都需要在此模式下完成，常用的命令则有复制、删除、粘贴、移动等等。而且，只有在命令模式下才能进入插入模式或者 EX 模式。\n移动光标 h // 光标左移 j // 光标下移 k // 光标上移 l // 光标右移 fx // 移动光标到当前行的下一个 x（任意字母）处（; 重复上一个f命令） Fx // 移动光标到当前行的上一个 x（任意字母）处（; 重复上一个F命令） tx // 移动光标到当前行的下一个 x（任意字母）左边（; 重复上一个t命令） Tx // 移动光标到当前行的上一个 x（任意字母）左边（; 重复上一个T命令） w // 光标后移一个单词到词首（W 也行） e // 光标后移一个单词到词尾（E 也行） b // 光标前移一个单词到词首（B 也行） * // 向下匹配当前光标所在字符串 # // 向上匹配当前光标所在字符串 ^ // 光标移动到行首（数字 0 也行） $ // 光标移动到行尾 gg // 光标移动到文件首行行首（ngg 第n行行首） G // 光标移动到文件末行行首（nG 第n行行首）（Shift + G ，或者开启大写） `. // 光标返回到上次编辑的位置 `a // 光标移动到书签a处 % // 光标在 ()、[]、{} 等符号之间左右移动 H // 光标移动到当前屏顶端行首 M // 光标移动到当前屏中部行首 L // 光标移动到当前屏底部行首 Ctrl + F // 向下移动一屏 Ctrl + D // 向下滚动半屏 Ctrl + B // 向上滚动一屏 Ctrl + U // 向上滚动半屏 复制、粘贴、剪切/删除 # 复制 yy // 复制光标所在整行 nyy // 复制光标所在行开始向下 n 行，例如 2yy # 粘贴 p // 光标所在行下方添加一行并粘贴剪贴板或该行 np // 光标所在行下方添加 n 行并粘贴剪贴板或该行，例如 2p P // 光标所在行上方添加一行并粘贴剪贴板或该行 nP // 光标所在行上方添加 n 行并粘贴剪贴板或该行，例如 2P # 删除/剪切 dd // 删除/剪切光标所在整行，D 亦可 ndd // 删除/剪切光标所在行开始向下 n 行，nD 亦可，例如 2dd dgg // 光标所在行到文档开头之间全部删除/剪切 dG // 光标所在行到文档结尾之间全部删除/剪切 dngg // 光标所在行到第 n 行之间全部删除/剪切，dnG 亦可，例如 d2gg d+^ // 光标所在字符到行首之间全部删除/剪切 d+$ // 光标所在字符到行尾之间全部删除/剪切，D 亦可 dw // 删除光标所在处一个单词、符号 x // 删除光标所在字符 nx // 删除光标所在字符开始向后 n 个字符，例如 2x nX // 删除光标所在字符开始向前 n 个字符，例如 2X 撤销、恢复 u // 撤销 Ctrl+r // 恢复 插入模式 插入模式其实就是我们所说的编辑模式，输入模式，进行字符输入操作。在该模式下，可以按 Esc 即可退回到命令模式。\nEX 模式 EX 模式可以在我们编辑完之后，进行一些保存、退出操作；也可以在我们编辑中途进行一些额外的操作。\n:w // 保存当前修改 :q // 退出 :q! // 强制退出，不保存修改 :x // 保存并退出（等价 :wq） :set nu // 显示行号（全写 :set_number） :set nonu // 隐藏行号（全写 :set_nonumber） :! [命令] // 执行一个命令并显示结果 :sh // 切换到命令行，使用 Ctrl+D 切换回 vim 配置 "},{"section":"Blog","slug":"/blog/computer-technology/linux/linux-cmd-shell/","title":"Linux-常用 Shell 命令","description":"Linux 是一个优秀的开发环境，大多数服务器都在上面部署。作为一个程序员，熟悉Linux 系统的常用操作也是很必要的。在 linux 内核外，shell 提供了我们程序员（用户）与内核之间的交互媒介，shell 可以说是一个命令解释器，当然它也负责将内核输出信息翻译给程序员。","date":"October 21, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 操作系统, Linux","tags":"","content":"Linux 是一个优秀的开发环境，大多数服务器都在上面部署。作为一个程序员，熟悉Linux 系统的常用操作也是很必要的。在 linux 内核外，shell 提供了我们程序员（用户）与内核之间的交互媒介，shell 可以说是一个命令解释器，当然它也负责将内核输出信息翻译给程序员。\nShell Linux 是一个基于命令行的操作系统，提供了一个命令解释器，即 Shell（壳）。Shell 是一个软件，是操作系统的用户界面，用户通过在 Shell 中输入命令，然后命令解释器解释完成后将指令送往内核中执行，来实现对 Linux 系统的操作。\nLinux 中的 Shell 也有不同的版本：Bourne Shell（贝尔实验室开发）、Bash（GNU 开发）、C shell（Sun 公司开发）、Z shell（集成了前几种 shell 的优点）等等，我们目前最常用的就是 Bash。\n常用命令 下面将是一些常用的 Shell 命令的总结，熟悉这些命令能帮助我们更快的适应 Linux 系统的环境。\n目录、文件 文件与目录是系统中最常见的基本单位，这里介绍一些常用的文件、目录操作。\n# 文件属性与权限（总共10位） [-][---][---][---] # 第1位：-表示文件；d表示目录；l表示软链接 # 第2-4位：rwx 所有者（user）用户权限 # 第5-7位：rwx 所属组（group）用户权限 # 第8-10位: rwx 其他用户权限 r （可读） w （可写） x （可执行） # 示例 -rwxr-xr-x # 这是一个文件，所有者可读可写可执行，所属组与其他用户可读可执行但不可写 pwd # 查看当前路径 cd [目录] # 切换到目标目录 创建 # 目录 mkdir [目录] # 创建一个空目录 mkdir -p [目录/子目录/] # 创建一个多层嵌套目录 # 文件 touch [文件] # 创建一个文件，或者更新已有文件时间 删除 # 命令格式 rm [选项] [目录文件] # 命令选项 -i # 删除时提示 -r # 允许删除目录 -f # 忽略提示警告 # 命令示例 rm -rf ./tmp # 删除当前目录下的tmp文件或目录，忽略提示警告 rmdir [目录] # 删除一个目录（只能删除空目录） 查看 # 目录 # 命令格式 ls [选项] [目录] # 命令选项 -d # 查看目录属性 -a # 查看目录内所有文件和子目录，包括隐藏的 -l # 显示文件、子目录详细信息 -h # 显示文件、子目录大小（带单位） -i # 显示文件、子目录 inode -R # 递归显示目录（显示子目录的子目录路径） # 命令示例 ls -a # 查看当前目录所有文件、子目录 ls -lh /root/ # 查看root目录内所有文件、子目录并显示详细信息和大小 # 文件 cat [文件] # 查看文件内容 file [文件] # 查看文件类型 head [-n] [文件] # 显示文件内容开始n行（默认10行） tail [-n] [文件] # 显示文件内容末尾n行（默认10行） -f # 持续更新文件末尾内容（方便查看更新的日志） more [文件] # 翻页显示文件内容（只能向下翻页） less [文件] # 翻页显示文件内容（上下翻页） 复制 # 命令格式 cp [选项] [源目录文件] [目标目录] # 命令选项 -r # 允许复制目录 -p # 同时复制文件属性 -d # 若源文件是链接文件，则复制链接属性 -a # 相当于 -pdr -v # 显示详细信息 # 命令示例 cp -r ./tmp1 ./tmp/ # 将当前目录下的tmp1目录或文件复制到当前目录下tmp目录内 剪切 mv [源目录文件] [目标目录] # 剪切目录或文件 mv [旧目录文件名] [新目录文件名] # 重命名 搜索 由于命令行的界面给我们查看系统文件带来了视觉上的不便，所以学会使用命令去搜索文件会给我们了解系统中存放的文件情况带来方便。\nlocate # 搜索某个目录、文件的所在路径 locate [文件] # 在后台数据库中搜索，速度快；但是最近新建的不能找到，需执行 updatedb 更新数据库 find # 搜索某个目录、文件的所在路径，以及详细信息等 # 命令格式 find [搜索范围] [选项] [搜索目标] # 命令选项 -name # 按目录或文件名搜索 -user # 按用户名搜索 -nouser # 搜索没有用户的目录、文件 -mtime # 按内容修改时间搜索 -atime # 按内容访问时间搜索 -ctime # 按属性修改时间搜索 -size # 按目录、文件大小搜索 -inum # 按目录、文件 inode 搜索 # 命令示例 find ./ -name tmp # 在当前目录下搜索名字为tmp的目录和文件 find / -nouser # 在根目录下搜索没有用户的目录和文件 find ./ -mtime +10 # 在当前目录下搜索10天前修改的目录和文件 find ./ -size 25k # 在当前目录下搜索大小为25KB的目录和文件 find ./ -size +25k -a -size -50k # 在当前目录下搜索大小为25KB到50KB的目录和文件 find ./ -inum 262 # 在当前目录下查找inode是262的目录和文件 # 执行多条命令（后一条命令接受前一条命令的结果） find [搜索范围] [选项] [搜索目标] -exec [命令] [选项] {} \\; # 命令示例 find ./ -size 25k -exec ls -lh {} \\; # 搜索当前目录下大小是25KB的目录和文件并显示详细信息 whereis # 搜索命令所在路径及帮助文档 # 命令格式 whereis [选项] [命令] # 命令选项 -b # 只查找可执行文件（命令） -m # 只查找帮助文件 # 命令示例 whereis ls # 查找 ls 命令可执行文件所在路径及帮助文档所在路径 which # 搜索命令所在路径以及别名 which [命令] grep # 搜索文件内容 # 命令格式 grep [选项] [搜索内容] [文件] # 命令选项 -v # 结果取反 -i # 忽略大小写 # 命令示例 grep \u0026quot;Hello\u0026quot; hello.sh # 搜索 hello.sh 文件内包含Hello字符串的地方 帮助 事实上，Linux 下的 shell 命令大概有三千左右个，而且常用的也非常多，我们不可能去死记硬背，学会适当的时候去查看命令的帮助文件也是很好的。\nman # 命令格式 man [选项] [级别] [命令] # 命令选项 -f # 查看命令所有级别（等价于 whatis ） -k # 查看所有相关命令（等价于 apropos ） # 命令示例 man ls # 查看 ls 命令详细帮助 help [命令] --help # 查看 shell 外部命令的详细帮助，如 ls help [命令] # 查看 shell 内部命令的详细帮助，如 cd（可用 whereis 判断是否内部命令） info # 命令格式 info [命令] # 帮助页面命令 - 回车 # 进入子帮助页面 - u # 进入上层页面 - n # 进入下一个帮助小节 - p # 进入下一个帮助小节 - q # 退出帮助页面 压缩、解压 Linux 系统下的多数应用软件都是以源代码的方式打包，而解压缩则是安装应用软件的常用操作。\n.zip 格式 # 压缩 zip [压缩文件名] [源文件] zip -r [压缩文件名] [源目录] # 解压 unzip [源目录文件] .gz 格式 # 压缩 gzip [源文件] # 直接压缩源文件，源文件消失 gzip -c [源文件] \u0026gt; [压缩文件名] # 本质是写入一个压缩文件，源文件不消失 gzip -r [源目录] # 只会压缩源目录内源文件，源文件消失 # 解压 gzip -d [源文件] # 源文件消失 gunzip [源文件] # 源文件消失 gunzip -r [源目录] # 源目录内源文件解压，源文件消失 .bz2 格式 # 压缩（不能压缩目录） bzip2 [源文件] # 源文件消失 bzip2 -k [源文件] # 保留源文件 # 解压 bzip2 -d [源文件] # 源文件消失 bzip2 -dk [源文件] # 保留源文件 bunzip2 [源文件] # 源文件消失 bunzip2 -k [源文件] # 保留源文件 .tar 包格式 # 打包、解包 tar [选项] [包文件名] [源文件] # 命令选项 -c # 打包 -x # 解包 -t # 查看包内文件 -v # 显示过程 -f # 指定打包后文件名 # 命令示例 tar -cvf bag.tar bag # 打包一个目录或文件 tar -xvf bag.tar # 解包 tar -tvf bag.tar # 查看包内文件 .tar.gz，.tar.bz2 格式 # 压缩 tar -zcvf [压缩文件名] [源目录文件] # 保留源目录文件（-z 为 .gz 格式） tar -jcvf [压缩文件名] [源目录文件] # 保留源目录文件（-j 为 .bz2 格式） # 解压 tar -zxvf [源文件名] # 保留源文件（-z 为 .gz 格式） tar -jxvf [源文件名] # 保留源文件（-j 为 .bz2 格式） 命令历史 history # 所有曾经执行过的命令 -c # 清空历史命令 -w # 把缓存中的历史命令保存在文件中 ./bash_history !! # 执行上一条命令 !u # 执行曾经以u开头的命令 !12 # 执行曾经第12命令 !-n # 执行曾经第前n个命令 !?name # 执行曾经包含name的命令 Ctrl+R # 搜索曾经执行过的命令 # 按 ESC 后再按 . 会增加上一个命令的选项 命令别名 alias # 查询所有别名 alias ls=\u0026quot;ls --color=never\u0026quot; # 设置别名 unalias ls # 删除别名 # 用户目录下的 bashrc ，设置别名永久生效 source .bashrc # 让文件立即执行，别名立即生效 IO 这里简单介绍一些输入、输出重定向的命令。\n输出重定向 # 标准输出重定向 [命令] \u0026gt; [文件] # 以覆盖的方式，把命令的正确输出到指定文件或者设备中去 [命令] \u0026gt;\u0026gt; [文件] # 以追加的方式，把命令的正确输出到指定文件或者设备中去 # 标准错误输出重定向 [错误命令] 2\u0026gt;[文件] # 以覆盖的方式，把命令的正确输出到指定文件或者设备中去（注意\u0026gt;后无空格） [错误命令] 2\u0026gt;\u0026gt;[文件] # 以追加的方式，把命令的正确输出到指定文件或者设备中去（注意\u0026gt;\u0026gt;后无空格） # 标准正确和错误输出同时保存 [命令] \u0026gt; [文件] 2\u0026gt;\u0026amp;1 # 覆盖方式 [命令] \u0026gt;\u0026gt; 文件 2\u0026gt;\u0026amp;1 # 追加方式 [命令] \u0026amp;\u0026gt;[文件] # 覆盖方式（注意\u0026gt;后无空格） [命令] \u0026amp;\u0026gt;\u0026gt;[文件] # 追加方式（注意\u0026gt;\u0026gt;后无空格） [命令]\u0026gt;\u0026gt;[文件1] 2\u0026gt;\u0026gt;[文件2] # 正确输出保存到文件1，错误输出保存到文件2（注意\u0026gt;\u0026gt;后无空格） 输入重定向 wc # 输入内容，输入完成后Ctrl+D -c # 统计字节数 -w # 统计单词数 -l # 统计行数 wc \u0026lt; [文件] # 将文件内容输入 wc \u0026lt;\u0026lt; [定界符] # 结束定界符 管道符 [命令1] | [命令2] # 命令1的正确输出作为命令2的操作对象 系统命令 这是一些涉及到系统权限或者说有关系统信息的命令，应谨慎操作。\n关机、重启 shutdown\n# 命令格式 shutdown [选项] [时间] # 命令选项 -h # 关机 -r # 重启 -c # 取消前一个关机、重启命令 # 命令示例 shutdown -h now # 立即关机 shutdown -r 20:20 \u0026amp; # 20:20时重启（\u0026amp; 为后台运行） 其他命令\nreboot # 立即重启 poweroff # 立即关机 logout # 退出登录 # 非安全命令 init 0 # 0 关机 init 6 # 6 重启 # （0 关机 1 单用户 2 不完全多用户，无NFS 3 完全多用户 4 未分配 5 图形界面 6 重启） runlevel # 查看当前运行级别 [命令] \u0026amp; # 该命令在后台执行 用户、密码 su [用户名] # 切换到目标用户，默认是 root 用户 sudo [命令] # 以 root 权限执行该条命令 # 添加用户 useradd [选项] [用户名] -d # 指定用户目录 -g # 指定用户群组 passwd [用户名] # 更改目标用户密码，默认当前用户 登录日志 w # 查看系统中用户登录情况，资源情况 who # 查看系统中用户登录情况 last # 查看系统中用户登录日志 lastlog # 查看系统中所有用户最后一次登陆时间 日期、时间 date # 查看当前系统时间 date -s \u0026quot;20:00:00\u0026quot; # 修改当前时间 date +%Y--%m--%d # 格式化显示 进程管理 通常使用ps命令来查看系统运行的进程信息。\n# 显示在当前 shell 终端运行的进程 ps [选项] -[A|e] # 显示所有进程信息 -l # 显示长列表信息 # 示例 ps -ef # 查看系统中所有运行进程 # 实时显示系统进程信息 top # 杀死进程 kill [PID] killall [进程名] 磁盘管理 下面是一些用于对磁盘信息进行查看或者统计的命令。\n# 查看磁盘分区使用情况 df [选项] [路径] -l # 仅显示本地磁盘（默认选项） -a # 显示所有文件系统的磁盘使用情况 -h # 以1024进制自动换算合适的单位显示磁盘容量 -H # 以1000进制自动换算合适的单位显示磁盘容量 -T # 显示磁盘分区类型 -t # 显示指定类型文件系统的磁盘分区（比如EXT4） -x # 不显示指定类型文件系统的磁盘分区 # 统计磁盘上的文件大小 du [选项] [路径] -b # 以byte为单位统计文件（四舍五入） -k # 以KB为单位统计文件（四舍五入） -m # 以MB为单位统计文件（四舍五入） -h # 以1024进制自动换算合适的单位统计文件 -H # 以1000进制自动换算合适的单位统计文件 -s # 指定统计路径（默认是当前路径） 文件系统 仅仅分区之后，磁盘还是不能使用的，必须创建文件系统才能使用，此时也会首先格式化硬盘。\n# 创建文件系统 mke2fs [选项] [文件系统格式] [磁盘目录] -t # 指定文件系统格式 -b # 指定文件系统块大小 -L # 指定卷标 -j # 建立文件系统日志 # 命令示例 mke2fs -t ext4 /dev/sda3 # 简写操作命令 mkfs.[文件系统格式] [磁盘目录] # 命令示例 mkfs.ext4 /dev/sda3 # 查看文件系统的详细信息 dumpe2fs [磁盘目录] # 命令示例 dumpe2fs /dev/sda2 # 查看文件系统标签 e2label [磁盘目录] # 设置文件系统标签 e2label [磁盘目录] [标签名] # 检查目标磁盘文件系统是否损坏（已卸载） fsck [磁盘目录] -y # 不提示直接修复 -t # 指定修复的文件系统格式 挂载、卸载 mount # 查看系统中已经挂载的设备 mount -a # 按配置文件 /etc/fstab 的内容，自动挂载 mount -t [文件系统] -o [特殊选项] [设备文件名] [挂载点] # 挂载指定设备 umount [挂载点或设备文件名] # 卸载设备文件 fdisk -l # 查看系统中已经识别的硬盘 fdisk -t vfat [设备文件名] [挂载点] # 以 fat32 文件格式挂载U盘（linux 默认不支持 ntfs 文件系统） 端口 netstat -anp | grep 177 # 查看指定端口进程 系统服务 service [服务名称] [选项] service * start # 启动服务 service * stop # 停止服务 service * status # 服务状态 service * restart # 重启服务 系统信息 # 操作系统信息 uname [选项] -a # 所有信息，包含操作系统名称，计算机名、内核、架构 -m # 系统架构（32/64） hwclock # 查看硬件时钟时间（等价 clock 命令） uptime # 查看系统运行时间 lspci # 查看PCI设备 -v # 详细信息 lsusb # 查看USB设备 -v # 详细信息 lsmod # 查看加载的模块（驱动） 应用安装 dpkg -L [应用名称] # 查看已安装应用相关路径 dpkg --get-selections | grep [应用名称] # 查看已安装应用相关所有包 快捷键 下面是一些在 Bash 终端界面的快捷键。\nCtrl + C 强制终止命令 Ctrl + L 清屏命令 clear Ctrl + A 光标移动到行首 Ctrl + E 光标移动到行尾 Ctrl + U 删除整行 Ctrl + Z 把命令放入后台 Ctrl + R 在历史中搜索命令 "},{"section":"Blog","slug":"/blog/computer-technology/web/web-performance-optimize-skill/","title":"Web 前端性能优化：工具与技巧","description":"Web 前端的性能优化是非常迫切的，客户端的资源非常有限，而且层次不齐，很容易造成一些性能问题从而影响到最终给用户所呈现的数据信息结构的不完整。为了增强用户体验，我们必须在各个方面进行优化，同时也可以节省服务器成本。","date":"August 20, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 性能优化, 技巧","tags":"计算机技术, Web前端, 性能优化, 技巧","content":"Web 前端的性能优化是非常迫切的，客户端的资源非常有限，而且层次不齐，很容易造成一些性能问题从而影响到最终给用户所呈现的数据信息结构的不完整。为了增强用户体验，我们必须在各个方面进行优化，同时也可以节省服务器成本。\n页面优化 首先，也是最重要的我们需要关注页面级的优化。\n减少 HTTP 请求数 HTTP 协议是基于 TCP 连接的，我们都知道 TCP 连接要经过三次握手、四次挥手的过程才能完成数据信息的传输，所以过多的 HTTP 请求会导致网页响应过慢。虽然浏览器是支持 HTTP 请求并发的，但并发数量也是有限的。\n合理设置 HTTP 缓存\n如果我们的页面是极其复杂的，而且客户端首次加载页面所需要的所有资源是必须的；这个时候我们可以对后续加载进行优化，即合理设置 HTTP 缓存，当客户端再次加载该页面时，大多数 HTTP 请求所需要的资源都已缓存在本地，所以 HTTP 请求的数量会大幅降低。\n资源合并压缩\n我们在项目上线时，应尽可能将 JavaScript/CSS/Imagines 这些静态资源进行合并与压缩。js 与 css 代码都有其相应的合并压缩工具，同时服务器端基本都支持 Gzip 压缩；而多个小图片（图标等）则可以利用 CSS Sprites 技术合并后将它们嵌入页面。\n内联图片（inline imagines）\n图片经过转码之后，可以使用 data：URL scheme 进行加载而不需要 HTTP 请求，但这种方式不会缓存，而且过大的图片也会体积变大，IE8 以下也不支持。通常背景图片将使用这种方式来进行加载。\nCSS 置顶，JS 沉底 我们应该将样式文件在 \u0026lt;head\u0026gt; 中就引入，这样不会因为 CSS 的载入而页面重新渲染；同样的，尽可能将 js 代码在 \u0026lt;/body\u0026gt; 尾部引入，这样页面的渲染不会因为加载 js 而阻塞。\n延迟/异步加载 JS script 标签是支持 defer 和 async 属性的，前者会将 JS 脚本推迟到 \u0026lt;/html\u0026gt; 标签关闭前才加载，而后者会进行异步加载 js 脚本，不会阻塞页面其它资源的加载。（IE10 才支持 async）\n按需加载（Lazy load） 网页中占用资源的一般都是图片，对于单页面设计，通常我们只需要用户在刚载入页面看到第一屏的图片即可，其他的图片则可以随着用户向下滚动页面的动作异步加载。这样的话，虽然 HTTP 请求数依然是不变的，但我们的页面响应速度明显就变快了。\n随着各种 js 框架的出现和越来越强大，它们的体积也变得越来越大，后来为了加载速度又将框架的核心代码与功能模块分离，这样我们只需要在刚开始加载核心代码即可，功能模块代码在需要的时候加载即可。\nCDN（内容分发网络） CDN（内容分发网络）将负载分配到不同地域的不同服务器上，可以使不同地区的用户就近获得服务器上相同的资源，可以很好的解决网络拥堵问题，提高用户访问网站的速度。\n启用 HTTP/2 我们现在使用的 HTTP/1.1 协议已经持续了十多年了，它在性能和安全方面已经显现出了不足，新的 HTTP/2 协议不仅性能上更胜一筹，信息安全方面也值得我们关注。\n优化数据库查询 事实上，前端是需要与后台进行大量数据交互的，而后台的数据库查询相当的耗费时间，利用索引可以大幅提高数据库查询速度，这对于前端页面的体验也是很大程度上的改善。\n代码优化 前端开发是一个很头疼的过程，由于不同浏览器的 js 引擎性能不一，虽然谷歌的 V8 引擎很快；CSS 兼容性的不一，在面对前端资源匮乏且复杂的环境下，代码编写的优化也是值得关注的。\nJS 优化 下面先讲一些 JS 编码过程中的优化方法。\n缓存 DOM 节点\nDOM 操作是相当耗费性能的，因为每次查找一个节点就需要遍历整个 DOM 树，所以当我们要对同一个节点进行多项操作时最好能先用一个变量将其缓存起来；事实上，Jquery 的链式操作正是解决了这一问题。\n不要遍历节点集合\n我们通常获取的是一个节点集合，而且是实时的，如果我们对其进行遍历则是相当低效的，所以我们最好将其转换为数组后再遍历。\n不要使用 eval()\neval() 方法是一个相当耗费性能的方法（因为它必须先将字符串进行分析转换成 js 代码，然后才去执行），而且非常不安全，我们应尽可能少的去使用它。\n减少作用链查找\n当我们在函数内部要对外部变量或者对象进行频繁操作时，我们最好先在函数内部使用一个局部变量将其保存起来，最后在退出函数时将局部变量的值再赋值给目标外部变量。这么做的原因是，当我们频繁操作一个变量时，每次都会从作用域链中去查找该变量，而外部变量查找就会更深一些。\nCSS 优化 下面则是一些 CSS 书写规则上的优化方式。\n选择器不宜复杂\nCSS 样式的选择器不应该嵌套过深，或者组合太复杂，页面无时无刻都在高速进行 CSS 计算，选择器太过复杂的话会严重影响 CSS 的计算速度的。\n选择器计算顺序（从右到左）\n浏览器对 CSS 选择器的计算顺序是从右到左的，所以我们不能以从左到右的书写顺序去思考这个问题。\nHTML 优化 对于很复杂的页面，页面 HTML 结构设计也是很重要的，HTML 结构不应该嵌套过深，否则不利于 SEO 排名，我们通常建议选择扁平化的页面结构设计方案。\nVarvy Varvy Tools 是一个国外的在线 Web 优化检测工具，并提供了全面的 SEO 优化、Web 加速、移动端优化的方案。\n**Varvy：**https://varvy.com/\n结语 其实前端的优化方案是很细化的，也是繁多的，为了用户体验，我们应该竭力去优化一切能优化到的地方。\n"},{"section":"Blog","slug":"/blog/computer-technology/web/web-cross-domain/","title":"Web 前端跨域访问","description":"为了用户的安全，浏览器通常都会限制跨域（Cross-domain）访问，也就是默认不允许不同域名下页面之间进行资源的传递和信息交互，但很多时候我们又有跨域请求资源的需求。","date":"August 10, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, 安全, 跨域","tags":"计算机技术, Web前端, 安全, 跨域","content":"为了用户的安全，浏览器通常都会限制跨域（Cross-domain）访问，也就是默认不允许不同域名下页面之间进行资源的传递和信息交互，但很多时候我们又有跨域请求资源的需求。\n同源策略 我们要在地址栏中正确输入“协议”、“域名”、“端口”、“文件路径”才能访问一个页面，其中任意一个不正确就不会达到我们期望的结果。所谓的跨域就是当协议、域名、端口这三者有一个不同时即称为跨域访问，这时候浏览器为了用户安全就会限制 JavaScript 的跨域行为，这也叫做同源策略（由网景公司提出）。\n通常一个公司（组织、团队）会申请一个主域名，然后根据服务类型分出多个二级域名，在某些涉及到敏感信息的页面又会采用 HTTPS 协议加密，或许还有更多的类似需求，这些需求大多都需要跨域共享资源才能实现用户的定制服务。所以，跨域访问不是个能避免的问题，在不破坏浏览器安全性的前提下我们需要去解决它。\n实现跨域访问 我们的跨域访问需求是多样化的，因此解决方法也是多样化的，下面就介绍一些常用的方法。\n响应头标识 随着 Ajax 技术的大量使用，Ajax 跨域请求的需求日益增多，我们可以在服务器端很简单的解决这个问题，即在相应文件中添加响应头标识。\n// 在服务器端的文件中加上以下响应头（允许所有域名跨域访问该资源） header('Access-Control-Allow-Origin: *'); // 只允许指定的域名跨域访问该资源 header('Access-Control-Allow-Origin: http://www.163.com'); 如果要指定多个域名，相互之间用逗号隔开就可以了。\njsonp json 是一种很简单的数据格式，鉴于它的简单性以及 script 标签可跨域的特性，我们采用 jsonp 的方式跨域访问资源。\n客户端代码 \u0026lt;script\u0026gt; // 在全局创建一个回调函数（result 参数为跨域访问到的资源） function callback(result){ ... // 在这里处理跨域访问到的资源（也可以保存在全局变量中） ... // 最后销毁全局的回调函数 window.callback = null; // 移除动态创建的 script document.body.removeChild(document.getElementById('nScript')); } // 自执行，避免污染全局空间 (function(){ // 动态创建 script 插入DOM树，实现跨域访问资源 var nScript = document.createElement('script'); nScript.id = \u0026quot;nScript\u0026quot;; nScript.src = \u0026quot;http://www.163.com/info.php?call=callback\u0026quot;; document.body.appendChild(nScript); })(window); \u0026lt;/script\u0026gt; **注意这个回调函数必须在全局空间内，否则无法被新创建的 \u0026lt;script\u0026gt; 标签调用，该回调函数是在新创建的 script 标签的 src 属性值中以参数方式发送给服务器端的。**该函数执行完毕后，我们也可以自己销毁它，避免污染全局空间；当然，如果我们给动态创建的 script 标签指定一个 id 的话，我们也可以移除该 script 元素。\n服务器端代码 \u0026lt;?php header('Content-type: application/json'); // 获取回调方法名(注意与客户端参数名对应) $call = htmlspecialchars($_GET['call']); // 要返回的 json 格式数据 $data = \u0026quot;['Name','Sex','Age']\u0026quot;; echo $call.\u0026quot;({$data})\u0026quot;; ?\u0026gt; 事实上，所谓的 jsonp 就是通过客户端将回调函数名发送给服务器端，服务器端再把要返回的 json 数据当作参数与方法名拼接成一段 JavaScript 代码返回给客户端，客户端执行得到的 js 代码表达式（调用回调方法）就实现了跨域访问资源。\nwindow.name **在浏览器中只要处于同一个窗口下，无论页面如何跳转，所有在该窗口下的页面都共享（同步）window.name属性（包括获取、修改操作）。**所以，我们可以将需要跨域访问的资源保存在该属性中共享即可。\n客户端代码 \u0026lt;sctipt\u0026gt; // 自执行，避免污染全局空间 (function(){ // 动态创建 iframe 插入DOM树，实现跨域访问资源 var nIframe = document.createElement('iframe'); nIframe.style.cssText = 'display: none'; nIframe.src = 'http://www.163.com/info2.html'; nIframe.onload = function(){ // 修改 src 到同源域名下（空白页） this.src = 'about:blank'; this.onload = function() { // 取得跨域访问资源，移除该 iframe var data = JSON.parse(this.contentWindow.name); document.body.removeChild(this); // 接下来就可以处理得到的资源了 ... } } document.body.appendChild(nIframe); })(window); \u0026lt;/script\u0026gt; **我们只是使用了一个 \u0026lt;iframe\u0026gt; 作为代理获取到跨域资源，但是 \u0026lt;iframe\u0026gt; 之间也是不允许跨域访问的，所以我们再次把它的 src 修改为同源页面或者空白页就可以获取到 window.name 的属性了，也就是我们需要的资源。**同样地，我们也可以在最后移除创建的 iframe 元素。\n资源页面代码 \u0026lt;script\u0026gt; window.name = '[\u0026quot;Name\u0026quot;,\u0026quot;Sex\u0026quot;,\u0026quot;Age\u0026quot;]'; \u0026lt;/script\u0026gt; 由于资源页面仅仅是为了传递数据，我们通常在动态创建 iframe 时设置 CSS 样式为 display：none，避免它影响客户端页面的布局。\ndocument.domain **即便是同一个页面的 \u0026lt;iframe\u0026gt; 也是有跨域限制的，若多个 \u0026lt;iframe\u0026gt; 载入的页面恰好是跨子域的话（主域名相同），我们可以将它们各自的 document.domain 设置为它们共有的主域名即可实现跨域访问。**下面举个例子，简单的说明一下：\n// iframe1 ： www.163.com \u0026lt;script\u0026gt; document.domain = \u0026quot;163.com\u0026quot;; \u0026lt;/script\u0026gt; // iframe2 ： study.163.com \u0026lt;script\u0026gt; document.domain = \u0026quot;163.com\u0026quot;; \u0026lt;/script\u0026gt; 这样设置好之后，我们则可以在全局范围内完成两个 iframe 跨子域的数据访问。\n同理，我们依然可以动态创建一个 iframe 去完成跨子域的数据访问，具体实现我们可以参考上面共享 window.name 时动态创建 iframe 的方法。需要注意的是，资源页面的 document.domain 属性要提前设置好，否则在客户端页面是无法跨域去修改资源页面的属性的。\nHTML5 postMessage API 在 HTML5 中，实现了一个安全便捷的跨域消息传递方案，也就是 postMessage() 方法，它有两个参数：第一个参数为发送的数据，绑定到 event 事件对象的 data 属性上；第二个参数为数据接受者限制域。在接受者页面还需要一个 message 事件供我们监听是否有数据发送过来配合使用。\n客户端代码 \u0026lt;script\u0026gt; // 注册 message 事件准备接受数据 window.onmessage = function(e){ // 可以先判断发送源再处理，保证安全 // if e.origin == \u0026quot;http://study.163.com\u0026quot; // 获取跨域访问的数据 var data = JSON.parse(e.data); // 处理数据 ... // 销毁该事件 this.onmessage = null; // 移除该 iframe document.body.removeChild(nIframe); } var nIframe = document.createElement('iframe'); nIframe.style.cssText = \u0026quot;display: none\u0026quot;; nIframe.src = \u0026quot;http://domain1.com:8081/info2.html\u0026quot;; document.body.appendChild(nIframe); \u0026lt;/script\u0026gt; 在进行数据接收和处理之前，我们可以使用 event.origin 来判断发送源是否已知，保证页面安全。\n资源页面代码 \u0026lt;script\u0026gt; window.top.postMessage('[\u0026quot;Name\u0026quot;,\u0026quot;Sex\u0026quot;,\u0026quot;Age\u0026quot;]', 'http://www.163.com'); \u0026lt;/script\u0026gt; 第二个参数规定了数据接受者的域限制，这个也是为了保证敏感数据不会发送给未知页面，确保数据安全。\n结语 事实上，跨域访问是个很常用的需求，而许多解决方法也都异曲同工，也不只有这些方法才能实现跨域访问，采用什么方法都是按实际需求来选择的。而我们使用跨域访问技术，是违背了浏览器默认行为的，所以更应该确保安全性。\n"},{"section":"Blog","slug":"/blog/computer-technology/web/css/css-bfc/","title":"块级格式化上下文（BFC）","description":"在进行页面布局时，通常有流式布局、定位布局、浮动布局这三种形式。而在布局过程中，各元素之间的影响却是一个很关键的问题。","date":"July 22, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, CSS, BFC","tags":"","content":"在进行页面布局时，通常有流式布局、定位布局、浮动布局这三种形式。而在布局过程中，各元素之间的影响却是一个很关键的问题。\nBFC BFC（Block Formatting Context，块级格式化上下文）是 CSS 2.1 中的一个规范，在 CSS 3 中也称为 Flow Root。首先，BFC 是块级元素身上的一个特性，通常它是隐藏不生效的，但某些情况下它会显现出来：\nfloat 不为 none position 不为 static、relative overflow 不为 visible display 不为 table-cell、table-caption、inline-block、flex、inline-flex 只要满足上述任一条件，该块级元素身上的 BFC 特性即会显现出来。\nBFC 特性 BFC 特性所展现出来的效果可以通俗的总结为，**BFC 特性导致块级元素成为一个容器盒子，将会把容器内的元素与容器外的元素相互隔离（也就是说容器内外的元素之间不再发生相互作用）。**于是乎，我们就可以说该容器内的所有元素都处在了同一个块级格式化上下文中，只有它们之间才会发生相互作用。\n清除 margin 重叠 最典型的相互作用就是两个相邻的块级元素垂直方向上的 margin 值会发生重叠并取最大值。当我们为其中一个元素包裹一个 div 元素并使该元素的 BFC 显现（例如 overflow:hidden）时，我们会发现原先两个元素在垂直方向上的 margin 值已不再重叠，这也就是说明它们之间已不存在相互作用。\n清除 float 覆盖 当一个元素 float 设置不为 none 时，该元素将会浮动起来脱离文档流，导致它后面的非浮动元素前移，从而自己覆盖在前移的元素上。这时候，当我们使它后面的非浮动元素 BFC 特性显现（例如 overflow:auto）时，我们就会发现这些元素不会前移了。\nfloat 包含 同样地，当父元素的高度没有设置，子元素浮动起来后，父元素的 height 依然为 0。这时候，我们使父元素的 BFC 特性显现（例如 float:left）时，我们会发现父元素的高度被浮动的子元素撑起来了，也就是父元素将浮动子元素包含了起来。\n清除文字环绕 当一个浮动元素后面跟了个 \u0026lt;p\u0026gt; 元素且内部有大量文字，这些文字会产生环绕效果，也就是环绕在浮动元素周围。我们可以使该 p 元素的 BFC 特性显现（例如 overflow:hidden），然后我们就可以看到文字全部显示在了侧边，而不会再环绕在该浮动元素上下方，也就是类似评论功能中头像与评论文字两侧布局的效果。\n结语 事实上，BFC 特性还有许多其它的妙用，我们在开发过程中可以多尝试，挖掘它新的技巧。\n"},{"section":"Blog","slug":"/blog/computer-technology/protocol/protocol-http/","title":"HTTP 协议","description":"随着 Internet 的发展，使用 Web 浏览器获取网络数据信息已经成为一种习惯标准，而 HTTP 协议也因此成为了网络体系中最重要的应用层协议。","date":"June 24, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 协议, HTTP","tags":"","content":"随着 Internet 的发展，使用 Web 浏览器获取网络数据信息已经成为一种习惯标准，而 HTTP 协议也因此成为了网络体系中最重要的应用层协议。\nHTTP HTTP（HyperText Transfer Protocol，超文本传输协议）是一种通用的、无状态（Stateless）的、与传输数据无关的，应用于分布式、协同式、超媒体信息系统的应用层协议。除了应用于 WWW（World Wide Web，万维网）服务器与 Web 浏览器之间的超文本传输外，它也可以应用于像名称服务器和分布对象管理系统这样的系统。\nHTTP 协议运行机制 HTTP 协议是基于 TCP 连接的，以请求/响应（Request/Response）模式来实现客户端（Web 浏览器）和服务器之间通信的。具体过程如下：\n客户端和服务器建立 TCP 连接\nHTTP 服务器运行在某个端口（默认为 80）上进行侦听，等待连接请求。客户端打开一个套接字（Socket）向服务器发出连接请求。\n客户端向服务器发送 HTTP 请求报文\n客户端与服务器建立 TCP 连接后，发送一个请求报文给服务器。请求报文包括请求方法、URI（统一资源标识符）和协议版本号，以及一个类 MIME 消息。这个类 MIME 消息又包括请求修饰符、客户端信息和可能的报文主体内容。\n服务器向客户端发送 HTTP 响应报文\n服务器接收到客户端的请求报文后，向其返回响应报文。响应报文提供一个状态行和一个类 MIME 消息。状态行包含报文的协议版本号和成功、出错的状态码，类 MIME 消息包含服务器信息、实体元信息，以及可能的实体内容。\n关闭 TCP 连接\n当服务器响应了客户端的请求后便会关闭 TCP 连接，直到接收到下一个请求后重新建立连接。我们现在使用的 1.1 版本的 HTTP 协议，可以在服务器响应过后，维持该连接一段时间，此时间段内客户端可以继续发送请求而不必重新建立连接。\nHTTP 协议的主要特点 概述一下 HTTP 协议的主要特点：\n简单协议\n与其他协议相比，HTTP 协议更简单，它的通信速度很快，可以有效的处理大量请求。客户端与服务器建立连接后，HTTP 协议要求客户端必须传送的信息只是请求方法和路径。该协议虽然定义了多种请求方法，但是实际上常用的只有其中的三种：GET、HEAD 和 POST。\n无连接协议\n客户端与服务器间通信是基于 TCP 连接实现的，而且每次只处理一个请求，客户端收到服务器响应后会立即断开连接。1.1 版本的 HTTP 协议也只是短暂维持连接。\n无状态协议\n这种无状态性使得客户端与服务器连接通信运行速度非常快，但是无状态意味着对事务处理没有记忆，即每一次的请求都是独立的。\n基于元数据的协议\nHTTP 协议对所有事务处理都加了首部，即在主要数据前面加一部分信息，称之为元数据，即关于信息的数据。用户可以利用元数据进行有条件的请求，或者报告一次事务处理是否成功等。\n统一资源标识符 URI（统一资源标识符）是统一资源定位符（URL）和统一资源名称（URN）的组合。就 HTTP 而言，统一资源标识符只是通过名称、地址或其他任何特征识别资源的格式化字符串。使用 URI 是为了唯一的标识网络上的某个目标资源；URL 就是我们通常所说的网页地址，它不仅提供了网络上目标资源的标识，而且也提供了我们访问该资源的方式。\n请求方法 HTTP 协议定义了八种请求方法：\nGET：获取由请求 URI 指定的信息。 HEAD：与 GET 方法一致，用来测试超文本链接的有效性、可访问性以及最近的改变。 POST：从客户端向服务器提交数据，例如表单信息。 PUT：请求服务器将包含的实体存储在请求 URI 所指示的资源中。 DELETE：请求源服务器删除请求 URI 制定的资源。 TRACE：用来进行对客户端请求的测试和调试。 CONNECT：保留给 SSL 隧道使用。 OPTIONS：表示请求由 URI 指定的请求/响应链上可得到的通信选项信息。 实际上，常用的只有其中三种方法：GET、HEAD 和 POST。\n（响应）状态码 状态码（HTTP Status Code）是服务器针对客户端请求做出响应的由 3 位十进制数组成的结果码，其中第一位代表了响应类别。状态码有以下几种类别：\n1xx：表示信息，请求收到继续处理。 2xx：表示成功，服务器对客户端发出请求的接受、理解和处理已成功完成。 3xx：表示重定向，为完成请求所要求采取的操作，客户端需要重新提出请求。 4xx：表示客户端错误，请求中有语法错误或不能被执行。 5xx：表示服务器错误，服务器错误的执行了一个正确的请求。 大多数时候，我们客户端发出的请求都能被服务器成功处理，并返回 200（ok）；当我们访问一个页面在地址栏输入网址时在末尾不加斜杠 /，服务器会有一次重定向行为并返回 301；当我们访问一个不存在的页面时，服务器则会返回 404。\nCookie、Session 由于 HTTP 协议是一个无状态的协议，每一次请求都是相互独立的，这就会导致一些资源会重复下载，因而造成性能严重下降以及其他问题。例如，当我们访问一个论坛时，登录信息若不能保存下来，我们的每次操作都要进行重复登录。而 Cookie 和 Session 这两种机制则是为了解决这个问题而引入的，他们都是用来保存客户端状态信息的。\n通常，当客户端第一次发起请求时，服务器接收到请求后会在内存中创建一个 Session 对象，并利用响应头标识 Set-Cookie 来将 Sessionid（Session 对象的唯一标识）返回给客户端，并存储在 Cookie 中（域名与 sessionid 对应，确保不同域名之间 Session 相互独立）。随后，客户端再次发送请求时，浏览器默认会将 Cookie 中的信息附加到请求信息中，服务器就可以利用客户端发送来的 Cookie 信息判断是否已被服务器授权，以此来实现状态保持。\nCookie 与 Session 的区别：\nCookie 将状态保存在客户端；Session 将状态保存在服务器上。 Cookie 在客户端本地以文本形式存在，伴随每次请求发送给服务器；Session 则由服务器指定一个 SessionID 对每次请求进行验证。 Session 相对于 Cookie 来说较为安全一点。 HTTPS HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer），是以安全为目标的 HTTP 通道。它的实现是在 HTTP 与 TCP 之间加入 SSL（TSL）协议来进行加密认证，从而保证数据传输的安全性。\nHTTP 与 HTTPS 的区别：\nHTTPS 协议需要申请 SSL 证书，且需要一定的费用。 HTTP 是明文传输信息，而 HTTPS 则是加密传输信息。 HTTP 使用的端口号是 80，而 HTTPS 使用的端口号是 443。 HTTP 连接简单、快速，而 HTTPS 需要进行加密认证，会消耗一定时间。 结语 对于 HTTP 协议的报文格式、请求头、响应头，我们均可以使用 HttpWatch 插件（IE 浏览器），或者 Wireshark 软件来进行监测，会有一个直观地、全面地了解。现在的浏览器开发者工具中也带有检测 HTTP 请求的功能。\n"},{"section":"Blog","slug":"/blog/computer-technology/protocol/protocol-ip/","title":"IP 协议","description":"作为 TCP/IP 协议栈中最核心的协议，IP 协议为网络数据传输和网络互联提供最基本的服务。IP 协议有 IPv4 和 IPv6 两个版本，我们只讨论 TPv4 版本的 IP 协议。","date":"June 23, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 协议, IP","tags":"","content":" 作为 TCP/IP 协议栈中最核心的协议，IP 协议为网络数据传输和网络互联提供最基本的服务。IP 协议有 IPv4 和 IPv6 两个版本，我们只讨论 TPv4 版本的 IP 协议。\nIP 协议 网络层是网络体系中通信子网的最高层，对于 TCP/IP 来说，网络层是其核心所在。该层包含 5 个协议：IP、ARP、RARP、ICMP、IGMP，其中最主要的 IP 协议负责生成发往目的地的数据报以实现逻辑寻址，完成数据从网络上一个节点向另一个节点的传输。\nIP 协议定义 IP（Internet Pcotocol，网际协议）是 TCP/IP 协议栈中网络层的协议，也是最为核心的协议，提供无连接的 IP 数据报投递服务。IP 协议是为了在分组交换（Packer-switching，又称包交换）计算机通信网络的互联系统中使用而设计。IP 层（网络层）只负责数据的路由和传输，在源节点与目的节点之间传送数据报，但并不处理数据内容。数据报中有目的地址等必要内容，使每个数据报经过不同的路径也能准确到达目的地，在目的地重新组合还原成原来发送的数据。IP 协议使用以下 4 个主要的机制来提供服务：\n服务类型（Type of Service） 用来指示要求的服务质量。 生存时间（Time of Live） 数据报生存时间的上限。 选项（Operation） 提供某些情况下需要或有用的控制功能。 首部校验和（Header Checksum） 提供对 IP 首部内容进行出错检测的功能。 IP 层通过 IP 地址实现了物理地址的统一，通过 IP 数据报实现了数据帧的统一。IP 层通过对以上两个方面的统一达到了向上屏蔽底层差异的目的。\nIP 协议的基本功能 IP 协议的主要目的是通过一个互联的网络传输数据报，涉及两个最基本的功能。\n寻址（Addressing）\nIP 协议根据数据报首部中包括的目的地址将数据报传送到目的节点，这就涉及传送路径的选择，即路由功能。IP 协议使用 IP 地址来实现路由。\n分片（Fragmentation）\nIP 协议还提供对数据大小的分片和重组，以适应不同网络对数据包大小的限制。如果网络只能传送小数据包，IP 协议将对数据报进行分段并重新组成小块再进行传送。\nIP 协议的特性 IP 协议是一个无连接的、不可靠的、点对点的协议，只能尽力传送数据，不能保证数据的到达。具体地讲，主要有以下特性：\nIP 协议提供无连接的数据报服务，各个数据报独立传输，可能沿着不同的路径到达目的地，也可能不会按序到达目的地。 IP 协议不含错误检测或错误恢复的编码，属于不可靠的协议。位于上一层（传输层）的 TCP 协议则提供了错误检测和恢复机制。 作为一种点对点协议，虽然 IP 数据报携带源 IP 地址和目的 IP 地址，但进行数据传输时的对等实体一定是相邻设备（同一网络）中的对等实体。 IP 协议的效率非常高，实现起来非常简单。 数据报分片 数据报分片（Fragmentation）是 IP 协议的基本功能中的一个功能，实现数据报分片的意义和作用我们接下来将会讨论。IP 数据报最大长度可达 65535（2^16-1）字节，但很少有底层的物理网络能够封装如此大的数据包，因此将 IP 数据报分片传输，目的主机将分片重组还原为一个数据报。\n####### 最大传输单元（MTU）\n底层物理网络能够封装的最大数据长度称为该网络的最大传输单元（Maximum Transmission Unit，MTU）。当数据报封装成帧时，数据报的长度必须小于 MTU。对于不同的物理网络协议，MTU 的值也是不同的。物理网络的 MTU 是由硬件决定的，通常网络的速度越高，MTU 也就越大。\nIP 数据报在从源节点到目的节点的传输过程中往往要经过多个不同的网络，而各个物理网络的 MTU 可能不同。将一个数据报封装在具有较大 MTU 的物理网络帧中发送时，可能在穿过较小 MTU 的物理网络时无法正常传输。此时解决这个问题有两种方案：一是将数据报按照从源节点到目的节点的最小 MTU 进行封装，但这种方案不能充分利用网络的传输能力，传输效率较低；二是将数据报先以源节点所在网络的 MTU 进行封装，在传输过程中再根据需要对数据报进行动态分片。\nTCP/IP 协议采用的是第二种方案，即数据报分片。\n####### 分片与重组\n当 IP 层要传送的数据大于物理网络的最大传输单元时，必须将 IP 数据包分片传输。分片是将一个数据报划分成若干个更小的单元，以适应底层物理网络的 MTU。分片必须满足两个条件：一是分片尽可能大，但必须能够为帧所封装；二是分片中数据的大小必须为 8 字节的整数倍，否则 IP 无法表达其偏移量。\n同一数据报各个分片到达目的地，必须被重组为一个完整的数据报。目的主机在进行分片重组时，采用一组重组定时器。开始重组时即启动定时器，如果重组定时器超时仍然未能完成重组（由于某些分片没有及时到达目的主机），源主机的 IP 层将丢弃该数据报，并产生一个超时错误，报告给源主机。\n分片可以在源主机或传输路径上的任何一台路由器上进行，而分片的重组只能在目的主机上进行。\nIP 寻址与地址解析 IP 地址是 TCP/IP 中的一个非常重要的概念，在网络层实现了底层网络地址的统一，使 TCP/IP 网络层地址具有全局唯一性和一致性。**IP 地址是 TCP/IP 网络的寻址机制（逻辑寻址），是 TCP/IP 网络进行寻址和选择路由的依据。**IP 数据包最终需要物理网络来处理，当 IP 数据包交付给物理网 络之后，物理网络就需要它自己的寻址机制来处理，即 MAC 寻址（物理地址）。这就涉及两种地址的转换，具体由地址解析协议（ARP）和反向地址解析协议（RARP）来实现。\nIP 地址 在 TCP/IP 网络中每个主机都有唯一的地址，它是通过 IP 协议来实现的，用来标识每一个网络节点以确保它们之间的相互通信。\n####### IP 地址格式\nInternet 采用一种全局通用的地址格式，为每一个网络和每一台主机都分配一个 IP 地址，以屏蔽物理网络地址的差异。IPv4 规定，IP 地址长度为 32 位（IPv6 规定地址长度为 128 位）。因此，IPv4 的地址空间为 2^32。\nIP 地址是 32 位二进制数字，为了方便我们一般将 IP 地址分为 4 个 8 位字段，以 4 个十进制数表示，之间用点隔开。例如，202.112.10.105，这种记录方法称为“点-数”法。\nIP 地址标识一个网络和连入此网络的一台主机。IP 地址采用一种由网络 ID（Net-id）和主机 ID（Host-id）组成的两级结构，网络 ID 表示主机所属的网络，主机 ID 代表主机本身。例如，192.168.1.102，这个 IP 地址中前 3 个十进制数表示网络 ID，最后一个十进制数表示主机 ID。\n####### IP 地址分配\nIP 地址分配的基本原则是，要为同一网络（子网或网段）内的所有主机分配相同的网络 ID，同一网络中的不同主机必须分配不同的主机 ID，以区分主机。\n####### IP 地址分类编址\n考虑到不同规模网络的需要，IP 将 32 位地址空间划分为不同的地址类别，并定义了 5 类地址，即 A 类至 E 类。其中 A、B、C 是 3 个基本的类别，分别代表不同规模的网络，由 InterNIC 在全球范围内统一分配。\nA 类地址\n高 8 位代表网络 ID，低 24 位代表主机 ID。\nB 类地址\n高 16 位代表网络 ID，低 16 位代表主机 ID。\nC 类地址\n高 24 位代表网络 ID，低 8 位代表主机 ID。\nIP 子网与超网 子网（Subnet）是对一个网络的进一步划分。子网划分不仅解决了 IP 地址的短缺问题，而且可以让用户灵活配置自己的 IP 网络。超网（Supernet）与子网正好相反，将多个网络合并成一个网络。\n####### 子网掩码（Subnet Mask）\n子网掩码（Subnet Mask）用来将 IP 地址划分成网络地址和主机地址两部分。对于同一个 IP 地址，如果其子网掩码不同，则代表不同的网络或主机。\n与 IP 地址相同，子网掩码也是 32 位二进制数，其中高位部分对应 IP 地址中的网络位，用“1”表示；剩余低位部分对应 IP 地址中的主机位，用 “0” 表示。为了方便，同样采用“点-数”法记录。\nA 类地址子网掩码：255.0.0.0 B 类地址子网掩码：255.255.0.0 C 类地址子网掩码：255.255.255.0 ####### 划分子网\n对于一个 C 类地址网络来说，可支持 254 台主机接入网络，如果需要两个网络，并且两个网络接入主机数加起来不超过 254 台（各自的主机数较少）时，若使用两个 C 类地址网络，对于 IP 地址来说是一种浪费；此时可以利用子网掩码来将同一个 C 类地址网络进一步划分成两个不同子网，以此来提高 IP 地址的利用率。\n将 IP 地址的主机 ID 部分划分成：子网 ID +主机 ID。也就是说将原来的 IP 地址两级结构扩充为三级结构：网络 ID +子网 ID +主机 ID。通过增加子网掩码中的 “1”（增加网络位），即可实现子网划分。例如，将 C 类地址的子网掩码 255.255.255.0，改成 255.255.255.128 即可。\n####### 组合超网\n对于一个 C 类地址网络来说，它仅能支持 254 台主机接入网络，如果需要一个网络，并且接入主机数多于 254（远小于 65534）时，若使用一个 B 类地址网络（可支持接入主机 65534 台），对于 IP 地址来说是一种浪费；此时可以利用子网掩码来将多个 C 类地址网络合并成一个超网，以此来提高 IP 地址的利用率。\n将 IP 地址的网络 ID 一部分划分为新的主机 ID。通过减少子网掩码中的 “1”（减少网络位），即可实现超网组合。例如将 C 类地址的子网掩码 255.255.255.0，改成 255.255.248.0 即可。\n地址解析 IP 地址属于网络层的寻址，数据包通过 IP 地址及路由表在物理网络中传递，还必须遵守网络的物理层协议，底层的物理网络需要获知 IP 地址，这就需要将 IP 地址映射为物理网络地址。同时，物理网络地址也需要映射为 IP 地址。网络层提供的 ARP（地址解析协议）和 RARP（反向地址解析协议）即可实现 MAC 地址（物理地址）和 IP 地址（逻辑地址）的相互转换。\n####### ARP（地址解析协议）\nIP 数据报必须封装成帧才能通过物理网络传输，这就要求发送方必须知道接收方的物理地址。ARP 的功能分为两部分：一部分在发送数据包时请求获得目的节点的物理地址；另一部分向请求物理地址的节点发送解析结果。\n当网络中的一个节点（主机或路由器）需要获知另一个节点（主机或路由器）的物理地址时它就发送 ARP 查询报文。这个报文包括发送方的物理地址和 IP 地址，以及接收方的 IP 地址。由于发送方并不知道接收方的物理地址，查询报文就只能在网络上广播。\n在网络上的每一个节点都会接受这个 ARP 查询报文，将该报文中的接收方 IP 地址与自己的 IP 地址进行比较，相同的节点向查询者回传 ARP 应答报文。该应答报文中包含接受方的 IP 地址和物理地址，以及发送方的物理地址。由于知道查询者物理地址，该报文用单播方式直接发送给查询者。\n####### RARP（反向地址解析协议）\nRARP 可以实现从物理地址到 IP 地址的转换，主要被无盘计算机用来获取其 IP 地址。\nARP 假定每个主机都知道自己的物理地址和 IP 地址的映射，地址解析的目的是获取另一个网络节点的物理地址。而 RARP 则主要是通过本机的物理地址获取本机的 IP 地址，需要借助于 RARP 服务器帮助完成解析。\n结语 虽然网络层中有 5 个协议，但 IP 协议是最核心的协议，其他 4 个协议都是为 IP 协议服务的，增加地址解析、差错控制等功能。\n"},{"section":"Blog","slug":"/blog/computer-technology/protocol/protocol-tcp-udp/","title":"TCP 与 UDP 协议","description":"传输层是网络分层模型中举足轻重的层，它是底层通信子网与高层资源子网的接口与桥梁，提供了面向连接的传输控制协议（Transmission Control Protocol，TCP）和无连接的用户数据报协议（User Datagram Protocol，UDP），负责提供端到端的数据传输服务。","date":"June 20, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 协议, TCP, UDP","tags":"","content":"传输层是网络分层模型中举足轻重的层，它是底层通信子网与高层资源子网的接口与桥梁，提供了面向连接的传输控制协议（Transmission Control Protocol，TCP）和无连接的用户数据报协议（User Datagram Protocol，UDP），负责提供端到端的数据传输服务。\n传输层协议 传输层在两个应用实体之间实现可靠的、透明的、有效的端到端数据传输服务，其主要的功能为以下几个方面：\n创建进程间通信，进程即正在运行的应用程序。 提供控制机制，如流量控制，差错控制等。 提供连接机制。 TCP 协议 TCP（Transmission Control Protocol，传输控制协议）是传输层最重要和最常用的协议。它提供了面向连接的、可靠的数据传输服务，保证了端到端数据传输的可靠性。以下为 TCP 协议的特点：\n面向连接\n两个需要通过 TCP 进行数据传输的进程之间首先必须建立一个逻辑连接（虚电路），即 TCP 连接；在数据传输完成后需要关闭（释放）连接。一般将发出请求连接的应用进程称为客户进程，而将响应连接的应用进程称为服务器进程，即 TCP 连接的建立采用的是一种客户/服务器模型。\n全双工\n提供全双工数据传输服务，只要建立了 TCP 连接，就能在两个进程间进行双向的数据传输服务，但是这种传输只是端到端的传输，不支持广播和多播。\n可靠\n提供流量控制、拥塞控制、差错控制，从而保证数据传输的可靠性。\n基于字节流\n提供面向字节流的服务，两个建立了 TCP 连接的应用进程间之间交换的是字节流。在传输层上数据被当作没有信息的字节序列来对待。\nTCP 比较安全、稳定，但由于每次传输数据时都要先建立连接，并在传送完成后关闭连接，所以效率比较低，而且占用的资源也比较多。TCP 协议的主要作用是在计算机之间可靠的传输数据，将具有一定可靠性的流式通信服务提供给应用程序。\nUDP 协议 UDP（User Datagram Protocol，用户数据报协议）是不可靠的无连接的基于数据报的协议，支持无连接 IP 数据报的通信方式。相对于 TCP 协议来说，UDP 是一种非常简单的协议，在网络层的基础上实现了进程之间端到端的通信。以下为 UDP 协议的特点：\n无连接\n传输数据之前双方不需要建立连接，因此不存在连接建立的时延。\n无需维护\n传输数据不需要维护连接状态，包括收发状态等，这样一台服务器可同时向多个客户端传输相同的数据，如实现多播。\n报文首部短\nUDP 数据报首部只有 8 字节，相对于 TCP 的 20 字节首部的开销要小很多。\n吞吐量不受控制\n吞吐量不受流量控制算法的调节，只受应用软件生成数据报的速率、传输带宽、信源和信宿主机性能的限制。\nUDP 的不可靠性并不影响 UDP 的可用性。在没有严格可靠性要求的情况下，UDP 避免了 TCP 面向连接的消耗，反而能提高传输速率和降低资源占用，非常适合于简单查询和响应类型的通信，如广播、路由、多媒体等广播形式的通信任务。\n进程间通信 传输层以下各层（通信子网）只提供相邻节点之间的点到点传输。例如，IP 协议负责在网络节点之间的通信，即主机之间的通信。作为网络层协议，IP 只能将报文交付给目的主机，但是这是一种不完整的交付，因为这个报文还必须送交到相应的进程。传输层提供端到端的数据传输，即源进程到目的进程的端到端通信。\n由于在一台计算机中同时存在多个进程，进程之间要进行通信，首先要解决进程的标识问题。为了保证数据能够正确地到达指定的目的进程，必须显示地给出全局唯一的目的进程标识符。主机可以用 IP 地址进行标识，IP 地址是全局唯一的；然后我们再给主机上的进程赋予一个本地唯一的标识符端口号（Port Number）。为了区别 TCP 和 UDP 的进程，还要指明协议。因此，我们要全局唯一地标识一个进程，必须采用一个三元组来表示：\u0026lt;协议，主机 IP 地址，端口号\u0026gt;。\n网络通信是两个进程之间的通信，两个进程相关联，因为采用的是同一种协议通信，可以用一个五元组来描述两个进程的关联：\n\u0026lt;源 IP 地址，源端口号，协议，目的 IP 地址，目的端口号\u0026gt;。\nTCP 连接机制 TCP 提供的是面向连接的数据传输服务，所以在进行数据传输前通信双方要建立 TCP 连接，数据传输完成后又要关闭 TCP 连接。我们可以将这个过程大致描述为：\nTCP 连接建立（三次握手） 数据传输（保持连接） TCP 连接关闭（四次挥手） 连接建立（三次握手） 通信双方在使用 TCP 传输数据之前，要建立一个稳定、可靠的 TCP 连接，这个连接建立过程形象地称为“三次握手”。下面来具体分析这个过程：\n第一次握手\n客户端（源主机）向服务器（目的主机）发送 TCP 连接建立请求（又称 SYN 段），其中标志 SYN=1，ACK=0；序列号为客户端初始序列号（简称 ISN）；目的端口号为所请求的服务（进程）对应的端口。同时客户端启动计时器，等待接受服务器的应答。这个 SYN 段不携带任何数据，但是它消耗一个序列号。这一步客户端执行主动打开（Action Open）。\n第二次握手\n服务器收到客户端的 TCP 连接建立请求后，将回应一个 TCP 连接建立应答（又称 SYN/ACK 段），其中标志 SYN=1，ACK=1；序列号为服务器初始序列号；确认号为客户端初始序列号加 1；目的端口号为客户端的源端口号。同时服务器启动计时器，等待接受客户端的应答。这个 SYN/ACK 段不携带数据，但消耗一个序列号。这一步服务器执行被动打开（Passive Open）。\n第三次握手\n客户端计时器超时前若收到服务器的应答报文，客户端会向服务器发送一个 TCP 连接建立确认报文（又称 ACK 段），其中标识 SYN=0，ACK=1；序列号为客户端初始序列号加 1；确认号为服务器初始序列号加 1。这个 ACK 段若不携带数据，则不消耗序列号。\n至此，服务器计时器超时前若收到客户端确认报文，则 TCP 连接正式建立。\n“三次握手”的过程大致可以描述为：客户端发送（主动）连接建立请求——\u0026gt;服务器接收请求，发送（被动）连接建立请求和应答信息——\u0026gt;客户端发送连接建立确认信息。\n数据传输（保持连接） 在完成“三次握手”的过程后，通信双方的 TCP 连接正式建立，此时就可以进行数据双向传输了。\n客户端和服务器都可以在两个方向上进行数据传输和确认。客户端和服务器分别记录对方的序列号，序列号的作用是为了同步数据。客户端向服务器发送数据报文，服务器收到后会回复一个带有 ACK 标志的确认报文段。客户端收到该确认报文段，就知道数据已经成功发送，否则，报文将被重新发送。接着它继续向服务器发送报文。\n建立 TCP 连接之后，可以保持连接以免每次发送数据都要重复执行握手过程。这样，即使没有数据在 TCP 链路上传送，仍旧能够维持连接。通常应用层可以实现连接保持，如 FTP。如果应用程序不能保持连接，则可以由服务器发起 TCP 保持连接。\n连接关闭（四次挥手） 双方在完成数据传输后，可以关闭 TCP 连接，释放资源同时也能准备为其他进程提供服务，而这个关闭（释放）连接的过程也被形象地称为“四次挥手”。**至于为何建立连接是“三次握手”，而关闭连接却是“四次挥手”，是因为 TCP 连接是全双工的，支持通信双方进行双向数据传输，所以每个方向上都必须单独关闭。**下面来具体分析这个过程：\n第一次挥手\n客户端向服务器发送 TCP 连接关闭请求（又称 FIN 段），其中标志 FIN=1。主动关闭客户端到服务器的数据传送。\n第二次挥手\n服务器收到客户端的 TCP 连接关闭请求后，将回应一个 TCP 连接关闭应答（又称 ACK 段），其中标志 ACK=1。并通知己方（服务器）应用程序关闭。\n第三次挥手\n服务器收到己方应用程序关闭信息后，向客户端发送 TCP 连接关闭请求（又称 FIN 段），其中标志 FIN=1。\n第四次挥手\n客户端收到服务器的 TCP 连接关闭请求后，将回应一个 TCP 连接关闭应答（又称 ACK 段），其中标志 ACK=1。\n至此，服务器收到客户端应答报文后会单向关闭 TCP 连接，稍后客户端也会单向关闭 TCP 连接，这样 TCP 连接就同时双向关闭了。\n“四次挥手”的过程大致可以描述为：客户端发送（主动）连接关闭请求——\u0026gt;服务器接受请求，发送应答信息，并通知应用程序关闭——\u0026gt;服务器应用程序已关闭，发送（被动）连接关闭请求——\u0026gt;客户端接受请求，并发送应答信息。\n要注意的是，四次挥手过程中主动发起连接关闭方既可以是客户端（Client）也可以是服务器（Server）。\n结语 对于 TCP 和 UDP 协议的报文格式，以及 TCP 连接整个过程我们可以使用 Wireshark 软件来监测，并进行具体的分析，这样我们可以直观的了解它们，也能帮助我们更好的理解。\n"},{"section":"Blog","slug":"/blog/computer-technology/protocol/protocol-lan-wan/","title":"局域网（LAN）与广域网（WAN）","description":"TCP/IP 的网络接口层包括物理层和数据链路层，既是局域网（LAN）技术起作用的分层，又是广域网（WAN）技术和连接管理协议发挥作用的层次。","date":"June 18, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 协议, LAN, WAN","tags":"","content":"TCP/IP 的网络接口层包括物理层和数据链路层，既是局域网（LAN）技术起作用的分层，又是广域网（WAN）技术和连接管理协议发挥作用的层次。\n局域网（LAN） 局域网（Local Area Network，LAN）是指一个局部的地理范围内（如一个学校、公司、单位），将各种计算机、外部设备和数据库等互相连接起来组成的计算机通信网。局域网通常是封闭的，但它可以通过数据通信网或专用数据电路，与远方的局域网、数据库或处理中心相连接，构成一个大范围的信息处理系统。局域网可以实现硬件资源（如服务器、打印机、扫描仪等）共享和软件资源（应用软件、文件管理等）共享，还可以实现办公自动化（如工作组内的日程安排、电子邮件和传真通信服务）等。\n局域网协议标准 IEEE 802 是为了规范随着局域网技术进步而产生的种类繁多的局域网产品而制定的标准，有时也称为局域网参考模型。它包括 CSDM/CD、令牌总线和令牌环网等底层（物理层和数据链路层）网络协议。\nIEEE 802 标准中规定局域网体系结构由物理层和数据链路层组成，且数据链路层又划分为：介质访问控制（Media Access Control，MAC）子层和逻辑链路控制（Logical Link Control，LLC）子层。\n####### 物理层\n物理层主要规定了局域网的机械、电气、功能和规程等方面的特性。例如，局域网采用的物理介质、传输距离、传输速率、传输信号数据编码与解码、物理接口特性、拓扑结构，以及的节点之间采用何种连接方式等硬件方面的问题。\n####### 介质访问控制（MAC）子层\n**局域网组网的一个显著特点是网上所有计算机使用一条共享信道进行广播式通信，这是与点对点链路组成的广域网通信的重要区别。**因此，局域网协议需要解决的一个重要问题就是多个节点如何接入一条共享信道，即介质访问控制（MAC 访问）问题。\nMAC 子层构成数据链路层的下半部分，它直接与物理层相邻，负责介质访问控制机制的实现，处理与特定类型的局域网相关的问题。例如，处理信道管理算法，如令牌传递、带有冲突检测的载波监听多路访问（CSMA/CD）、优先权（802.5 和 802.4）、差错检测和成帧。MAC 子层有以下两个主要功能：\n支持 LLC 子层完成介质访问控制空能，MAC 子层为不同的物理介质定义了介质访问控制标准。 在发送数据时，将从上一层接受的数据组装成带 MAC 地址和差错检测字段的数据帧；在接收数据时拆帧，并完成地址识别和差错检测。 ####### 逻辑链路控制（LLC）子层\nLLC 子层构成数据链路层的上半部分，与网络层和 MAC 子层相邻，负责屏蔽掉 MAC 子层的不同实现，隐藏各种局域网技术之间的差别，向网络层提供服务。LLC 子层的功能主要是建立、维持和释放数据链路，提供一个或多个服务访问点，为网络层提供面向连接的或无连接的服务。另外 LLC 子层还提供差错控制、流量控制和发送顺序控制等功能。\n以太网 以太网（Ethernet）主要采用总线型拓扑的基带传输系统，使用相当广泛。随着技术的发展，网桥、交换机等产品的出现，以太网得到了进一步的发展，快速以太网、吉比特以太网甚至万兆以太网相继出现。在以太网技术中，快速以太网是一个里程碑，确立了以太网技术在桌面的统治地位。以太网技术作为局域网链路层标准战胜了令牌总线、令牌环网等技术，成为局域网事实标准。\n广域网（WAN） 广域网（Wide Area Network，WAN）是指将跨地区的计算机互联在一起组成的计算机网络，又称为远程网。广域网除了直接连接分散的、独立的计算机之外，常被用来连接多个局域网，而 Internet 是连接多个广域网、局域网和分散的计算机所组成的网际网。\n**广域网由通信子网和资源子网两部分构成。**通信子网是由通信链路、通信节点等网络设备组成的通信网，主要使用分组交换技术。局域网使用的协议大多数是位于数据链路层或者物理层，而广域网的协议除了物理层和数据链路层外，更多集中在网络层。\n广域网通信技术 广域网链路分成两种：一种是专线连接，另一种是交换连接。专线是永久的点对点的服务，常用于为某些重要的企业用户提供核心或骨干连接。交换连接包括电路交换、分组交换，很少使用报文交换。\n####### 分组交换\n分组交换是将数据分隔为一个个分组（数据包）进行传送，有两种实现方式：虚电路（Virtual Circuit）和数据报（Datagram）。\n虚电路\n采用虚电路方式，源节点要与目的结点进行通信之前，首先必须建立一条从源节点到目的节点的虚电路（逻辑连接），然后通过该虚电路进行数据传输，最后当数据传输结束时，释放该虚电路。虚电路方式为每一对节点之间之间的通信预先建立一条虚电路，后续的数据通信沿着建立好的虚电路进行，交换节点不必为每个报文进行路由选择。\n数据报\n采用数据报方式，交换机在传输数据过程中不必记录每条打开的虚电路，只需要一张表来指明到达所有可能的目的端交换机的输出线路。数据报方式中，每一个交换节点为每一个进入的报文进行一次路由选择，每个报文的路由选择独立于其他报文。\n####### 电路交换\n电路交换是在源和目的之间建立一条实在的物理专用链路，可以由一条实际的物理线路构成，也可以通过多路复用技术产生。电路交换支持按需连接，通信结束时就会被切断。\nPPP 协议 常用的广域网协议有高级数据链路控制规程（HDLC）、点到点协议（PPP）、串行链路通信协议（SLIP）等。随着互联网的快速发展，现在全世界使用最广泛的数据链路层协议是点到点协议（Point-to-Point Protocol，PPP）。PPP 是使用串行线路通信的面向字节（B）的协议，它通过同步电路和异步电路提供路由器到路由器和主机到网络的连接，还可与包括 IP 在内的多种网络层协议协同工作，并且内置安全机制，如 PAP 和 CHAP 认证。\n####### PPP 协议组件\n用于封装的 HDLC 协议\nPPP 用于在点对点链路上封装数据报的是 HDLC 协议。许多数据链路层协议的封装方式都是基于 HDLC 的封装格式的，PPP 也不例外，它也采用了 HDLC 的定界帧格式。HDLC 是一种面向位（bit）的数据链路控制协议，提供了面向连接和无连接服务，是其他许多重要数据链路控制协议的基础。\n链路控制协议\nPPP 提供了链路控制协议（Link Control Protocol，LCP）。LCP 用于建立、配置和测试数据链路连接。它能用来协商 PPP 协议的一些配置参数选项，处理不同大小的数据帧，检测链路环路，终止一条链路。LCP 提供链路中对等体的身份认证，决定连接成功或者失败。\n网络控制协议\nPPP 包括一系列用于建立和配置各种网络层协议的网络控制协议（Network Control Protocol，NCP）。PPP 的网络层交由各自的网络层协议管理。PPP 支持同时使用多种网络层协议。\nPPP 协议主要包括以上三部分，PPP 执行的大部分工作是由 LCP 和 NCP 在数据链路层和网络层完成的。LCP 负责建立 PPP 连接、设置其参数，以及终止 PPP 连接；而 NCP 负责配置上层协议。\n结语 对于局域网内的通信，只需要用到 MAC 寻址即可确定目标主机；而对于广域网通信不仅要用到 MAC 寻址，还需要用到 IP 地址进行标识，才能在全局唯一的确定目标主机。因为，MAC 地址实际上只在局域网内有效，虽然不同的设备 MAC 地址是唯一的，但由于每经过一个路由网段，数据包的源和目的 MAC 地址都要更改（源和目的 IP 地址不变），所以不同网段中存在相同的 MAC 地址也是可以的。\n"},{"section":"Blog","slug":"/blog/computer-technology/protocol/protocol-base/","title":"网络通信关键概念","description":"计算机网络是通过通信设备与线路将地理上分散并且具有独立功能的计算机系统连接在一起，并由功能完善的软件来控制，进而实现资源共享的系统。从物理组成上来看，计算机网络包括硬件、软件和协议三大部分。计算机网络中结点间相互通信是由控制信息传送的网络协议及其他相应的网络软件共同实现的。在计算机网络通信中，有部分关键性概念需要理解透彻，在此做一总结。","date":"June 18, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 协议, 关键概念","tags":"","content":"计算机网络是通过通信设备与线路将地理上分散并且具有独立功能的计算机系统连接在一起，并由功能完善的软件来控制，进而实现资源共享的系统。从物理组成上来看，计算机网络包括硬件、软件和协议三大部分。计算机网络中结点间相互通信是由控制信息传送的网络协议及其他相应的网络软件共同实现的。在计算机网络通信中，有部分关键性概念需要理解透彻，在此做一总结。\n网络通信协议 **网络通信协议简称网络协议（Poctocol），是指为了能在计算机网络中进行数据交换，实现资源共享而建立的通信规则、标准或约定的集合。**在计算机网络中，只有采用相同网络协议的计算机才能进行信息的交流与沟通。网络协议有以下三个基本要素：\n语义（Semantics）\n规定双方完成通信需要的控制信息及应执行的动作。\n语法（Syntax）\n规定通信双方交换的数据或控制信息的格式和结构。\n时序（Timing）\n规定通信双方彼此的应答关系，包括速度的匹配和顺序。\n点-点传输 \u0026amp; 端-端传输 在网络通信过程中，定义了两种数据传输方式：点到点传输和端到端传输。\n点-点传输 **点到点（Point-To-Point，PTP）传输方式对应于物理拓扑，是一种更注重过程的传输方式。**点到点传输不需要建立连接，在网络中的两个直接相连相邻节点之间的数据传输方式就是点到点传输，即相邻设备之间不存在其他设备。在 OSI 体系结构中，底三层通信子网（物理层、链路层、网络层）采用的就是点到点传输方式。\n优点\n发送端设备送出数据后，它的任务已经完成，不需要参与整个传输过程，这样不会浪费发送端设备的资源。另外，即使接收端设备关机或故障，点到点传输也可以采用存储转发技术进行缓冲。\n缺点\n发送端发出数据后，不知道接收端能否收到或何时能收到数据。\n端-端传输 端到端（End-To-End，ETE）传输方式对应于逻辑拓扑，是一种更注重结果的传输方式。 端到端传输是依赖于网络连接的，网络要通信必须建立连接，无论（源和目的）之间经过多少个网络节点，只要建立连接就属于端到端传输，即这种连接是一种逻辑链路。在 OSI 体系结构中，高四层（传输层、会话层、表示层、应用层）采用的就是端到端传输方式。\n优点\n逻辑链路建立后，发送端知道接收设备一定能收到，而且经过中间交换设备时不需要进行存储转发，因此传输延迟小。\n缺点\n直到接收端收到数据为止，发送端的设备一直要参与传输。如果整个传输的延迟很长，那么对发送端的设备造成很大的浪费；而且如果接收设备关机或故障，那么端到端传输不可能实现。\n面向连接协议 \u0026amp; 无连接协议 网络通信协议可分为两种类型：面向连接协议和无连接协议。\n面向连接协议 **采用面向连接协议（Connection-oriented Protocol）进行通信时，发送端与接收端必须要建立连接，即两个端点之间建立数据通信信道（虚电路）。**面向连接的方式通常提供的是可靠的传输服务，它能保证数据一定能够传送到目的地，而且数据内容不发生变化。 TCP 协议就是一种面向连接的协议，它提供了面向连接、可靠的字节流服务。\n无连接协议 **采用无连接协议（Connectionless Protocol）进行通信时，发送端与接收端不需要建立连接，只需要知道接收端地址即可。**无连接的方式通常提供的是不可靠的传输服务，它不能保证数据一定能够到达目的地，但它可以检验出到达目的地的数据是否完整；另一方面，由于不需要建立连接，这种方式更快一些。IP、UDP 协议就是无连接的协议，它们也是数据报协议，不是通过字节流而是分组的数据报进行数据传输。\n电路交换 \u0026amp; 报文交换 \u0026amp; 分组交换 网络数据交换技术主要有三种：电路交换、报文交换、分组交换。现在主要使用电路交换和分组交换技术。\n电路交换 **电路交换（Circuit Switching，也称线路交换）是一种面向连接的服务，即两台计算机通过通信子网进行数据交换之前，首先要在通信子网中建立一条实际的、专用的（独占的）物理线路连接。**最典型的例子就是电话通信系统。\n优点\n通信线路为通信双方专用，数据直达，所以传输数据的时延非常小；通信双方之间的物理通路一旦建立，双方可以随时通信，实时性强；双方通信时按发送顺序传送数据，不存在失序问题；电路交换既适用于传输模拟信号，也适用于传输数字信号；电路交换的交换设备（交换机等）及控制均较简单。\n缺点\n平均连接建立时间对计算机通信来说显得较长；电路交换连接建立后，物理通路被通信双方独占，即使通信线路空闲，也不能供其他用户使用，因而信道利用率低；电路交换时，数据直达，不同类型、不同规格、不同速率的终端很难相互进行通信，也难以在通信过程中进行差错控制。\n报文交换 **报文交换（Message Switching）采用存储-转发技术进行数据传输。**首先将一个完整的报文传送给交换机的缓冲区，待下一个节点的交换机空闲时将报文转发给它，一级一级的最终送到目的主机。电子邮件系统（E-mail）适合采用报文交换方式。\n优点\n报文交换不需要为通信双方预先建立一条专用的通信线路，不存在连接建立时延，用户可随时发送报文；采用存储-转发技术，可通过不同的逻辑链路将数据送达目的主机，提高了可靠性；而且可实现不同类型、不同规格、不同速率的终端之间相互通信；提供多目标服务，即一个报文可以同时发送到多个目的地址；允许建立数据传输的优先级，使优先级高的报文优先转换。\n缺点\n由于数据进入交换结点后要经历存储、转发这一过程，从而引起转发时延，同时也造成服务实时性差；报文交换只适用于数字信号；每个网络节点需要一定容量的缓冲区，成本高。\n分组交换 分组交换（Packet Switching，也称包交换）仍采用存储-转发传输方式，但将一个长报文先分割为若干个较短的分组，然后把这些分组逐个地发送出去。分组交换原理与报文交换类似，是目前应用最广的交换技术，它结合了电路交换和报文交换两者的优点，使其性能达到最优。分组交换的实现方式又分为两种：数据报分组交换和虚电路分组交换。\n数据报（Datagram）分组交换\n通信前不需要建立逻辑连接，数据包可通过不同的逻辑链路送达目的主机，而且不同数据包到达顺序是无序的，属于无连接的工作方式。\n虚电路（Virtual Circuit）分组交\n通信前需要建立一条逻辑连接，数据包通过一条相同的逻辑链路，保证了数据传输的顺序，提供了可靠的服务，属于面向连接的工作方式。\n除过报文交换的优缺点外，分组交换在此基础上的优缺点为以下部分。\n优点\n加速了数据在网络中的传输；简化了存储管理；减少了出错几率和重发数据量。\n缺点\n每个分组都要添加源、目的地址和分组编号等，开销大；采用数据报分组交换服务时，可能出现失序、丢失或重新分组。\n"},{"section":"Blog","slug":"/blog/computer-technology/protocol/protocol-osi/","title":"OSI 与 TCP/IP 参考模型","description":"目前流行的两大网络体系结构是 OSI/RM 和 TCP/IP 参考模型，他们均是分层结构。分层是为了简化问题，降低网络设计复杂性，而且各层次结构相互独立，实现的功能也相对独立。层与层之间只在层间接口处关联，层间耦合最小。","date":"June 17, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 协议, OSI, TCP/IP","tags":"","content":"目前流行的两大网络体系结构是 OSI/RM 和 TCP/IP 参考模型，他们均是分层结构。分层是为了简化问题，降低网络设计复杂性，而且各层次结构相互独立，实现的功能也相对独立。层与层之间只在层间接口处关联，层间耦合最小。\nOSI（Open System Interconnect） OSI/RM（Open System Interconnection Reference Module，简称 OSI）即开放系统互联参考模型。为了解决不同网络体系结构的互联、互操作问题，ISO（国际标准化组织）制定了 OSI 模型。OSI 模型把网络通信的工作分为七层，自上而下依次为：\n应用层（Application） 表示层（Presentation） 会话层（Session） 传输层（Transport） 网络层（Network） 链路层（Data Link） 物理层（Physical） 第 1-3 层（物理层、链路层、网络层）属于 OSI 参考模型的底层，负责创建网络通信连接的链路，通常称为 通信子网；第 5-7 层（会话层、表示层、应用层）是 OSI 参考模型的高层，具体负责端到端的数据通信、加密/解密、会话控制等，通常称为 资源子网；第 4 层（传输层）是 OSI 参考模型的高层与底层之间的连接层，起着承上启下的作用，是 OSI 参考模型中第一个端到端的层次。\nOSI 参考模型中的每一层都能完成一定的功能，直接为上层提供服务，并且所有层次都相互支持，网络通信可以自上而下（发送端）或自下而上（接收端）双向进行。而且每一层的内部结构对上、下层屏蔽不可见，上层依赖于下层所提供的服务，仅通过层间接口进行数据传输，实现层间耦合最小。\n通信机制 **OSI 参考模型采用逐层传递、对等通信的通信机制。**整个通信过程都必须经过一个自上而下（发送端），或自下而上（接收端）的数据传输过程，但通信必须在双方对等层进行。网络中的节点之间要相互通信，必须经过一层一层的信息转换来实现，即源主机向目标主机发送数据，数据必须自上而下逐层封装（数据打包），目标主机接收数据后，必须对封装的数据进行自下而上逐层分解（解封）。对于用户来说，这种数据通信看起来就像是在两台计算机相关联的对等层之间直接进行的，而对同一主机内的相邻层之间的通信是透明的，两台主机的通信就像在通信的双方对应层之间建立了一种逻辑的、虚拟的通信。实际上，真正的通信只发生在同一主机内彼此相邻的两层之间。\nOSI 参考模型中，在网络各层的实体之间传送的比特组称为数据单元（Data Unit）。常用的数据单元有服务数据单元（SDU）和协议数据单元（PDU）。 SDU 是在同一主机上的两层之间传送的信息，而 PDU 则是发送主机上每层发送到接受主机上的相应层（对等层）的信息。\nOSI 参考模型中第 1-3 层（物理层、链路层、网络层）采用的是点到点传输，而剩下的第 4-7 层（传输层、会话层、表示层、应用层）则采用端到端传输。\n物理层（Physical Layer） 物理层规定了通信设备的机械特性、电气特性、功能特性和规程特性，用于建立、维护、拆除物理链路的连接。物理层传输的数据单元是比特（bit）。物理层定义的典型规范有 EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45 等。物理层的典型设备有光纤、同轴电缆、双绞线、中继器、集线器和网卡等。\n数据链路层（Data Link Layer） 数据链路层是在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路（逻辑的），通过差错控制提供数据帧在信道上无差错的传输。**数据链路层传输的数据单元是帧（Frame）。**数据链路层协议主要有 SDLC、HDLC、PPP、STP、帧中继等。数据链路层的典型设备有二层交换机、网桥、网卡等。\n网络层（Network Layer） 网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送到目的地。网络层还可以实现拥塞控制、网际互联等功能。**网络层传输的数据单元是数据分组（Packet）。**网络层协议主要有 IP、IPX、ICMP、IGMP、RIP、OSPF 等。网络层的典型设备就是路由器。\n传输层（Transport Layer） 传输层居中，是承上启下层，该层负责获取全部信息，为上层提供端到端的透明的、可靠的数据传输服务。**传输层传输的数据单元是报文（Message）或数据包（Packets），具体也可称为数据段（TCP 协议）或数据报（UDP 协议）。**传输层协议主要有 TCP、UDP、SPX 等。传输层及以上高层次的典型设备就是各种终端设备（PC、平板、手机等）。\n会话层（Session Layer） 会话层不参与具体的传输，它提供包括访问验证和会话管理在内的建立、维护应用进程之间通信的机制，如服务器验证用户登录等。**会话层及以上的高层次中，数据传送的单元不再另外命名，统称为某层报文。**会话层没有具体的协议。\n表示层（Presentation Layer） 表示层主要解决用户信息的语法表示、加密/解密、压缩/解压等问题。它将欲交换的数据从适合某一用户的抽象语法，转换为适合 OSI 系统内部使用的传送语法，即提供格式化的表示和转换数据服务。表示层也没有具体的协议。\n应用层（Application Layer） 应用层是 OSI 参考模型的最高层，它是服务用户，惟一直接为用户应用进程访问 OSI 环境提供手段和服务的层次，应用层以下各层通过应用层间接地向应用进程提供服务。应用层协议主要有 DNS、Telnet、FTP、HTTP、SMTP、SNMP 等。\nTCP/IP（Transmission Control Protocol/Internet Protocol） TCP/IP（Transmission Control Protocol/Internet Protocol Reference Module，简称 TCP/IP）参考模型就是 TCP/IP 协议栈（协议簇），其中核心协议是 TCP 和 IP。它分为 4 层，与 OSI 参考模型中的分层类似，但并非完全一致。它的四层结构自上而下依次为：\n应用层（对应 OSI 中：应用层+表示层+会话层） 传输层（对应 OSI 中：传输层） 网际互联层（对应 OSI 中：网络层） 网络接口层（对应 OSI 中：链路层+物理层） **TCP/IP 协议栈与 OSI 参考模型一样采用逐层传递、对等通信的通信机制。**在发送端主机自上而下进行数据的封装，发送到接收端后，接收端主机自下而上进行数据的分用（解封），实现对等层通信。\n网络接口层（Network Interface Layer） 网络接口层又称为网络访问层（Network Access Layer），包括 OSI 参考模型中的物理层和链路层，负责向网络物理介质发送数据包，从网络物理介质接受数据包。**实际上，TCP/IP 并没有对物理层和链路层进行定义，只是定义了一个接口，并且支持现有的各种底层网络技术和标准。**网络接口层涉及操作系统中的设备驱动程序和网络接口设备。\n网际互联层（Interconnection Layer） 网际互联层又称为 IP 层，是 TCP/IP 模型中最主要的层次，是整个体系结构的关键部分，负责处理 IP 数据包的传输、路由选择、流量控制和拥塞控制。网际互联层主要协议有网际协议 IP、地址解析协议 ARP、反向地址解析协议 RARP、Internet 控制报文协议 ICMP、组管理协议 IGMP、内部网关协议 IGP、外部网关协议 EGP 等。网际协议 IP 是 TCP/IP 协议栈中的核心协议。\n传输层（Transport Layer） **传输层为两台主机上的应用程序提供端到端的通信，该层主要定义了两个端到端的协议：传输控制协议 TCP 和用户数据报协议 UDP。**这两种协议对应不同的性质的服务，TCP 为主机提供可靠的面向连接的传输服务；UDP 为应用层提高简单高效的无连接传输服务。\n应用层（Application Layer） 应用层包括 OSI 参考模型中的会话层、表示层、应用层，直接为特定的应用提供服务。TCP/IP 协议栈给出了应用层的一些常用协议规范，如文件传输协议 FTP、简单邮件传输协议 SMTP、超文本传输协议 HTTP 等。\nOSI 与 TCP/IP 模型比较 OSI 模型是一个概念模型，并没有提供一个可供实现的方法；而 TCP/IP 模型是已经被广泛实现的事实标准。OSI 参考模型制定时 TCP/IP 协议已经实现，随后为了实现网络通信标准化通过借鉴 OSI 参考模型制定了 TCP/IP 参考模型。 两种体系结构均能提供面向连接（TCP）和无连接（UDP）两种通信服务机制。 TCP/IP 参考模型的网络接口层并不是真正的一层，它没有像 OSI 模型一样定义物理层和链路层，只是定义了一个接口。 OSI 参考模型的抽象能力高，降低了各层之间耦合度，适合于描述各种网络；而 TCP/IP 是先有了协议，才制定 TCP/IP 模型的，并且各层之间耦合度相对来说比较高。 "},{"section":"Blog","slug":"/blog/computer-technology/web/web-local-storage/","title":"Web 本地存储","description":"为了达到某些需求，我们通常需要在本地存储一些数据，方便我们进行用户个性化定制服务。","date":"June 1, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web前端, Cookie, LocalStorage, SessionStorage","tags":"计算机技术, Web前端, Cookie, LocalStorage, SessionStorage","content":"为了达到某些需求，我们通常需要在本地存储一些数据，方便我们进行用户个性化定制服务。\nWeb 存储 在互联网上，许多网站提供用户注册功能，因为 http 协议是个无状态的协议（无法记录客户端与服务器端状态），所以我们注册登录后每一次跳转网页都需要重新登陆。为了增强用户体验，我们不得不将状态信息保存下来，而 Web 存储技术则实现了该需求。Cookie 最多可在本地存储 4K 数据，出于安全性考虑， Cookie 中并非直接存储的是用户敏感数据（帐号、密码、个人信息等），而是一个状态 ID，该 ID 是服务器端利用 session 存储一个会话状态并分配给客户端用来进行状态识别的。因此，每一次的 http 请求都会带上 Cookie 数据发送给服务器端进行状态识别，从而达到状态保持的目的。\nHTML5 Web 本地存储 在以前，我们是通过 Cookie 来实现 Web 本地存储的。不过，HTML5 为我们带来了新的 Web 本地存储功能，即 localStorage 与 sessionStorage，下面我们来简单的分析一下它们各自的特点。\nCookie Cookie 相对来说用的时间很长了，技术更加成熟，尤其是这么多年以来在 Web 安全方面也有了很大的进步，在敏感信息存储方面 Cookie 的优势是明显的。而且，Cookie 在同源窗口中是共享的，同时也可以限制在某个路径下；它的有效期也是可以设置的，没有到达有效期前即使关闭浏览器窗口依然是有效的。\n相反的，Cookie 的缺点也是明显的，最多只能存储约 4K 大小的数据；而且每次都会伴随同源 http 请求发送给服务器端，很浪费带宽。\nlocalStorage localStorage 存储的数据量要大得多，大约 5M 左右；它在同源窗口中也是共享的。而且，localStorage 存储数据的时间甚至长达数年（不主动删除，即使浏览器关闭也存在），所以说在开发过程中我们可以使用它来存储更多的数据，并更持久的存储。\nsessionStorage sessionStorage 存储的数据量也要大得多，但它是不能在同源窗口中共享的，也就是说它只允许在同窗口同页面中访问。而且，sessionStorage 存储的数据会在浏览器窗口关闭的时候自动删除，不能实现持久的保存数据。\n注意：sessionStorage 在不同的标签页之间无法共享。\n结语 就目前来看，HTML5 提供的新的 Web 本地存储方法适合存储一些非敏感数据，对于用户敏感的数据还是依靠 Cookie 来存储更安全一些。而 Web 本地存储是没有绝对安全的，依然面临很严峻的考验。\n"},{"section":"Blog","slug":"/blog/computer-technology/linux/linux-base/","title":"Linux-基础","description":"Linux 是在做一些较为底层的开发工作时的必要开发环境，了解 Linux 也对操作系统概念的理解有很大的帮助，这篇文章是对 Linux 的一些基础概念的阐述。","date":"May 29, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 操作系统, LINUX","tags":"","content":"Linux 是在做一些较为底层的开发工作时的必要开发环境，了解 Linux 也对操作系统概念的理解有很大的帮助，这篇文章是对 Linux 的一些基础概念的阐述。\nLinux Linux 的诞生是在上世纪 90 年代，距离现在也就二十年左右，是一种优秀的开发环境，大多时候应用在嵌入式系统开发当中。Linux 是一个开源的基于 POSIX 和 UNIX，支持多用户、多任务、多线程和多 CPU 的操作系统。事实上，linux 指的是其操作系统的内核。\n特点 下面是一些 Linux 系统的一些特点。\n开源\nLinux 操作系统的源代码是公开的，遵循 GPL 协议（开源协议），所以 Linux 允许任何人去查看它的源代码，并进行修改。这对于开发人员来说相当于提供了一个了解操作系统原理的绝佳机会。\n免费\nLinux 操作系统的使用是免费的，但需要遵循 GPL 协议。很多人认为开源即免费，这其实是个概念上的错误。有很多的商业项目是开源的，开源即允许个人用户去查看源代码，了解其实现过程，但并不意味着你可以将其免费用作商业用途。但是，Linux 不仅是开源的，还是免费的。还需要注意的一点就是，Linux 有不同的发行版本，部分都有商业公司支持，这样的 Linux 用作商业用途的话需要购买其许可证，之后会得到更好的技术服务支持。\n兼容 POSIX 标准\nPOSIX 是一种可移植操作系统接口标准，POSIX 标准定义了操作系统应该为应用程序提供的接口标准，是 IEEE 为要在各种 UNIX 操作系统上运行的软件而定义的一系列 API 标准的总称，其正式称呼为 IEEE 1003，而国际标准名称为 ISO/IEC 9945。这样的好处就是，在 Linux 环境下，我们可以通过相应的模拟器运行常见的 DOS、Windows 的程序。\n多用户、多任务\n与微软 Windows 系统一样，Linux 也支持多用户、多任务、多线程、多 CPU，这是现代操作系统所必须具备的能力。\n基于命令行\nLinux 操作系统准确的说是一个基于命令行的系统，它并没有实现 GUI（图形用户界面），这就是和微软 Windows 的不同之处，这也使得 Linux 根本不可能面向社会上的大众用户。\n可移植性\nLinux 可运行在不同的 CPU 平台上，可移植性很强，所以 Linux 在嵌入式系统开发当中应用广泛。\nLinux 的组成 首先，Linux 可划分为以下四部分：\nLinux 内核 GNU 工具 图形化桌面环境 应用软件 Linux 内核 **Linux 系统的核心是内核。**内核控制着计算机系统上所有的硬件和软件，在必要时分配硬件，并根据需要执行软件。\n内核主要负责以下四种功能：\n系统内存管理 软件程序管理 硬件设备管理 文件系统管理 **Linux 操作系统对于用户空间和内核空间有严格的区分，他们之间有明显的界限。**用户空间主要包含 GNU C 库（glibc）和用户应用程序（User Applications）等；内核空间则包含系统调用接口（System Call Interface，SCI）、内核（Kernel）、板级支持包（Board Support Package，BSP）三层。\nWindows 系统的内核是 NT，它是一种微内核，只提供操作系统必要的功能，例如进程管理，内存管理等等，微内核可以更方便的进行升级，扩展；而** Linux 操作系统的内核是 linux，它是一种宏内核**，不仅在内核中实现了操作系统必要的服务，而且硬件设备驱动也存在于内核中，内核效率相对于微内核来说较高，对硬件设备支持也更全面。所有不同发行版本的 Linux 操作系统都是使用的统一标准的 linux 内核，版本号由 Linux 社区所控制。\nlinux 内核主要包含以下几部分子系统：\n系统调用接口（System Call Interface，SCI）\n系统调用接口主要实现从用户空间到内核的函数调用，是一个非常有用的函数调用多路复用和多路分解服务。\n进程管理（Process Management，PM）\n进程管理主要完成进程调度，管理进程共享内存空间等。\n内存管理（Memory Management，MM）\n内存管理主要完成对系统内存资源的管理，以及实现虚拟内存和硬盘资源交换。\n虚拟文件系统（Virtual File System，VFS）\n虚拟文件系统是为文件系统提供的通用的借口抽象，为 SCI 和内核与文件系统之间提供了一个交换层。\n网络堆栈（Network Stack）\n网络堆栈提供了大量的网络协议的用户接口，例如 IP、TCP 协议。\n设备驱动（Device Drivers，DD）\n包含了硬件设备驱动，并且占用了内核大量的资源。\n依赖体系结构的代码（Arch）\n包含 linux 内核支持的硬件体系结构相关的核心代码。\nlinux 内核还是一个动态内核，支持动态添加或删除软件组件，可以在任何时候根据需要将特定模块进行插入，即实现用户定制功能。\n文件（设备）系统 Linux 操作系统支持非常多的文件系统类型，例如 ext、ext2、ext3、ext4、iso9660、xfs、ntfs、proc 等等。而且，**Linux 中的一切设备都抽象成为了文件，用户通过设备文件（设备节点）来使用设备驱动操作设备。**Linux 系统中将设备分为三类：\n字符设备\n指那些必须以串行顺序依次进行访问的设备，如触摸屏、磁带驱动器、鼠标等，用字节流存取文件，没有缓冲区。\n块设备\n块设备可以从设备的任意位置读取一定长度数据的设备，包括硬盘、磁盘、U 盘、SD 卡等,有缓冲区。\n网络设备\n网络设备不同于前两者，不能直接对文件进行操作，不能直接访问网络设备驱动，在 Linux 中通过设备接口和 Socket（套接字）技术（协议）来进行网络设备（进程）之间的通信，从而访问网络设备驱动，实现对网络设备的操作。\nGNU 工具 除了由内核控制硬件设备外，操作系统还需要工具来执行一些标准功能，比如控制文件和程序。Linus 在创建 Linux 系统内核时，并没有可用的系统工具。\nGNU 组织（GNU 是 GNU’s Not Unix 的缩写）开发了一套完整的 Unix 工具，但没有可以运行它们的内核系统。这些工具是在名为开源软件（open source software，OSS）的软件理念下开发的。\n**将 Linus 的 Linux 内核和 GNU 操作系统工具整合起来，就产生了一款完整的、功能丰富的免费操作系统。**因此，Linux 操作系统又称 GNU/Linux 系统。\n核心 GNU 工具 GNU 项目的主旨在于为 Unix 系统管理员设计出一套类似于 Unix 的环境。这个目标促使该项目移植了很多常见的 Unix 系统命令行工具。供 Linux 系统使用的这组核心工具被称为 coreutils（core utilities）软件包。\nGNU coreutils 软件包由三部分构成：\n用以处理文件的工具 用以操作文本的工具 用以管理进程的工具 shell GNU/Linux shell 是一种特殊的交互式工具。它为用户提供了启动程序、管理文件系统中的文件以及运行在 Linux 系统上的进程的途径。shell 的核心是命令行提示符。命令行提示符是 shell 负责交互的部分。它允许你输入文本命令，然后解释命令，并在内核中执行。\nshell 包含了一组内部命令，用这些命令可以完成诸如复制文件、移动文件、重命名文件、显示和终止系统中正运行的程序等操作。shell 也允许你在命令行提示符中输入程序的名称，它会将程序名传递给内核以启动它。\n你也可以将多个 shell 命令放入文件中作为程序执行。这些文件被称作 shell 脚本。你在命令行上执行的任何命令都可放进一个 shell 脚本中作为一组命令执行。\n在 Linux 系统上，通常有好几种 Linux shell 可用。不同的 shell 有不同的特性，有些更利于创建脚本，有些则更利于管理进程。所有 Linux 发行版默认的 shell 都是 bash shell。bash shell 由 GNU 项目开发，被当作标准 Unix shell——Bourne shell（以创建者的名字命名）的替代品。bash shell 的名 称就是针对 Bourne shell 的拼写所玩的一个文字游戏，称为 Bourne again shell。\nLinux 桌面环境 在 Linux 的早期（20 世纪 90 年代初期），能用的只有一个简单的 Linux 操作系统文本界面。这个文本界面允许系统管理员运行程序，控制程序的执行，以及在系统中移动文件。\n随着 Microsoft Windows 的普及，电脑用户已经不再满足于对着老式的文本界面工作了。这推动了 OSS（open source software）社区的更多开发活动，Linux 图形化桌面环境应运而生。Linux 有各种图形化桌面可供选择。\nX Window 系统 X Window 软件是直接和 PC 上的显卡及显示器打交道的底层程序。它控制着 Linux 程序如何在电脑上显示出漂亮的窗口和图形。Linux 并非唯一使用 X Window 的操作系统，它有针对不同操作系统的版本。\n核心的 X Window 软件可以产生图形化显示环境，但仅此而已。虽然对于运行独立应用这已经足够，但在日常 PC 使用中却并不是那么有用。它没有桌面环境供用户操作文件或是开启程序。为此，你需要一个建立在 X Window 系统软件之上的桌面环境。\nKDE 桌面 KDE（K Desktop Environment，K 桌面环境）最初于 1996 年作为开源项目发布。它会生成一个类似于 Microsoft Windows 的图形化桌面环境。\nKDE 桌面允许你把应用程序图标和文件图标放置在桌面的特定位置上。单击应用程序图标，Linux 系统就会运行该应用程序。单击文件图标，KDE 桌面就会确定使用哪种应用程序来处理该文件。\nGNOME 桌面 GNOME（the GNU Network Object Model Environment，GNU 网络对象模型环境）是另一个流行的 Linux 桌面环境。GNOME 于 1999 年首次发布，现已成为许多 Linux 发行版默认的桌面环境（不过用得最多的是 Red Hat Linux）。\nUnity 桌面 这是 Ubuntu 的公司自己开发的一套叫作 Unity 的 Linux 桌面环境。Unity 桌面得名于该项目的目标——为工作站、平板电脑以及移动设备提供一致的桌面体验。 不管你是在工作站还是在手机上使用 Ubuntu，Unity 桌面的使用方式都是一样的。\nBootloader 是什么 **Bootloader 是系统的启动加载程序，用来初始化硬件设备、建立内存空间映射图，为调用内核准备好正确的环境。**Bootloader 一般包括两种不同的操作模式：\n启动加载模式\n此模式下，Bootloader 会将操作系统从固态存储设备上加载进内存。\n下载模式\n此模式下，目标机可通过串口连接或网络连接从主机下载文件，例如内核映射和根文件系统映射。\nBootloader 的作用主要是完成系统配置、中断接管、系统引导；装载内核、根文件系统、参数传递、内核调试、内核和根文件系统的下载。\nLinux 的文件系统 Windows 下用户可以将硬盘实现分区，即 C 盘、D 盘等，文件存储的实现是多个并行树形结构；而在 Linux 下硬盘用户是不可以分区的，文件存储的实现是单个树形结构，这种目录结构称为虚拟目录（virtual directory），最顶层则是根目录/。\n在 Linux PC 上安装的第一块硬盘称为根驱动器，它包含了虚拟目录的核心，其它目录都是从这里开始构建。Linux 会在根驱动器上创建一些特别的目录，我们称之为挂载点（mount point）。挂载点是虚拟目录中用于分配额外存储设备的目录。虚拟目录会让文件和目录出现在这些挂载点目录中，然而实际上它们却存储在另外一个驱动器中。\n通常系统文件会存储在根驱动器中，而用户文件则存储在另一驱动器中。\n在 Linux 系统中，通用的目录名用于表示一些常见的功能，下面是一些常见的 Linux 顶层虚拟目录名及其内容：\n/bin\n二进制目录，存储一些普通的系统所必需用户级 GNU 工具，是二进制可执行命令文件\n/boot\n启动目录，存储 Linux 操作系统的引导程序，启动加载文件等\n/dev\n设备目录，Linux 在这里创建设备节点，存储系统设备文件，并不是设备驱动程序，而是设备端口文件\n/etc\n系统配置文件目录，存储服务器配置文件，用户账号密码等\n/home\n用户工作主目录，Linux 在这里创建用户目录，用户的个人配置，个人环境变量等都在此存储\n/lib\n库目录，存放系统和应用程序动态共享库文件，类似 Windows 上的 Dll 文件\n/media\n媒体目录，可移动媒体设备的常用挂载点\n/mnt\n挂载目录，另一个可移动媒体设备的常用挂载点\n/opt\n可选目录，常用于存放第三方软件包和数据文件\n/proc\n进程目录，存放系统信息，现有硬件及当前进程的相关信息，系统运行时由内存自动生成\n/root\nroot 用户的工作目录\n/sbin\n系统二进制目录，存储许多 GNU 管理员级工具，是二进制可执行命令文件\n/run\n运行目录，存放系统运作时的运行时数据\n/srv\n服务目录，存放本地服务的相关文件\n/sys\n系统目录，存放系统硬件信息的相关文件\n/tmp\n临时目录，可以在该目录中创建和删除临时工作文件\n/usr\n用户二进制目录，大量用户级的 GNU 工具和数据文件都存储在这里\n/var\n可变目录，用以存放经常变化的文件，比如日志文件\n以上就是 Linux 根目录下一些关键性目录及其存储的文件。需要注意的是：Linux 下的文件存放并不像 Windows 下那样具有随意性，很多文件需要存放在相应的目录中才行。\n应用程序安装 Linux 是一个开源的操作系统，上面使用的软件大多数为开源软件，安装应用程序的方式与 Windows 很不相同。Linux 下的应用程序安装包多为源码包，在安装前需要进行编译，然后才能进行安装；不过，也有 RPM 包，安装过程中不需要手动编译，对技术要求较低。但是，源码包适合所有发行版本的 Linux，RPM 包却没有这个优点。\nLinux 发行版 我们将完整的 Linux 系统包称为发行版。有很多不同的 Linux 发行版来满足可能存在的各种运算需求。大多数发行版是为某个特定用户群定制的，比如商业用户、多媒体爱好者、软件开发人员或者普通家庭用户。每个定制的发行版都包含了支持特定功能所需的各种软件包，比如为多媒体爱好者准备的音频和视频编辑软件，为软件开发人员准备的编译器和集成开发环境（IDE）。\n不同的 Linux 发行版通常归类为 3 种：\n完整的核心 Linux 发行版 特定用途的发行版 LiveCD 测试发行版 核心 Linux 发行版 核心 Linux 发行版含有内核、一个或多个图形化桌面环境以及预编译好的几乎所有能见到的 Linux 应用。它提供了一站式的完整 Linux 安装。市场上比较流行的核心 Linux 发行版有以下：\nSlackware - 最早的 Linux 发行版中的一员，在 Linux 极客中比较流行 Red Hat - 主要用于 Internet 服务器的商业发行版 Fedora - 从 Red Hat 分离出的家用发行版 Gentoo - 为高级 Linux 用户设计的发行版，仅包含 Linux 源代码 openSUSE - 用于商用和家用的发行版 Debian - 在 Linux 专家和商用 Linux 产品中流行的发行版 特定用途的 Linux 发行版 除了提供特定软件外（比如仅为商业用户提供的办公应用），定制化 Linux 发行版还尝试通过自动检测和自动配置常见硬件来帮助新手安装 Linux。这使得 Linux 的安装过程轻松愉悦了许多。\n市场上流行的定制化 Linux 发行版有以下：\nCentOS - 一款基于 Red Hat 企业版 Linux 源代码构建的免费发行版 Ubuntu - 一款用于学校和家庭的免费发行版 PCLinuxOS - 一款用于家庭和办公的免费发行版 Mint - 一款用于家庭娱乐的免费发行版 dyne:bolic - 一款用于音频和 MIDI 应用的免费发行版 Puppy Linux - 一款适用于老旧 PC 的小型免费发行版 许多特定用途的 Linux 发行版都是基于 Debian Linux。它们使用和 Debian 一样的安装文件，但仅打包了完整 Debian 系统中的一小部分。\nLinux LiveCD Linux 世界中一个相对较新的现象是可引导的 Linux CD 发行版的出现。它无需安装就可以看到 Linux 系统是什么样的。多数现代 PC 都能从 CD 启动，而不是必须从标准硬盘启动。基于这点，一些 Linux 发行版创建了含有 Linux 样本系统（称为 Linux LiveCD）的可引导 CD。\n一些可用的流行 Linux LiveCD：\nKnoppix - 来自德国的一款 Linux 发行版，也是最早的 LiveCD Linux PCLinuxOS - 一款成熟的 LiveCD 形式的 Linux 发行版 Ubuntu - 为多种语言设计的世界级 Linux 项目 Slax - 基于 Slackware Linux 的一款 LiveCD Linux Puppy Linux - 为老旧 PC 设计的一款全功能 Linux 结语 这篇文章并不能涵盖 Linux 操作系统的所有概念，Linux 的可移植性很强，使得其在嵌入式系统开发中有着广泛的应用，智能手机操作系统安卓（Android）使用的就是 linux 内核。可以说，Linux 操作系统为开发者提供了一个优秀的开发环境，同时也是一个兼具稳定性和安全性的服务器环境。\n参考 《Linux 命令行与 shell 脚本编程大全》（第 3 版）- [美] Richard Blum / Christine Bresnahan 著 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-js/","title":"DOM-加载 JavaScript","description":"页面的动态交互离不开 Javascript，将 js 脚本引入页面时会阻塞页面加载，在某些时候我们则可以选择异步加载 js 脚本。","date":"May 24, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, JavaScript","tags":"","content":"页面的动态交互离不开 Javascript，将 js 脚本引入页面时会阻塞页面加载，在某些时候我们则可以选择异步加载 js 脚本。\n引入 js 代码 通常我们会将 JavaScript 代码写在一个单独的文件中，这样做的好处是页面整洁、结构更清晰，页面更小加载速度更快，同时也易维护。实际上在页面中引入 js 代码的方法有多种，我们按需选择即可。\n外部脚本文件（允许跨域） 这种方式是最常用的，但要注意的是 \u0026lt;script\u0026gt; 标签内如果再写 js 代码会被直接忽略掉（不执行）。\n\u0026lt;script src=\u0026quot;./js/main.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 内联脚本 该方式会生成一个文本节点，如果我们通过节点的 innerHTML 和 textContent 属性改变其文本内容（代码），并不会执行新的代码。此种方式也较常用。\n\u0026lt;script\u0026gt; alert(1); \u0026lt;/script\u0026gt; 事件属性 我们可以在事件属性的值中写入一个方法引用，在事件触发时则会执行该方法。这种方法不推荐使用。\n\u0026lt;body\u0026gt; \u0026lt;div onclick=\u0026quot;show()\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; function show() { ... } // 作用等价形式为下 var obj = document.querySelector('div'); obj.onclick = show; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; JavaScript 协议 我们可以在元素的属性值中使用 JavaScript 协议来执行相应代码，但这种方式是不推荐使用的。\n\u0026lt;a href=\u0026quot;javascript: false\u0026quot;\u0026gt;Link\u0026lt;/a\u0026gt; 加载外部 js 文件 页面在加载过程中，默认是同步加载 js 的，如果遇到 \u0026lt;script\u0026gt; 标签则会停止页面的一切解析行为，开始（下载）执行相应的 JavaScript 代码，直至执行完毕。这会造成页面阻塞，页面的显示效果可能会因此受到影响。所以说，我们应该尽可能将不需要立即执行的 js 脚本放在 \u0026lt;body\u0026gt; 标签的尾部加载，这时候所有的页面元素已加载完毕，并不会对页面产生过多影响。\n延迟加载 有时候我们的 js 文件可能很大，即便是放在 \u0026lt;body\u0026gt; 尾部也加载的很慢，或者要放的更靠前一点，这样页面的显示效果会被严重影响。此时，我们可以选择将一些不是很重要的 js 文件延迟到 \u0026lt;html\u0026gt; 标签关闭前再进行下载、执行。\ndefer exp：\n\u0026lt;!-- 一直延迟到 \u0026lt;/html\u0026gt; 前才开始加载 --\u0026gt; \u0026lt;script defer src=\u0026quot;./js/main.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 我们可以延迟多个脚本的加载，但并不是所有的浏览器最后都按顺序并且在 DOMContentLoaded 事件前加载它们。\n异步加载 也许我们并不想将 js 文件延迟到 \u0026lt;/html\u0026gt; 标签关闭前才进行加载，此时我们可以通过异步加载来更提前一些。\nasync exp：\n\u0026lt;!-- 开始加载，但不阻塞页面 --\u0026gt; \u0026lt;script async src=\u0026quot;./js/main.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 异步加载会一开始就进行 js 文件的下载，但不会阻塞当前页面的解析，至于何时加载完我们也不知道，但是一加载完就会执行相应代码，此时也不会阻塞页面的解析。同样地，我们可以异步加载多个文件，但必定不会按顺序进行加载，这是我们要注意的。而且，IE10 才开始支持该属性。\n\u0026lt;!-- 测试加载完毕顺序 --\u0026gt; \u0026lt;script async onload=\u0026quot;console.log('1 加载完毕')\u0026quot; src=\u0026quot;./js/1.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script async onload=\u0026quot;console.log('2 加载完毕')\u0026quot; src=\u0026quot;./js/2.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script async onload=\u0026quot;console.log('3 加载完毕')\u0026quot; src=\u0026quot;./js/3.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 动态引入，异步加载 我们可以在不使用 async 属性的情况下，动态创建 \u0026lt;script\u0026gt; 标签并插入 DOM 树，此时引入的 js 文件也会进行异步加载。\n\u0026lt;script\u0026gt; // 动态引入，异步加载，可跨域 var nScript = document.createElement('script'); nScript.src = \u0026quot;http://.../js/1.js\u0026quot;; document.body.appendChild(nScript); \u0026lt;/script\u0026gt; **该方法可以解决跨域访问资源的问题。**同样的，多个文件动态引入均会进行异步加载，但也不会按顺序加载。\n获取所有 script 节点 我们可以通过预先设置的属性获取页面中所有 \u0026lt;script\u0026gt; 标签的节点集合，然后我们可以对其进行遍历打印一些信息。\ndocument.scripts exp：\n\u0026lt;script\u0026gt; // 遍历并打印出 src Array.prototype.slice.call(document.scripts).forEach(function(e){ console.log(e, e.src); }) \u0026lt;/script\u0026gt; 我们获取的并不是一个数组，而是一个节点集合，要使用数组的 forEach() 方法我们就先将其转换成一个数组。\n结语 由于 \u0026lt;script\u0026gt; 标签的同步加载特性，若我们的代码中有进行 DOM 操作，那么放在 \u0026lt;head\u0026gt; 中将会执行失败，因为此时 \u0026lt;body\u0026gt; 中要操作的元素还未解析出来。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-textnode/","title":"DOM-文本节点","description":"文本（Text）节点虽然很多时候我们直接用 innerHTML 去赋值替换，但当我们进行一些细微的修改时，了解一下 DOM 操作还是非常有用的。","date":"May 24, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM","tags":"","content":"文本（Text）节点虽然很多时候我们直接用 innerHTML 去赋值替换，但当我们进行一些细微的修改时，了解一下 DOM 操作还是非常有用的。\n文本节点 文本节点的 DOM 操作是不常用的，我们通常直接用元素节点的 innerHTML 属性直接替换其所有文本节点，但当我们要对文本节点进行局部操作时 DOM 操作却是很有用的。下面列举一些文本节点常用的属性及方法：\ntextContent appendData() deleteData() insertData() replaceData() subStringData() splitText() normalize Data 需要注意的是，我们在元素节点中留下的空格、回车符、制表符等空白字符也是被解析成文本节点的，所以说我们不压缩页面代码的话，会有许多无用的文本节点影响性能。\n文本节点的 DOM 操作 下面就详细介绍一下文本节点常用的 DOM 操作的过程，首先来了解一下如何创建一个文本节点并将其插入到 DOM 树中。\n创建节点并更新到 DOM 树 文本（Text）节点不同于元素节点，在 document 对象上也有专门用来创建文本节点的方法。\ncreateTextNode() exp：\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var textO = document.createTextNode('Hello World!'); document.querySelector('h1').appendChild(textO); \u0026lt;/script\u0026gt; 获取节点的文本值 文本节点的文本值是呈现出来给用户看的，但有些时候我们也需要让程序去获知被用户修改后的文本值。\ndata nodeValue substringData() exp：\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var textO = document.querySelector('h1').firstChild; // 获取文本值 console.log(texto.data); // Hello World! console.log(textO.nodeValue); // Hello World! // 获取文本值的长度 console.log(textO.length); console.log(textO.data.length); console.log(textO.nodeValue.length); // 获取部分文本值（开始索引\u0026lt;不包括\u0026gt;，长度） console.log(textO.substringData(6,5)); // World \u0026lt;/script\u0026gt; 节点的文本值操作 文本节点的文本值事实上也是重要的数据，这涉及到一些查看、增添、删除、修改等操作。\nappendData() deleteData() insertData() replaceData() splitText() exp：\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var textO = document.querySelector('h1').firstChild; // 添加（尾部附加） textO.appendData('!'); console.log(textO.data); // Hello World! // 删除（删除位置索引\u0026lt;不包括\u0026gt;，删除长度） textO.deleteData(7,4); console.log(textO.data); // Hello W! // 插入（插入位置索引\u0026lt;其后插入\u0026gt;，插入值） textO.insertData(7,'orld'); console.log(textO.data); // Hello World! // 替换（替换位置索引\u0026lt;不包括\u0026gt;，替换长度，替换值） textO.replaceData(6,5,'China') console.log(textO.data); // Hello China! // 分割（分割位置索引\u0026lt;不包括\u0026gt;，分割长度） var sText = textO.splitText(6,5); console.log(sText.data); // China! \u0026lt;/script\u0026gt; splitText() 方法会按要求将一个文本节点分割成多个文本节点，同时还会返回包含分割部分的文本节点对象。\n多个文本节点的情况 当我们在一个元素节点内写了很多文本值时，只要它们没有被元素节点分割，所有相邻的文本值将被浏览器解析成一个文本节点。但是，当我们主动创建多个文本节点并插入到 DOM 树中时，浏览器却不会合并这些相邻的文本节点。\n元素内所有文本值 当元素节点内的文本值被多个元素节点分割时，这些文本值会被解析成多个文本节点。元素节点的 innerHTML 属性获取的是该节点内的所有后代节点（包括文本节点与元素节点），而我们有时候却只想查看该节点的所有文本值（所有文本节点合并而成），下面就来看看如何查看。\ntextContent exp：\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello \u0026lt;i\u0026gt;World!\u0026lt;/i\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var eleO = document.querySelector('h1'); // 获取所有文本值 console.log(eleO.textContent); // Hello World! // 设置所有文本值 eleO.textContent = 'Hello World!'; console.log(eleO.textContent); // Hello World! \u0026lt;/script\u0026gt; 我们会发现，textContent 与 innerHTML 获取的值不同，但是它们在进行设置时行为却是一样的，也就是说会覆盖掉目标元素节点内的所有后代节点。\n合并多个文本节点 当有多个相邻的文本节点存在时，我们可以让其合并成一个文本节点，只需要在它们的父元素节点上使用 normalize() 方法即可，这里不再做示例。\nnormalize() 结语 文本节点的属性及方法大部分都可以用在注释节点（Comment）上。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-fragment/","title":"DOM-文档片段","description":"DOM 操作是非常消耗性能的，如果要进行大量的 DOM 操作，我们可以选择在内存中先构建一个文档片段然后一次性插入 DOM 树。","date":"May 23, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, Fragment","tags":"","content":"DOM 操作是非常消耗性能的，如果要进行大量的 DOM 操作，我们可以选择在内存中先构建一个文档片段然后一次性插入 DOM 树。\n文档片段 文档片段（DocumentFragment）也就是 DOM 树的部分节点组合而成的局部。频繁的 DOM 操作对性能的影响是显著的，如果我们要进行大量的相似的 DOM 操作，建议在内存中创建一个文档片段并对其修饰，然后一次性插入 DOM 树。这么做的对性能的影响是最小的，同时也更灵活一些。\n创建文档片段 创建的文档片段是存放在内存中的，我们要谨慎操作，以防丢失引用或者内存泄漏，集中处理完毕后要及时更新到 DOM 树上。\ncreateDocumentFragment() exp：\n\u0026lt;script\u0026gt; var docFrag = document.createDocumentFragment(); ['blue','green','red','pink'].forEach(function(e){ var li = document.createElement('li'); li.textContent = e; li.style.backgroundColor = e; docFrag.appendChild(li); }); \u0026lt;/script\u0026gt; 这样，我们就创建好了一个文档片段，其中包含了四个 li 元素，我们并把它们各自的背景色设置为了其文本内容。\n更新到 DOM 树 在内存中对文档片段处理完毕后，我们就应该将其更新到 DOM 树上，采用的方法前面已经介绍过了。\nappendChild() insertBefore() exp：\n\u0026lt;body\u0026gt; \u0026lt;ul id=\u0026quot;container\u0026quot;\u0026gt;\u0026lt;/ul\u0026gt; \u0026lt;script\u0026gt; document.getElementById('container').appendChild(docFrag); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; 这样我们就将刚才创建的文档片段插入到了 DOM 树中，在页面上的效果也是我们预期的。要清楚的是，文档片段被插入 DOM 树中时，自身会被选中的 DOM 元素替代，也就是文档片段内的元素全都作为选中元素的子元素插入；而且，在插入 DOM 树后，文档片段自身也不再存在，不会发生内存泄漏的问题。\n更灵活的做法 为了让创建文档片段结构更加灵活一点，我们可以使用节点的属性来快速创建 DOM 结构。\ninnerHTML exp：\n\u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var docFrag = document.createDocumentFragment(); var divO = document.createElement('div'); docFrag.appendChild(divO); docFrag.querySelector('div').innerHTML = \u0026quot;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;1\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;2\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;3\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026quot;; document.getElementById('container').appendChild(docFrag); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; 该方法用来创建更复杂的 DOM 结构的代码量是很少的，所以说创建文档片段可以混合不同的方法来提高效率，当然该方法可能更耗性能一些。\n重复利用 我们前面说过，文档片段在更新到 DOM 树中时会自动消失，如果我们想重复利用文档片段的话，在插入 DOM 树时将其副本插入就可以了。\ncloneNode()\n注意，cloneNode() 方法有一个布尔型参数，false 代表只复制节点自身，true 代表复制节点自身及其所有子节点。\n结语 文档片段为我们提供了一个在内存中进行 DOM 预处理的机制，这要比我们重复进行真实 DOM 操作性能要高得多，我们应该合理利用这个机制。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-event/","title":"DOM-事件","description":"JavaScript 的作用就是让 html 静态页面具备动态效果，而这些基本都是利用 DOM 事件来实现的。","date":"May 23, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, Event","tags":"","content":"JavaScript 的作用就是让 html 静态页面具备动态效果，而这些基本都是利用 DOM 事件来实现的。\n注册 DOM 事件 事件就是给目标 DOM 节点提前注册一个相应类型的事件方法，在合适的时机进行回调执行该方法的过程。接下来就来看看如何给目标 DOM 节点注册事件：\n\u0026lt;style\u0026gt; div { background-color: #ccc; margin-bottom: 20px; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- 第一种：内联（html）事件 --\u0026gt; \u0026lt;div onclick=\u0026quot;alert(-1)\u0026quot;\u0026gt;这是个内联事件\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;event0\u0026quot;\u0026gt;这是个0级DOM事件\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;event2\u0026quot;\u0026gt;这是个2级DOM事件\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 第二种：属性（0级DOM）事件 var div_obj0 = document.querySelector(\u0026quot;#event0\u0026quot;); div_obj0.onclick = function(){ alert(0); } // 第三种：2级DOM事件（addEventListener 方法） var div_obj2 = document.querySelector(\u0026quot;#event2\u0026quot;); div_obj2.addEventListener(\u0026quot;click\u0026quot;, function(){ alert(1); }, false); \u0026lt;/script\u0026gt; 以上示例可以看出，我们有三种定义事件的方式：内联（html）事件、属性（0 级 DOM）事件、2 级 DOM 事件。事实上，前两者的本质是一样的，都是内联属性事件；我们通常都是通过第三种方式来（2 级 DOM 事件）定义事件的，它可以将同种事件定义多次而不会覆盖。\n我们在这里通过三种方式定义了三个事件，但它们都属于 click （鼠标左键点击）类型的事件，这只是其中一种事件类型，更多的事件类型我们不在这里进行一一列举。\n事件流程 如果我们给一个元素节点和它的子节点均定义了相同类型（例如 click）的事件，当子节点的事件触发时，那么它的父元素事实上也满足了事件触发条件，但是它们的先后顺序是怎样的？这时候对于整个 HTML 文档（DOM 树）来说就有一个事件流程的概念。\n\u0026lt;style\u0026gt; div { height: 200px; background-color: #ccc; } \u0026lt;style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;body是html的子节点，该div又是body的子节点\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 事件捕获阶段 document.documentElement.addEventListener('click', function(){ console.info(\u0026quot;1：捕获目标中\u0026quot;); }, true); document.body.addEventListener('click', function(){ console.info(\u0026quot;2：捕获目标中\u0026quot;); }, true); // 目标div document.querySelector('div').addEventListener('click', function(){ console.info(\u0026quot;3：找到目标div\u0026quot;); }, false); // 事件冒泡阶段 document.body.addEventListener('click', function(){ console.info(\u0026quot;4：事件冒泡中\u0026quot;); }, false); document.documentElement.addEventListener('click', function(){ console.info(\u0026quot;5：事件冒泡中\u0026quot;); }, false); \u0026lt;/script\u0026gt; 以上示例中，当我们用鼠标左键点击 DIV 时，控制台上会依次出现这五句话，而这正展示了 DOM 事件流程中的一部分，但足以说明事件流程这个概念。\n当我们触发了某个 DOM 节点上的事件时，浏览器会从 DOM 树的根部开始遍历（捕获）到目标节点，待找到目标节点后触发事件，之后又反向遍历（冒泡）到 DOM 树的根节点。这也就是 DOM 事件流程：\n捕获 -\u0026gt; 目标触发事件 -\u0026gt; 冒泡\n在捕获与冒泡过程中，若路过（遍历）的节点上定义的事件与目标节点上触发的事件类型相同的话也会被触发。\naddEventListener() 方法的第三个参数是个布尔值：**true 则表示事件在捕获阶段触发，false 则表示事件在冒泡阶段触发。**我们通常让事件在冒泡阶段触发。\n事件对象 每一个 DOM 事件都有一个对应的 event 对象，该对象拥有一些属性和方法可以帮助我们更好地控制事件。下面来看看该对象的一些常用属性：\ntype\n事件类型（例如 click、mouseover）\ntarget\n事件触发节点对象\ncurrentTarget\n事件定义（注册）源节点对象\neventPhase\n事件触发阶段（1：捕获，2：目标，3：冒泡）\nexp：\n\u0026lt;style\u0026gt; div { height: 200px; background-color: #ccc; margin: 20px; } \u0026lt;style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;分别点击该DIV和body试试看\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;分别点击该DIV和body试试看\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // body上定义事件 document.body.addEventListener('click', function(event){ console.info(\u0026quot;this：\u0026quot;, this); console.info(\u0026quot;currentTarget：\u0026quot;, event.currentTarget); console.info(\u0026quot;target：\u0026quot;, event.target); }, true); \u0026lt;/script\u0026gt; 以上示例可以看出，当我们分别点击 body 与 div 时，target 是变化的，它表示的是事件触发的节点对象；而 currentTarget 是不变的，它表示的是定义事件的节点对象（也就是节点自身），与 this 关键字相等。\n阻止事件默认行为 当我们验证表单时，如表单中用户输入的值不满足要求时是不能提交的，这时候就需要阻止表单的默认行为（提交）。所以说，在某些场景下，我们需要阻止事件的默认行为来达到我们的一些目的。\npreventDefault() exp：\n\u0026lt;body\u0026gt; \u0026lt;a href=\u0026quot;http://www.163.com\u0026quot;\u0026gt;网易\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; document.querySelector(\u0026quot;a\u0026quot;).onclick = function(event){ // 阻止超链接的默认跳转行为 event.preventDefault(); // return false; 也可以 } \u0026lt;/script\u0026gt; 以上示例中，我们会发现点击该超链接是没有任何反应的，它不会跳转到目标页面。需要注意的是，preventDefault() 方法并不会阻止事件的捕获和冒泡行为。\n终止事件流程 通常我们都是让事件在冒泡阶段触发，在这种情况下当我们要很精确的控制事件触发条件时，也就是要确保 event 对象的 target 与 currentTarget 属性相同时，我们就要终止事件流程，防止触发其他节点的事件。\nstopPropagation() exp：\n\u0026lt;body\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; value=\u0026quot;请输入信息\u0026quot; /\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // 定义body上的事件（冒泡阶段触发） document.body.addEventListener('click', function(){ alert(\u0026quot;我是body\u0026quot;); }, false); // 定义input上的事件 document.querySelector(\u0026quot;input\u0026quot;).addEventListener('click', function(event){ this.value = \u0026quot;\u0026quot;; // 终止事件流程 event.stopPropagation(); }, false); \u0026lt;/script\u0026gt; 以上示例中，当我们点击输入框时，触发了 input 上的事件却没有紧接着触发 body 上的事件，这是因为我们终止了事件流程（冒泡）。\n移除 DOM 事件 既然能定义（添加）事件，当然也能移除事件了，而我们有时候的确需要这么做。\n\u0026lt;body\u0026gt; \u0026lt;inout type=\u0026quot;text\u0026quot; value=\u0026quot;请输入信息\u0026quot; /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 定义事件方法 function show(){ alert(this.value); this.value=\u0026quot;\u0026quot;; } // 定义input上的0级DOM事件 document.querySelector(\u0026quot;input\u0026quot;).onclick = show; // 移除0级DOM事件（内联事件也一样） document.querySelector(\u0026quot;input\u0026quot;).onclick = \u0026quot;\u0026quot;; // 定义input上的2级DOM事件 document.querySelector(\u0026quot;input\u0026quot;).addEventListener('click', show, false); // 移除2级DOM事件 document.querySelector(\u0026quot;input\u0026quot;).removeEventListener('click', show, false); \u0026lt;/script\u0026gt; 内联事件与 0 级 DOM 事件只需要给目标节点的相应内联属性赋值为空即可移除事件；而 removeEventListener() 可以移除事件方法为引用类型的 2 级 DOM 事件，它不能移除事件方法为匿名方法的事件。\n事件委托 有时候我们需要提前给未加入 DOM 树中的节点定义（添加）事件，这时我们可以将该事件委托（定义）给该节点的父节点，利用事件流程就可以实现我们的目的。\n\u0026lt;body\u0026gt; \u0026lt;form action=\u0026quot;\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; value=\u0026quot;请输入用户名\u0026quot; /\u0026gt; \u0026lt;input type=\u0026quot;password\u0026quot; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 将input(text)上的事件委托给父节点form document.querySelector(\u0026quot;form\u0026quot;).addEventListener('click',function(event){ // 判断事件触发目标 if(event.target.nodeName == \u0026quot;INPUT\u0026quot; \u0026amp;\u0026amp; event.target.type == \u0026quot;text\u0026quot;){ alert(event.target.value); event.target.value=\u0026quot;\u0026quot;; ｝ }, false); \u0026lt;/script\u0026gt; 事件委托的原理就是，我们将目标节点的事件定义（委托）在其父节点上，当我们在目标节点触发了事件时，在向上冒泡的过程中碰到其父节点然后触发事件。\n结语 灵活运用事件，可以让我们的 html 页面用户交互体验效果更好，同时事件委托也为我们提供了更改 html 文档后同类元素节点依然可以拥有相同事件的可能。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-attribute/","title":"DOM-元素节点属性","description":"元素节点上具有很多属性，这些属性我们通常可以很方便的获取，并进行简单的操作。","date":"May 21, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, Attribute","tags":"","content":"元素节点上具有很多属性，这些属性我们通常可以很方便的获取，并进行简单的操作。\n节点属性常用操作 每个 HTML 元素都有很多属性，例如（id、class、name、url、src、href）等等，元素节点上定义了一些方法供我们使用，来对这些属性进行设置、获取、移除操作。\nsetAttribute() getAttribute() removeAttribute() exp:\n\u0026lt;body\u0026gt; \u0026lt;img style=\u0026quot;width: 200px;height: 200px;\u0026quot; /\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var img_obj=document.querySelector(\u0026quot;img\u0026quot;); // 用方法设置单个属性 img_obj.setAttribute(\u0026quot;src\u0026quot;,\u0026quot;123.png\u0026quot;); img_obj.setAttribute(\u0026quot;title\u0026quot;,\u0026quot;img\u0026quot;); img_obj.setAttribute(\u0026quot;alt\u0026quot;,\u0026quot;img\u0026quot;); // 用方法获取单个属性 console.log(img_obj.getAttribute(\u0026quot;src\u0026quot;)); // 输出 123.png console.log(img_obj.getAttribute(\u0026quot;title\u0026quot;)); // 输出 img console.log(img_obj.getAttribute(\u0026quot;alt\u0026quot;)); // 输出 img // 用方法移除单个属性 img_obj.removeAttribute(\u0026quot;src\u0026quot;); img_obj.removeAttribute(\u0026quot;title\u0026quot;); img_obj.removeAttribute(\u0026quot;alt\u0026quot;); \u0026lt;/script\u0026gt; 要注意的是，我们通常也可以直接获取、设置、移除某个元素节点上的属性，但是用方法获取比较好，并且获取的是原始值。例如，img 元素的 src 属性若直接获取得到的是计算后的绝对路径，而用 getAttribute() 方法获取得到的则是我们写在标签上的原始数据。\n\u0026lt;script\u0026gt; // 直接获取属性（绝对路径） console.log(img_obj.src); // 输出 file:///C:/Users/Administrator.USER-20141121ES/Desktop/html/123.png // 用方法获取（原始值） console.log(img_obj.getAttribute(\u0026quot;src\u0026quot;)); // 输出 123.png \u0026lt;/script\u0026gt; 所以，我们要获取元素的属性，务必用 getAttribute() 方法。\n内联 CSS 属性 每个 HTML 元素都有个 style 属性，可以用来插入针对该元素的内联 CSS 属性。\n\u0026lt;body\u0026gt; \u0026lt;div style=\u0026quot;width: 200px;height: 200px;background-color: #ccc;border: 5px dotted blue;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // 获取内联style属性 console.log(document.querySelector(\u0026quot;div\u0026quot;).style); // 输出 CSSStyleDeclaration {0: \u0026quot;width\u0026quot;, 1: \u0026quot;height\u0026quot;, 2: \u0026quot;background-color\u0026quot;...} \u0026lt;/script\u0026gt; 元素节点的 style 内联属性返回一个 CSSStyleDeclaration 对象，该对象仅包含该元素节点的内联 CSS 属性（不包含内部样式表、外部样式表中的 CSS 属性）。\n单个 CSS 属性操作 元素节点的内联 CSS 属性都是该元素的 style（CSSStyleDeclaration） 对象上的一个个属性，所以我们可以通过 style（CSSStyleDeclaration）对象来设置、获取、移除单个内联 CSS 属性。\n\u0026lt;body\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var div_style=document.querySelector(\u0026quot;div\u0026quot;).style; // 直接设置单个内联CSS属性 div_style.width=\u0026quot;200px\u0026quot;; div_style.height=\u0026quot;200px\u0026quot;; div_style.backgroundColor=\u0026quot;red\u0026quot;; // 直接获取单个内联CSS属性 console.log(div_style.width); //输出200px console.log(div_style.height); //输出200px console.log(div_style.backgroundColor); // 输出red // 直接移除单个内联CSS属性 div_style.width=\u0026quot;\u0026quot;; div_style.height=\u0026quot;\u0026quot;; div_style.backgroundColor=\u0026quot;\u0026quot;; \u0026lt;/script\u0026gt; 要注意的是，style（CSSStyleDeclaration） 对象的属性名并不包含 - 字符，比如 background-color 属性名是不存在的。这些包含横线的属性名需要转译，通常规则如下：\n// 写成驼峰体命名法 background-color ---\u0026gt; backgroundColor font-size ---\u0026gt; fontSize border-bottom ---\u0026gt; borderBottom margin-top ---\u0026gt; marginTop // 简写属性也可以 border ---\u0026gt; border margin ---\u0026gt; margin // 如果属性名为 javascript 关键字，则加前缀 float ---\u0026gt; cssFloat 如果我们觉得属性名转译不太方便的话，我们还可以通过 style（CSSStyleDeclaration） 对象上定义的方法来进行设置、获取、移除单个内联 CSS 属性的操作。\nsetProperty() getPropertyValue() removeProperty() exp:\n\u0026lt;body\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var div_style=document.querySelector(\u0026quot;div\u0026quot;).style; // 用方法设置单个内联CSS属性 div_style.setProperty(\u0026quot;width\u0026quot;,\u0026quot;200px\u0026quot;); div_style.setProperty(\u0026quot;height\u0026quot;,\u0026quot;200px\u0026quot;); div_style.setProperty(\u0026quot;background-color\u0026quot;,\u0026quot;red\u0026quot;); // 用方法获取单个内联CSS属性 console.log(div_style.getPropertyValue(\u0026quot;width\u0026quot;)); // 输出200px console.log(div_style.getPropertyValue(\u0026quot;height\u0026quot;)); // 输出200px console.log(div_style.getPropertyValue(\u0026quot;background-color\u0026quot;)); // 输出red // 用方法移除单个内联CSS属性 div_style.removeProperty(\u0026quot;width\u0026quot;); div_style.removeProperty(\u0026quot;height\u0026quot;); div_style.removeProperty(\u0026quot;backgroundColor\u0026quot;); \u0026lt;/script\u0026gt; 批量 CSS 属性操作 当我们需要批量操作内联 CSS 属性的时候，一个一个的进行未免太过麻烦，这里我们可以一次性改变所有内联 CSS 属性。\ncssText exp:\n\u0026lt;body\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var div_obj=document.querySelector(\u0026quot;div\u0026quot;); // 用内联style属性对象上的方法 // 设置所有内联CSS属性 div_obj.style.cssText=\u0026quot;width: 200px;height: 200px;background-color: #ccc\u0026quot;; // 获取所有内联CSS属性 console.log(div_obj.style.cssText); // 输出 width: 200px; height: 200px; background-color: rgb(204, 204, 204); // 移除所有内联CSS属性 div_obj.style.cssText=\u0026quot;\u0026quot;; // 用元素自身的方法 // 设置所有内联CSS属性 div_obj.setAttribute(\u0026quot;style\u0026quot;,\u0026quot;width: 200px;height: 200px;background-color: #ccc\u0026quot;); // 获取所有内联CSS属性 console.log(div_obj.getAttribute(\u0026quot;style\u0026quot;)); // 输出 width: 200px;height: 200px;background-color: #ccc; // 移除所有内联CSS属性 div_obj.removeAttribute(\u0026quot;style\u0026quot;); \u0026lt;/script\u0026gt; 计算后的 CSS 属性 我们其实最想得到的是元素内联 CSS 样式以及级联（内部样式表、外部样式表）CSS 样式计算后得到的最终样式，而不仅仅是未计算的内联样式。\ngetComputedStyle() exp:\n\u0026lt;style\u0026gt; div{ width: 200px; height: 200px; background-color: #ccc; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div style=\u0026quot;background-color: red;border: 1px solid blue;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var div_obj=document.querySelector(\u0026quot;div\u0026quot;); // 此为内部样式表中的CSS属性 console.log(window.getComputedStyle(div_obj).width); // 输出 200px console.log(window.getComputedStyle(div_obj).height); // 输出 200px // 内联CSS属性覆盖了内部样式表中的CSS属性 console.log(window.getComputedStyle(div_obj).backgroundColor); // 输出 rgb(255, 0, 0) // 此为内联CSS属性 console.log(window.getComputedStyle(div_obj).border); // 输出 1px solid rgb(0, 0, 255) \u0026lt;/script\u0026gt; getComputedStyle() 方法获取的是计算后的最终样式（包括内联样式、内部样式表、外部样式表），CSS 属性名注意要进行转译（例如，background-color =\u0026gt; backgroundColor）。\n利用 id 和 class 改变 CSS 样式 更多的时候，我们都是将 CSS 样式写在内部样式表或者外部样式表中的，这样做便于维护和替换。我们可以通过改变元素节点的内联 id 或 class 属性来批量替换 CSS 样式。\n\u0026lt;style\u0026gt; #a{ background-color: red; } .b1{ border:1px solid blue; } .b2{ width: 200px; height: 200px; background-color: yellow; margin: 0 auto; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;b1\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var div_obj=document.querySelector(\u0026quot;div\u0026quot;); // 添加ID，改变背景颜色 div_obj.setAttribute(\u0026quot;id\u0026quot;,\u0026quot;a\u0026quot;); // 获取ID console.log(div_obj.getAttribute(\u0026quot;id\u0026quot;)); // 输出 a // 去掉ID div_obj.removeAttribute(\u0026quot;id\u0026quot;); // 添加class,让DIV居中 div_obj.classList.add(\u0026quot;b2\u0026quot;); // 获取class console.log(div_obj.getAttribute(\u0026quot;class\u0026quot;)); // 输出 b1 b2 console.log(div_obj.classList); //输出 DOMTokenList [\u0026quot;b1\u0026quot;,\u0026quot;b2\u0026quot;] // 删减class的一部分，去掉边框 div_obj.classList.remove(\u0026quot;b1\u0026quot;); // 再次获取class console.log(div_obj.getAttribute(\u0026quot;class\u0026quot;)); // 输出 b2 console.log(div_obj.classList); //输出 DOMTokenList [\u0026quot;b2\u0026quot;] \u0026lt;/script\u0026gt; 要特别注意的是，通过改变 id 或 class 属性值更改的是内部样式表、外部样式表中的 CSS 样式属性，要比内联 CSS 样式属性的优先级低。\n结语 其实要进行批量的改变 CSS 样式，我们完全可以替换元素的 id 和 class 属性（CSS 选择器），这样既方便还可以重复利用样式，这也是我们常用的方式。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/css/css-clear-float/","title":"CSS 清除浮动","description":"在浮动布局中，有时候会因为父元素没有设置高度而子元素浮动导致父元素坍塌，我们就需要清除浮动撑起父元素的高度，在这里总结一下常用方法。","date":"May 21, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, CSS,  Float","tags":"","content":"在浮动布局中，有时候会因为父元素没有设置高度而子元素浮动导致父元素坍塌，我们就需要清除浮动撑起父元素的高度，在这里总结一下常用方法。\n浮动 我们通常为了将块级（block）子元素水平排列，就将其浮动（float: left|right）起来而达到我们的目的，当然这会带来一些问题。所以，我们应尽可能清除浮动所带来的副作用，以免影响其它元素的布局。\n\u0026lt;style\u0026gt; #container{ background-color: grey; } .inner { margin: 15px; width: 200px; height: 200px; background-color: blue; float: left; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt;1\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt;2\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt;3\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; 此时，我们并看不到外层 div 的灰色背景，打开调试工具会发现外层 div 的 height: 0。当我们没有设置父元素高度，恰巧所有子元素浮动时，父元素的高度会成为 0，而没有被子元素撑起来。这是因为，子元素浮动之后脱离了文档流。\n清除浮动 清除浮动的方法很多，灵活性很大，通常我们只用一两种，但是都了解一下还是应该的。\n添加块级子元素 我们知道，当所有子元素浮动之后，我们继续在后面添加一个不浮动的块级（block）子元素，浮动的子元素会漂浮在该元素上方。\n\u0026lt;div id=\u0026quot;container\u0026quot;\u0026gt; ... \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt;3\u0026lt;/div\u0026gt; \u0026lt;div style=\u0026quot;clear:both;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 在所有浮动子元素尾部添加一个块级元素并清除浮动，我们会发现父元素被撑高了，而且此元素也没有影响页面布局的副作用。该方法的原理是：该元素由于设置了清除浮动，不允许有浮动元素漂浮在自己上方，所以该元素自然就排在了所有浮动元素之后，而该元素高为 0 相当于隐藏，因此也不会产生影响其它元素。\n但是，该方法是不推荐的，因为添加一个没有表现内容的标签会显得页面代码复杂化，所以我们应该选择更好的方法。\n父元素 overflow: auto 我们也可以从父元素着手来解决浮动问题，当然这也不是个最佳方法。\n\u0026lt;style\u0026gt; #container { overflow: auto; zoom: 1; /* IE兼容 */ } \u0026lt;/style\u0026gt; **我们可以通过给父元素设置 overflow: atuo;zoom: 1; 来达到清除浮动的目的。**后者是为了低版本的 IE 兼容性而设置的。\n此方法实际上也是不推荐的，简单的来说我们并不能确保父元素不会产生滚动条从而影响页面美观性。\n伪元素 :after 接下来要说的就是一种推荐的做法了，这个方法被大多数人采用。\n\u0026lt;style\u0026gt; #container { zoom: 1; /* IE兼容 */ } #container:after { clear: both; /* 清除浮动 */ content: ''; /* 伪元素默认属性 */ height: 0; /* 保证不显示 */ display: block; /* 确保为块元素 */ visibility: hidden; /* 确保渲染但不显示 */ } \u0026lt;/style\u0026gt; 该方法事实上是对上面两个方法的综合，伪元素不是实际的 DOM 元素，这是其优势。该方法是最为优雅的清除浮动的方法，我们应该尽可能的采用该方法来清除浮动，不过还是应该视情况而定。\n双伪元素 随着浏览器的更新，标准的统一和兼容，可以使用更简洁的双伪元素法清除浮动，它与上面的原理相同。\n\u0026lt;style\u0026gt; #container:before, #container:after { content:\u0026quot;\u0026quot;; display:table; } #container:after { clear:both; } #container { zoom:1; } \u0026lt;/style\u0026gt; 这里的 :before 伪元素并不是用来清除浮动的，而是解决垂直方向上 margin 重叠问题。\n其他方法 在实际开发过程中，我们发现并不是只有以上三种方法会产生清除浮动的效果，而其他某些时候也会产生该效果，下面就简单的列举一下。\n父元素也浮动时； 父元素为 position: absolute 时； 父元素为 display: table 时。 以上这些均是一些副作用产生了清除浮动的效果，不应该作为清除浮动的目的来使用，因为这样会产生一些其他问题。\n结语 也许，CSS 清除浮动的方法不止这些，不过我们只是单纯的为了清除浮动，采取最优雅的方法即可。其实，直接定义父元素的高度也相当于清除了浮动的副作用。\n"},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-rule/","title":"DOM-元素节点几何量","description":"当我们在查看 HTML 文档时，每个元素节点被解析后，都画成了可视形状。我们可以获取每个元素节点的几何量（宽、高、偏移量）以及页面滚动距离。","date":"May 19, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, Rule","tags":"","content":"当我们在查看 HTML 文档时，每个元素节点被解析后，都画成了可视形状。我们可以获取每个元素节点的几何量（宽、高、偏移量）以及页面滚动距离。\n元素节点几何量 通常我们将一个元素抽象成一个盒子模型，具有 content（内容）、padding（填充、内边距）、border（边框）、margin（外边距）这些尺寸属性。\n定位偏移量 使用元素节点的 offsetTop 与 offsetLeft 属性，我们可以分别获取该元素节点顶部与左侧外边框相对于 offsetParent 的顶部与左侧内边框的偏移像素量。\noffsetParent offsetTop offsetLeft 一个元素节点的 offsetParent 判定依据为查找**距离该元素节点最近的 CSS 定位（position）值不为 static（默认值）的祖先元素，**直至 body 元素为止。如果在查询过程中，找到 td、th、table 元素之一，且它的定位值为 static，则将它作为 offsetParent。\n\u0026lt;style\u0026gt; #out{ width: 200px; height: 200px; background-color: #ccc; border: 5px solid yellow; padding: 10px; margin: 15px; position: relative; } #in{ width: 100px; height: 100px; background-color: red; border: 3px solid blue; padding: 6px; margin: 9px; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026quot;out\u0026quot;\u0026gt; \u0026lt;div id=\u0026quot;in\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 查看内部DIV的offsetParent console.log(document.querySelector(\u0026quot;#in\u0026quot;).offsetParent); // 输出\u0026lt;div id=\u0026quot;out\u0026quot;\u0026gt;...\u0026lt;/div\u0026gt; // 这是因为外部DIV的position=\u0026quot;relative/absolute\u0026quot; // 验证内部DIV的offsetTop与offsetParent的值 console.log(document.querySelector(\u0026quot;#in\u0026quot;).offsetTop); // 输出19 console.log(document.querySelector(\u0026quot;#in\u0026quot;).offsetLeft); // 输出19 \u0026lt;/script\u0026gt; 上述示例可以看出，符合外边框到 offsetParent 内边框的计算方式。通俗的说就是，我们将一个小盒子放到一个大盒子中，小盒子外侧到大盒子内侧的距离就是我们要计算的值。\n盒子属性 在可视区（浏览器 HTML 文档显示区，不包含浏览器导航、地址栏等）内，我们可以通过 getBoundingClientRect() 方法获取某个元素的矩形盒子基本属性。\ngetBoundingClientRect() exp：\n\u0026lt;style\u0026gt; body{ border: 0px; padding: 0px; margin: 0px; } div{ width: 200px; height: 200px; background-color: #ccc; border: 10px solid yellow; padding: 30px; margin: 50px; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取DIV的矩形盒子基本属性 console.log(document.querySelector(\u0026quot;div\u0026quot;).getBoundingClientRect()); // 输出ClientRect{top: 50, right: 330, bottom: 330, left: 50, width: 280, height: 280} // 可以单独获得某项基本属性 console.log(document.querySelector(\u0026quot;div\u0026quot;).getBoundingClientRect().top); // 输出50 \u0026lt;/script\u0026gt; 上述示例可以看出，top、bottom、left、right 属性表示该元素矩形的上、下、左、右外边框相对于浏览器可视区上、下、左、右边沿的偏移像素量。通俗的说就是，在存放快递盒子的仓库中，每个盒子四周外侧到仓库四周墙壁的距离就是我们要计算的值。\nwidth 与 height 属性表示该元素矩形的可视尺寸（宽、高），不包括 margin（外边距）。\n盒子尺寸 我们可以通过一些属性获取可视区（浏览器 HTML 文档显示区，不包含浏览器导航、地址栏等）内元素矩形的尺寸。\noffsetWidth offsetHeight clientWidth clientHeight exp：\n\u0026lt;style\u0026gt; div{ width: 200px; height: 200px; background-color: #ccc; border: 10px solid yellow; padding: 30px; margin: 50px; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取DIV的矩形盒子尺寸 console.log(document.querySelector(\u0026quot;div\u0026quot;).offsetWidth); // 输出280 console.log(document.querySelector(\u0026quot;div\u0026quot;).offsetHeight); // 输出280 console.log(document.querySelector(\u0026quot;div\u0026quot;).clientWidth); // 输出260 console.log(document.querySelector(\u0026quot;div\u0026quot;).clientHeight); // 输出260 \u0026lt;/script\u0026gt; 上述示例可以看出，offsetWidth 与 offsetHeight 属性表示的是元素矩形的可视尺寸（宽、高），不包括 margin（外边距）。\n但是，clientWidth 与 clientHeight 属性表示的是元素矩形的有效尺寸（宽、高），不包括 margin（外边距）、border（边框）。\n获取特定点上最顶层元素节点 我们可以使用 elementFromPoint() 方法获取可视区（浏览器 HTML 文档显示区，不包含浏览器导航、地址栏等）内，特定点上最顶层元素节点的引用。\nelementFromPoint() exp：\n\u0026lt;script\u0026gt; // 获取文档可视区内left=50，top=50处最顶层元素节点 console.log(document.elementFromPoint(50,50)); \u0026lt;/script\u0026gt; 如果没有设置 z 轴索引值 z-index，则最顶层元素节点就是 HTML 文档中该点上最后被解析的元素节点。\n滚动几何量 当 HTML 文档太大（页面元素太多）时，或者当某个元素节点内内容太多时，会出现左右滚动条。此时，我们可能需要知道该元素节点的滚动区域、滚动距离等等。\n滚动尺寸 我们可以通过以下属性来获取 HTML 页面或者某个元素节点的滚动尺寸（总高、总宽）。\nscrollWidth scrollHeight exp：\n\u0026lt;style\u0026gt; div{ width: 200px; height: 200px; background-color: #ccc; overflow: auto; } p{ width: 1000px; height: 10000px; margin: 0px; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取DIV的滚动尺寸 console.log(document.querySelector(\u0026quot;div\u0026quot;).scrollWidth); // 输出1000 console.log(document.querySelector(\u0026quot;div\u0026quot;).scrollHeight); // 输出1000 \u0026lt;/script\u0026gt; 当滚动条未出现（滚动区域\u0026lt;元素尺寸）时，这两个属性将返回 clientWidth 与 clientHeight 属性的值，也就是有效尺寸。\n滚动距离 通常页内导航可以将视区跳转到页内某个区域内，或者当页面向下滚动时才继续加载图片等等。这些功能的实现都要获取（设置）所滚动的距离。\nscrollLeft scrollTop exp：\n\u0026lt;style\u0026gt; p{ width: 10000px; height: 10000px; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 利用事件将窗口滚动距离显示在标题上 window.onscroll=function(){ scroll_left=document.body.scrollLeft || document.documentElement.scrollLeft; scroll_top=document.body.scrollTop || document.documentElement.scrollTop; document.title=scroll_left+\u0026quot;,\u0026quot;+scroll_top; } \u0026lt;/script\u0026gt; 如果我们想让页面滚动到某一处，直接给 scrollLeft 和 scrollTop 属性赋值即可。\n滚动元素节点到视区内 页内导航通常也可以根据选取特定元素，将视区跳转到该元素节点上来实现，这样实现的方式是最科学的。\nscrollIntoView() exp：\n\u0026lt;style\u0026gt; button{ margin: 10px; } p{ height: 1000px; background-color: #ccc; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button\u0026gt;跳转到第一段\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;跳转到第二段\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;跳转到第三段\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;跳转到第四段\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;跳转到第五段\u0026lt;/button\u0026gt; \u0026lt;p id=\u0026quot;p1\u0026quot;\u0026gt;第一段\u0026lt;/p\u0026gt; \u0026lt;p id=\u0026quot;p2\u0026quot;\u0026gt;第二段\u0026lt;/p\u0026gt; \u0026lt;p id=\u0026quot;p3\u0026quot;\u0026gt;第三段\u0026lt;/p\u0026gt; \u0026lt;p id=\u0026quot;p4\u0026quot;\u0026gt;第四段\u0026lt;/p\u0026gt; \u0026lt;p id=\u0026quot;p5\u0026quot;\u0026gt;第五段\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取按钮集合并转换为数组 var buttons=document.getElementsByTagName(\u0026quot;button\u0026quot;); buttons=Array.prototype.slice.call(buttons); // 利用事件实现按钮跳转 for (var i = buttons.length - 1; i \u0026gt;= 0; i--) { buttons[i].onclick=function(){ var index=buttons.indexOf(this)+1; document.querySelector(\u0026quot;#p\u0026quot;+index).scrollIntoView(); } } \u0026lt;/script\u0026gt; 结语 元素节点的几何量（尺寸、定位偏移量），页面元素的滚动距离等等都是我们经常使用的值，所以清楚的了解什么属性、方法获取什么值是非常有必要的。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-sublime/","title":"编辑器：Sublime Text 常用插件","description":"Sumblime Text 是一个具有漂亮的界面和强大功能的文本编辑器，而且也支持许多丰富的插件。它是一个收费软件，但是允许开发人员无限期的免费试用。这篇文章介绍一下常用的插件。","date":"May 19, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 工具, 编辑器, Sublime Text","tags":"","content":"Sumblime Text 是一个具有漂亮的界面和强大功能的文本编辑器，而且也支持许多丰富的插件。它是一个收费软件，但是允许开发人员无限期的免费试用。这篇文章介绍一下常用的插件。\n安装 Sublime Text Sublime Text 编辑器，我们直接去官网下载相应版本安装即可，2 或 3 版本官网均有链接。\n**Sublime Text：**http://www.sublimetext.com/\n必备插件 Package Control Package Control 插件是一个方便 Sublime Text 管理插件的插件，所以要安装其他插件之前，应该先安装它。\n**Package Control：**https://packagecontrol.io/installation\n进入以上网站，按照其说明的两种方法即可安装该插件。在这里说一下最简单的方法：打开 Sublime Text 按Ctrl + ~键进入控制台，然后复制网站中相应版本的代码到控制台，按回车执行即可，看左下角状态栏显示安装成功信息，重启 Sublime Text。\n注意该插件网站上有许多其他插件的详细介绍和安装方法哟。\n插件安装方法 以后我们通过该插件来管理其他插件的安装，其他插件的安装方式也有两种：在线安装、本地安装。我们通常采用简单快捷的方式，即在线安装。\n在线安装 打开 Sublime Text 按Ctrl + Shift + P键出现输入框后输入 install package 命令按回车，等待一会之后输入框又会出现，此时即可输入相应插件名字，选择好后按回车，查看左下角状态栏信息，即可安装成功。\n本地安装 我们事先从网站上将插件的源文件下载到本地，然后打开 Sublime Text 选择工具栏中 Preferences -\u0026gt; Browse Packages 会自动打开一个文件夹，我们将下载的插件源文件拷进该文件夹中，重启 Sublime Text 即可。\n常用插件 下面，将会介绍一些在 Sublime Text 使用过程中比较常用的简单插件，安装方法不再重复，查看前面即可。\nIMESupport 让人郁闷的是，在 Sublime Text 中输入法的输入框不能跟随光标，总是在屏幕的某个角上，这样打字的时候感觉很不习惯。IMESupport 这个小插件就是为了解决这个问题而诞生，它的作者是一位日本人。\n**IMESupport：**https://github.com/chikatoike/IMESupport\n该插件安装成功后，不用重启 Sublime Text 即可看到效果。\nEmmet 该插件的前身为 Zen coding ，改名为 Emmet 后也带来了许多新特性，对于从事前端开发的朋友来说是很强大的。该插件可以实现代码自动完成、语法提示、支持 CSS 语法选择器代码生成、批量操作等等。\n**Emmet：**http://docs.emmet.io/\n需要注意的是，该插件体积比较大，在进行安装的时候要注意左下角状态栏信息，等待 PyV8（必备，自动下载） 成功安装之后该插件方可生效。\n**PyV8：**https://github.com/emmetio/pyv8-binaries\nColor Highlighter 这款插件可以让我们设置的 CSS 样式颜色可视化，从而帮助我们更好的掌握页面颜色的布局。\n**Color Highlighter：**https://packagecontrol.io/packages/Color%20Highlighter\nSyncedSideBarBg 该插件可以让 Sublime Text 的侧边栏，也就是文件夹目录的背景色与主题同步，默认是灰白色的不太好看。侧边栏可以按Ctrl + K + B键唤出。\n**SyncedSideBarBg：**https://packagecontrol.io/packages/SyncedSideBar\nJsFormat JsFormat 插件可以一键格式化对齐我们的 JavaScript 代码，让凌乱的代码瞬间变得整齐起来，可读性大大提高。\n**JsFormat：**https://packagecontrol.io/packages/JsFormat\n安装好之后，任意打开一个 js 文件，按Ctrl + Alt + F即可格式化代码看到效果。\nA File Icon A File Icon 插件可以美化侧边栏文件的图表，文件分类的视觉效果更加直观。\n**A File Icon：**https://packagecontrol.io/packages/A%20File%20Icon\n"},{"section":"Blog","slug":"/blog/computer-technology/tools/tools-sublime-vim/","title":"编辑器：Sublime Text - Vim 插件","description":"Sumblime Text 是一个具有漂亮的界面和强大功能的文本编辑器，而且也支持许多丰富的插件。它是一个收费软件，但是允许开发人员无限期的免费试用。","date":"May 18, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"","tags":"计算机技术, 工具, 编辑器, Sublime Text, 插件, Vim","content":"Sumblime Text 是一个具有漂亮的界面和强大功能的文本编辑器，而且也支持许多丰富的插件。它是一个收费软件，但是允许开发人员无限期的免费试用。\nVim Vim 是 Linux 操作系统下类 Vi 编辑器，是一款被开发者广泛使用，并且功能强大的文本编辑器。而 Sublime Text 最初的设计初衷也是基于 Vim 的设计思想，被设计为一个跨平台的具有丰富扩展功能的 Vim。随着后来的发展，它已经不仅仅是单纯的模仿 Vim，而是支持越来越多的插件和强大的功能。\nVim 插件在目前的新版本中都是默认没有安装的，但是有了 Vim 插件我们可以像在 Linux 操作系统下使用 Vim 一样使用 Sublime Text，这样我们的开发效率会大大提升。下面我们就来看看如何在 Sublime Text 3 中安装 Vim 插件，并且了解一下 Vim 插件的常用功能。\nVim 插件安装 首先，我们要安装好 Sublime Text 3 和 Package Control 插件。\n**Sublime Text：**http://www.sublimetext.com/ \u0026gt; **Package Control：**https://packagecontrol.io/installation\n然后，我们安装 Vim 插件，这里有两种方法：在线安装和本地安装。\n在线安装 打开 Sublime Text 3，Ctrl+Shift+P打开命令行，输入 Install Package 回车，等一会之后命令行再次出现，输入 vintageous 回车。\n本地安装 先下载 Vim 插件文件：\n**Vintageous：**https://packagecontrol.io/packages/Vintageous\n打开 Sublime Text 3，在菜单中选择 Preferences-\u0026gt;Browse Packages，将下载好的 Vim 插件文件夹拷进打开的文件夹，关闭文件夹。\n用户配置 打开 Sublime Text 3，在菜单 Preferences 下选择 Settings-User，也就是用户设置。我们可以找到以下这句：\n\u0026quot;ignored_packages\u0026quot;: [\u0026quot;Vintage\u0026quot;] 这句代码的意思就是，Sublime 默认是关闭 Vim 插件的。我们将其改为：\n\u0026quot;ignored_packages\u0026quot;: [] 然后，保存退出，关闭 Sublime Text 3 重启即可。\nVim 插件使用 Vim 插件会有三个模式：插入模式（INSERT MODE）、命令模式（COMMAND MODE）、行末模式。\n插入模式 插入模式也就是编辑模式，我们写代码的时候用的模式。此模式下可以输入代码，和普通的编辑器一样，按键盘左上角Esc即可进入命令模式。\n命令模令 命令模式提供便捷强大的快捷键，是 Vim 插件的核心模式。此模式下，进入插入模式有八种方式：\ni // 光标前插入 a // 光标后插入 s // 替换插入（删除当前光标所在字符） Shitf+I // 行首插入（光标所在行） Shift+A // 行尾插入（光标所在行） Shift+S // 行替换插入（删除光标所在行） o // 下一行插入（光标所在行下添加一行） Shift+O // 上一行插入（光标所在行上添加一行） 然后，命令模式下进入行末模式的方式是：Shift+;，也就是冒号。\n######### 常用快捷键\n命令模式下还有许多便捷而强大的快捷键，下面来了解一下。\n光标移动\nh // 光标左移 j // 光标下移 k // 光标上移 l // 光标右移 gg // 光标移动到文档开头 Shift+G // 光标移动到文档结尾 复制、粘贴、剪切/删除、撤销/恢复（批量操作）\nyy // 复制光标所在整行 2+yy // 复制光标所在行开始向下2（n）行 p // 光标所在行下方添加一行并粘贴 2+p // 光标所在行下方添加2（n）行并粘贴 Shitf+P // 光标所在行上方添加一行并粘贴 dd // 删除、剪切光标所在整行 2+dd // 删除、剪切光标所在行开始向下2（n）行 u // 撤销 Ctrl+Y // 恢复 r // 替换光标所在字符 其他删除/剪切方式\nd+gg // 光标所在行到文档开头之间全部删除、剪切 d+Shift+G // 光标所在行到文档结尾之间全部删除、剪切 d+2+gg // 光标所在行到第2（n）行之间全部删除、剪切 d+2+Shift+G // 同上 d+^ // 光标所在字符到行首之间全部删除、剪切 d+$ // 光标所在字符到行尾之间全部删除、剪切 Shift+D // 同上 d+w // 删除光标所在处一个单词、符号 x // 删除光标所在字符 2+x // 删除光标所在字符开始向后2（n）个字符 行末模式 行末模式也就是通常我们所说的菜单栏，提供文件保存等操作。\nw // 保存当前文档 x // 保存文档并关闭 结语 Vim 插件有三种模式，但是不能互相切换，命令模式是其切换枢纽。三者切换关系如下：\n插入模式\u0026lt;\u0026mdash;\u0026gt;命令模式\u0026lt;\u0026mdash;\u0026gt;行末模式\n为了方便、安全，我们通常将其初始化模式设置为 命令模式，方式：打开 Sublime Text 3，在菜单 Preferences 下选择 Settings-User，也就是用户设置；添加下面这句：\n\u0026quot;vintage_start_in_command_mode\u0026quot;: true "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-nodelist/","title":"DOM-节点集合","description":"当从文档树中选取成组的节点或者使用预定义的节点集合时，这些节点都是放在 NodeList 或者一个 HTMLCollecton 之中，而不是一个数组（Array）中。","date":"May 17, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, NodeList","tags":"","content":"当从文档树中选取成组的节点或者使用预定义的节点集合时，这些节点都是放在 NodeList 或者一个 HTMLCollecton 之中，而不是一个数组（Array）中。\n节点集合 我们将一个 NodeList 或者 HTMLCollecton 称为节点集合，也就是类数组的节点对象集合。节点集合一般有以下特征：\n实时或静态\n这意味着在集合中包含的节点对象们或是实时文档树的某一部分，或是某一实时文档树的快照。\n顺序一致性\n默认情况下，集合中的节点对象以其所在 DOM 树中的顺序排序，这就意味着这个顺序与从树到分支的线性路径吻合。\nlength 属性\n我们可以通过其 length 属性获取该节点集合中的节点数目。\n注意，NodeList 与 HTMLCollection 都是实时列表。\n获取所有直属子节点 利用节点对象身上的 childNodes 属性会获取一个类数组的包含直属（第一代）子节点的列表，也就是 NodeList。\n\u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello,World!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 输出\u0026lt;body\u0026gt;元素节点的所有直属子节点集合 console.log(document.body.childNodes); // 输出为 [text, p, text, script] \u0026lt;/script\u0026gt; 要注意的是，它并不是一个纯数组，而是类数组的集合。为什么有两个子节点是文本（Text）节点，是因为 \u0026lt;p\u0026gt; 标签前后都有回车符和空格。\nchildNodes 属性返回的 NodeList 仅包含直属子节点；而且不仅包含元素（Element）节点，还包含其他所有类型节点，例如文本（Text）节点、注释（Comment）节点。\n获取所有元素节点集合 对于一个元素节点对象，我们可以利用其 children 属性获取其所有的 直属子元素节点。而且还有以下几个文档对象属性可以获取预定义的元素节点集合：\ndocument.all\n获取 HTML 文档中所有元素节点的集合。\ndocument.forms\n获取 HTML 文档中所有（from）元素。\ndocument.images\n获取 HTML 文档中所有（img）元素。\ndocument.links\n获取 HTML 文档中所有（a）元素。\ndocument.scripts\n获取 HTML 文档中所有（script）元素。\ndocument.styleSheets\n获取 HTML 文档中所有（link、style）元素。\n以上类数组列表中，document.all 构建自 HTMLAllCollection；styleSheets 构建自 StyleSheetList；其他的均构建自 HTMLCollection。\n将节点集合转换成数组 节点集合（NodeList 与 HTMLCollection）都是类数组，但并不是真正的数组，后者继承数组的方法。我们做以验证：\n\u0026lt;body\u0026gt; \u0026lt;a href=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // 验证 NodeList console.log(Array.isArray(document.body.childNodes)); // 输出false // 验证 HTMLCollection console.log(Array.isArray(document.links)); // 输出false \u0026lt;/script\u0026gt; 如何将一个类数组列表转换成真正的 javascript 数组？\n我们只需要将类数组列表传给 call() 或者 apply()，在它们中调用一个数组方法，它们就会返回一个未经修改的真正的 javascript 数组。\n\u0026lt;body\u0026gt; \u0026lt;a href=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // NodeList 转换成数组并验证 console.log(Array.isArray(Array.prototype.slice.call(document.body.childNodes))); // 输出true // HTMLCollection 转换成数组并验证 console.log(Array.isArray(Array.prototype.slice.call(document.links))); // 输出true \u0026lt;/script\u0026gt; 将其转换为真正的 javascript 数组有以下好处：\n获取快照\nNodeList、HTMLCollection 都是实时列表，这么做使我们能够获取该列表的快照，不与实时 DOM 绑定。\n方便操作\n转换成数组之后，我们可以使用数组的方法，例如 forEach、pop、map、reduce 等。\n结语 其实节点集合我们通常可能不太关注，我们大多数时候关注的都是单个节点。但是，在某些需要批量操作的场景，这时候节点集合倒是不错的选择。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-select/","title":"DOM-选取元素节点","description":"DOM 操作都是通过对文档树中节点的访问来实现的，如何选取特定的元素节点是关键，进而才能访问该元素节点实现修改、查看、移除、替换等操作。","date":"May 17, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, Selector","tags":"","content":"DOM 操作都是通过对文档树中节点的访问来实现的，如何选取特定的元素节点是关键，进而才能访问该元素节点实现修改、查看、移除、替换等操作。\n选取特定单一元素节点 取得某一特定单一元素节点的引用最常用的方式如下：\nquerySelector() getElementById() exp：\n\u0026lt;body\u0026gt; \u0026lt;ul id=\u0026quot;animal\u0026quot;\u0026gt; \u0026lt;li\tid=\u0026quot;Dog\u0026quot;\u0026gt;Dog\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026quot;Cat\u0026quot;\u0026gt;Cat\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026quot;Pig\u0026quot;\u0026gt;Pig\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // querySecletor()方法可通过多种途径获取第一个\u0026lt;li\u0026gt; console.log(document.querySelector(\u0026quot;li\u0026quot;)); console.log(document.querySelector(\u0026quot;ul\u0026gt;li\u0026quot;)); console.log(document.querySelector(\u0026quot;#Dog\u0026quot;)); console.log(document.querySelector(\u0026quot;#animal\u0026gt;#Dog\u0026quot;)); // getElementById()通过ID属性获取 console.log(document.getElementById(\u0026quot;Dog\u0026quot;)); \u0026lt;/script\u0026gt; getElementById() 方法仅能通过节点的 id 属性获取目标节点的引用；而 querySelector() 方法更强大，它可以接受一个 CSS 选择器语法格式（例如 ul \u0026gt; li）的参数，而且它只会返回第一个符合条件的节点的引用。\n选取特定元素节点集合 取得某一特定元素节点集合最常用的方式如下：\nquerySelectorAll() getElementsByTagName() getElementsByClassName() getElementsByName() exp：\n\u0026lt;body\u0026gt; \u0026lt;ul id=\u0026quot;animals\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;animal\u0026quot;\u0026gt;Dog\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;animal\u0026quot;\u0026gt;Cat\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;animal\u0026quot;\u0026gt;Pig\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // querySecletorAll()方法可通过多种途径获取第三个\u0026lt;li\u0026gt;集合 console.log(document.querySelectorAll(\u0026quot;li\u0026quot;)); console.log(document.querySelectorAll(\u0026quot;ul\u0026gt;li\u0026quot;)); console.log(document.querySelectorAll(\u0026quot;#animals\u0026gt;.animal\u0026quot;)); // getElementsByTagName()通过标签名称获取 console.log(document.getElementsByTagName(\u0026quot;li\u0026quot;)); // getElementsByClassName()通过class属性获取 console.log(document.getElementsByClassName(\u0026quot;animal\u0026quot;)); \u0026lt;/script\u0026gt; 同样地，querySelectorAll() 方法更强大一些，它可以接受一个 CSS 选择器语法格式（例如 ul \u0026gt; li）的参数。getElementsByName() 方法可以通过节点的 name 属性获取特定节点集合的引用，但是它并不常用。\nquerySelectorAll() 方法获取的节点集合是静态的，也就是说是非实时的，它只是创建该节点集合时文档的快照；而其他的方法获取的节点集合都是实时的，会及时反映文档的当前状态。\n选取所有的直属子元素节点 使用元素节点上的 children 属性，我们可以获取该元素节点的所有直属（第一代）子元素节点。\n\u0026lt;body\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Dog\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Cat\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Pig\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取\u0026lt;ul\u0026gt;元素内的所有\u0026lt;li\u0026gt;子元素 console.log(document.querySelector(\u0026quot;ul\u0026quot;).children); \u0026lt;/script\u0026gt; 获取的该节点集合是实时的，文档中任何改动都将会动态反映到集合中。\n选取与上下文有关的元素节点 虽然 querySelector()、querySelectorAll()、getElementsByTagName()、getElementsByClassName() 这些方法一般都通过 document 对象访问，其实在元素节点上也有定义。这样我们可以将这些方法的查找范围缩小到文档树中某一特定分支（或者分支集）。\n\u0026lt;body\u0026gt; \u0026lt;ul id=\u0026quot;fruits\u0026quot;\u0026gt; \u0026lt;li\u0026gt;Apple\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Banana\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Pear\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul id=\u0026quot;animals\u0026quot;\u0026gt; \u0026lt;li\u0026gt;Dog\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Cat\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Pig\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取第二个\u0026lt;ul\u0026gt;元素中的所有\u0026lt;li\u0026gt;子元素 console.log(document.querySelectorAll(\u0026quot;#animals\u0026gt;li\u0026quot;)); // 这样也可以 var li_animals=document.querySelector(\u0026quot;#animals\u0026quot;); console.log(li_animals.querySelectorAll(\u0026quot;li\u0026quot;)); \u0026lt;/script\u0026gt; 预定义的元素节点选取 有一些很方便的预定义的元素集合，如下所示：\ndocument.all\n获取 HTML 文档中所有元素节点的集合。\ndocument.forms\n获取 HTML 文档中所有（from）元素。\ndocument.images\n获取 HTML 文档中所有（img）元素。\ndocument.links\n获取 HTML 文档中所有（a）元素。\ndocument.scripts\n获取 HTML 文档中所有（script）元素。\ndocument.styleSheets\n获取 HTML 文档中所有（link、style）元素。\n以上类数组列表中，document.all 构建自 HTMLAllCollection；styleSheets 构建自 StyleSheetList；其他的均构建自 HTMLCollection，并且都是实时的。\n验证特定元素节点 使用 matchesSelector() 方法，我们可以判断一个元素是否匹配某个选择器字符串。但是该方法在不同内核的浏览器中实现不一样，分别加了前缀：\nmozMatchesSelector() webkitMatchesSelector() msMatchesSelector() oMatchesSelector() exp：\n\u0026lt;body\u0026gt; \u0026lt;ul id=\u0026quot;fruits\u0026quot;\u0026gt; \u0026lt;li\u0026gt;Apple\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Banana\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Pear\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul id=\u0026quot;animals\u0026quot;\u0026gt; \u0026lt;li id=\u0026quot;Dog\u0026quot;\u0026gt;Dog\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Cat\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Pig\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 验证id为Dog的\u0026lt;li\u0026gt;元素是否是第二个\u0026lt;ul\u0026gt;元素的子元素节点 var a=document.querySelector(\u0026quot;#Dog\u0026quot;).webkitMatchesSelector(\u0026quot;#animals\u0026gt;li\u0026quot;); console.log(a); // 输出true \u0026lt;/script\u0026gt; 结语 querySelector() 与 querySelectorAll() 方法相对来说要功能强大一些，但要特别注意的是后者获取的节点集合不是实时的。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-elementnode/","title":"DOM-元素节点","description":"可以说，元素节点是 DOM 树中的核心部分，我们进行文档的操作通常都是建立在元素节点上的。","date":"May 17, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, Element Node","tags":"","content":"可以说，元素节点是 DOM 树中的核心部分，我们进行文档的操作通常都是建立在元素节点上的。\n元素节点 元素节点（Element Node）是我们最常用的 DOM 节点，不同类型的节点都有其自己的构造方法，并且它们身上还有许多属性和方法（包括继承的）来帮助我们完成 DOM 操作。\n\u0026lt;body\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; console.log(document.querySelector('div').constructor); // 输出 function HTMLDivElement() { [native code] } \u0026lt;/script\u0026gt; DOM 中每一个元素节点都是从唯一的 Javascript 接口/构造器构建的。对于任何节点（不仅是元素节点），我们可以通过 constructor 属性来获知它们的构造方法。\n元素节点 DOM 操作 前面在介绍 DOM 时元素节点（Element Node）的部分属性与方法已做过示例，在此仅简单的提及。\n创建节点 document.createElement() exp：\n\u0026lt;script\u0026gt; // 创建一个DIV节点 var new_div=document.createElement('div'); \u0026lt;/script\u0026gt; 获取标签名 tagName nodeName exp：\n\u0026lt;script\u0026gt; // 获取DIV元素的标签名 console.log(document.querySelector('div').tagName); // 输出 \u0026quot;DIV\u0026quot; console.log(document.querySelector('div').nodeName); // 输出 \u0026quot;DIV\u0026quot; \u0026lt;/script\u0026gt; 获取属性列表/集合 每个元素节点身上都有很多属性（包括继承自 Node），我们可以取得一个由当前元素定义的 Attr（属性）节点组成的集合。\nattributes exp：\n\u0026lt;body\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;id\u0026quot; class=\u0026quot;class\u0026quot; title=\u0026quot;input\u0026quot; data-foo=\u0026quot;dataFoo\u0026quot; value=\u0026quot;123\u0026quot;/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取属性列表/集合 var attr=document.querySelector('input').attributes; console.log(attr); // 输出 NamedNodeMap{...} // 遍历取得属性名与值 for (var i in attr) { console.log(attr[i].nodeName+':'+attr[i].nodeValue); } \u0026lt;/script\u0026gt; 我们使用元素节点的 attributes 属性获取的是一个包含其所有属性与相应值的属性节点对象集合（NamedNodeMap），因为每一个属性事实上也是一个属性节点对象（Attr 节点）。我们要知道的是，NamedNodeMap 是一个实时数组，会随元素节点属性的变化而变化。\n属性操作 setAttribute() getAttribute() removeAttribute() exp：\n\u0026lt;script\u0026gt; // 设置属性 document.querySelector('img').setAttribute('src','123.png'); // 获取属性 console.log(document.querySelector('img').getAttribute('src')); // 输出 123.png // 移除属性 document.querySelector('img').removeAttribute('src'); \u0026lt;/script\u0026gt; 属性检测 有时候，我们可能想知道一个元素节点身上是否有某个特定属性时，我们也可以通过下面的方法获知。\nhasAttributes exp：\n\u0026lt;body\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; title=\u0026quot;\u0026quot; checked\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // 查看input元素是否有title属性 console.log(document.querySelector('input').hasAttribute('title')); // 输出 true // 查看input元素是否有checked属性 console.log(document.querySelector('input').hasAttribute('checked')); // 输出 true \u0026lt;script\u0026gt; 从上述示例可以看出，当元素节点具有该属性，即使该属性值为空也是存在的。\nclass 属性 一个元素节点可以包含多个定义的类样式，这些 className 均被放在 class 属性中用空格分割，而我们可以对它们进行单独操作。\n获取 class 列表 classList exp：\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;a b c\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取div元素的class属性列表 console.log(document.querySelector('div').classList); // 输出 ['a','b','c'] // 获取div元素的class属性值 console.log(document.querySelector('div').className); // 输出 a b c \u0026lt;/script\u0026gt; 因为 class 是 JavaScript 的关键字，所以获取 class 属性的值时使用 className 代替。\nclass 值操作 我们可以对 class 属性列表中的值进行单独修改，添加或者移除某一个 class 值。\nadd() remove() exp：\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;a b\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 给class属性列表中添加c document.querySelector('div').classList.add('c'); console.log(document.querySelector('div').className); // 输出 a b c // 从class属性列表中移除b document.querySelector('div').classList.remove('b'); console.log(document.querySelector('div').className); // 输出 a c \u0026lt;/script\u0026gt; class 值检测 当然，我们也可以检测 classList 中是否包含某一特定的 class 值。\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;a b\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 查看class属性列表中是否包含b console.log(document.querySelector('div').classList.contains('b')); // 输出 true // 查看class属性列表中是否包含c console.log(document.querySelector('div').classList.contains('c')); // 输出 false \u0026lt;/script\u0026gt; toggle 自动化 当我们要实现特效时，可能要经历查看某个 class 样式是否存在，不存在时添加，存在时移除这个过程。然而，我们可以自动地一步来完成这三个过程。\ntoggle() exp：\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;a b\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; document.querySelector('div').classList.toggle('b'); document.querySelector('div').classList.toggle('c'); // 查看class属性值 console.log(document.querySelector('div').className); // 输出 a c \u0026lt;/script\u0026gt; data-*属性 元素节点上经常会出现一些类似 data-* 形式的属性，这些属性是为了让我们实现某些目的而进行数据保存的属性。\ndataset exp：\n\u0026lt;body\u0026gt; \u0026lt;div data-foo-foo=\u0026quot;foo\u0026quot; data-bar-bar=\u0026quot;bar\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 获取DIV元素上的数据集合 console.log(document.querySelector('div').dataset); // 输出 DOMStringMap {...} // 获取一个数据 console.log(document.querySelector('div').dataset.fooFoo); // 输出foo // 设置一个数据 document.querySelector('div').dataset.gooGoo = 'goo'; // 删除一个数据 delete document.querySelector('div').dataset.barBar \u0026lt;/script\u0026gt; 要注意的是，对单个数据引用时不需要加 data 前缀，并且当属性名中有 - 时应采用驼峰式命名方式书写（例如 foo-foo ==\u0026gt; fooFoo）。\n结语 除此之外，元素节点的插入、替换、遍历等等我们在 DOM 介绍时均已经说过，它们适用于任何类型的节点对象，我们不在此赘述。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom/","title":"文档对象模型（DOM）","description":"在网页设计中，有一个很重要的角色需要我们了解，DOM 帮助我们对页面元素进行增、删、改等全方位的操作，而且让 JavaScript 在客户端修改 HTML 文档成为一个很简单的事情，可以说 DOM 为我们操作 HTML 文档提供了强大的编程接口。","date":"May 16, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM","tags":"","content":"在网页设计中，有一个很重要的角色需要我们了解，DOM 帮助我们对页面元素进行增、删、改等全方位的操作，而且让 JavaScript 在客户端修改 HTML 文档成为一个很简单的事情，可以说 DOM 为我们操作 HTML 文档提供了强大的编程接口。\n文档对象模型 Document 对象是 BOM 中的核心对象，也是最为复杂的一个。Html 文档解析时，会创建一个 Document 对象，并将整个文档以树形结构展现，而这种结构被抽象为 DOM（Document Object Model），也就是文档对象模型。\nDOM 最大的特点就是，它是一种树形/层次结构，由许多节点组成，而 DOM 中将这些节点抽象为一个对象，称为节点对象（Node Object）。DOM 中的所有操作都是通过访问这些节点对象来进行的，所以我们要了解 DOM 就要首先了解这些节点对象。\n这里要说的一点就是，DOM 是遵循 W3C 标准的。而且 DOM 最初是为 XML 文档设计的应用编程接口，后来为了在 HTML 文档中使用而被扩展。\n节点对象类型 HTML 文档中绝大部分常见的节点对象类型（Node Object Model）有以下几个：\nDOCUMENT_NODE（文档，如 window.document） DOCUMENT_TYPE_NODE（文档类型，如 \u0026lt;!DOCTYPE html\u0026gt;） ELEMENT_NODE（元素，如\u0026lt;html\u0026gt;、\u0026lt;body\u0026gt;、\u0026lt;a\u0026gt;、\u0026lt;p\u0026gt;、\u0026lt;script\u0026gt;） ATTRIBUTE_NODE（属性，如 id=\u0026ldquo;main\u0026rdquo;） TEXT_NODE（文本内容） COMMENT_NODE（注释，\u0026lt;!\u0026ndash; \u0026ndash;\u0026gt;） DOCUMENT_FRAGMENT_NODE（文档片段，如 document.creatDocumentFragment()） 这些其实都是浏览器 javascript 环境下 Node 对象的常量属性，用来存储映射节点到某一特定节点对象类型的数值代号。我们可以通过以下代码获取 Node 对象的所有属性：\n```html \u0026lt;script\u0026gt; for(var key in Node){ console.log(key,\u0026quot;=\u0026quot; + Node[key]); } // 控制台输出 // ELEMENT_NODE =1 // ATTRIBUTE_NODE =2 // TEXT_NODE =3 // CDATA_SECTION_NODE =4 // ENTITY_REFERENCE_NODE =5 // ENTITY_NODE =6 // ··· \u0026lt;/script\u0026gt; ``` 每一种节点对象类型都对应着一种接口，并且都有其 JavaScript 构造函数。ATTRIBUTE_NODE 并不是树的一部分，不参与构成 DOM 树结构。\n节点对象（Node Object） 如果知道关于面向对象编程知识的话，很容易去理解节点对象。DOM 树里面每个节点对象都从 Node 继承属性和方法。例如：\nObject\u0026lt;Node\u0026lt;Element\u0026lt;HTMLElement\u0026lt;(如 HTML*Element) Object\u0026lt;Node\u0026lt;CharacterData\u0026lt;Text Object\u0026lt;Node\u0026lt;Document\u0026lt;HTMLDocument 其实，可以看出的是节点对象与 JavaScript 中的其他对象一样，都继承自 Object.prototype。我们可以遍历一个元素（Element）对象，查看其继承的所有属性和方法。如下所示：\n```html \u0026lt;body\u0026gt; \u0026lt;a href=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var a_obj = document.querySelector(\u0026quot;a\u0026quot;); for (var key in a_obj){ document.write(key+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); } // 输出 // target // download // ping // ... \u0026lt;/script\u0026gt; ``` 通用属性、方法 由于所有的节点对象都继承自 Node ，所以它们有一些共同的属性、方法用来操作、查看、遍历 DOM 的基础值与函数。\n节点属性 parentNode firstChild lastChild previousSibling nextSibling childNodes nodeName nodeType nodeValue 节点方法 appendChild() insertBefore() removeChild() replaceChild() cloneNode() compareDocumentPosition() contains() hasChildNodes() isEqualNode() 文档方法 document.createElement() document.createTextNode() document.createComment() HTML*Element 属性 innerHTML outerHTML textContent innerText outerText firstElementChild lastElementChild nextElementSibling previousElementSibling childElementCount children HTML 元素方法 insertAdjacentHTML() insertAdjacentText() 以上这些属性、方法就可以用来操作 HTML 文档，实现增、删、改等操作，要记住的一点就是：DOM 操作通常都是通过访问节点对象来实现。\n识别节点对象类型与名称 我们可以看到所有的节点对象都具有 nodeType 和 nodeName 属性，继承自 Node。下面，我们来看看它们的返回值是什么。\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello World!\u0026lt;/p\u0026gt;\u0026lt;hr /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 查看p元素标签的nodeType和nodeName p_obj=document.querySelector(\u0026quot;p\u0026quot;); document.write(p_obj.nodeType+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出1 document.write(p_obj.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出P // 查看p标签内文本节点的nodeType和nodeName text_obj=document.querySelector(\u0026quot;p\u0026quot;).firstChild; document.write(text_obj.nodeType+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出3 document.write(text_obj.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出#text \u0026lt;/script\u0026gt; ``` 其实，我们可以看出来 nodeType 的返回值就是前面讲到的 Node 常量属性的值，这样我们就可以确定一个节点对象的类型了；而 nodeName 的返回值通常就是元素标签的名称大写。\n获取节点的值 绝大多数节点类型（除了 Text 和 Comment）的 nodeValue 属性都返回 nil。它的作用就是获取 Text 与 Comment 节点的实际文本字符串。\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello World!\u0026lt;/p\u0026gt;\u0026lt;hr /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 查看p标签内文本节点的nodeValue text_obj=document.querySelector(\u0026quot;p\u0026quot;).firstChild; document.write(text_obj.nodeValue); // 输出Hello World! \u0026lt;/script\u0026gt; ``` 当然，我们也可以给 Text 或 Comment 节点的 nodeValue 赋值改变其字符串内容。\n常用 DOM 操作 接下来我们来看看如何使用这些节点对象的通用属性、方法来进行 DOM 操作。遍历节点、创建节点、插入节点、移除节点、替换节点、复制节点等等都是最基础的 DOM 操作。\n遍历节点对象 我们要使用 JavaScript 进行 DOM 操作，首先就要了解 DOM 树的结构，也就是节点的序列。这时候我们可以通过一个目标节点来实现遍历节点。\nparentNode firstChild lastChild previousSibling nextSibling exp：\n```html \u0026lt;body\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li id=\u0026quot;A\u0026quot;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026quot;B\u0026quot;\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;em\u0026gt;\u0026lt;/em\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; /* 这里要注意的是，\u0026lt;ul\u0026gt;元素节点有4个直属子节点，包括： 两个\u0026lt;li\u0026gt;元素节点，一个\u0026lt;em\u0026gt;元素节点，一个文本（Text）节点。 这是因为第一个\u0026lt;/li\u0026gt;后面的回车符也是文本字符。 */ // 先找到一个目标节点\u0026lt;ul\u0026gt; var ul_obj=document.querySelector(\u0026quot;ul\u0026quot;); // 获取它的父节点 document.write(ul_obj.parentNode.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出BODY // 获取它的第一个直属子节点 document.write(ul_obj.firstChild.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出LI // 获取它的最后一个直属子节点 document.write(ul_obj.lastChild.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出EM // 重新找一个目标节点\u0026lt;li id=\u0026quot;B\u0026quot;\u0026gt; var B_obj=document.querySelector(\u0026quot;#B\u0026quot;); // 获取它的上一个兄弟节点 document.write(B_obj.previousSibling.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出#text // 获取它的下一个兄弟节点 document.write(B_obj.nextSibling.nodeName+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出EM \u0026lt;/script\u0026gt; ``` 上述示例可以分为两部分来看，先看 parentNode 、firstChild、lastChild 这三个属性，它们分别返回的是目标节点的父节点、首个直属子节点、末尾直属子节点。**直属子节点的意思就是一个节点的第一代子节点。**可以看出来这三个属性分别是跨越了 DOM 树的层结构，可以让某个节点获取到它的上层或者下层节点。\n接下来的两个属性 previousSibling 和 nextSibling，分别返回的是目标节点的上一个兄弟节点和下一个兄弟节点。因为返回的是兄弟节点，所以说这两个属性并没有跨越 DOM 树的层结构，属于同级操作。\n总的来说，我们可以通过这五个属性获取某个节点的上层节点、下层节点，同级节点，实现 DOM 树节点的遍历。\n创建节点对象 在 HTML 文档解析完成后，所有节点都是基于文档内容创建的，形成 DOM 树结构。然而，我们还可以通过 JavaScript 来创建额外的节点对象。下面就以创建元素（Element）与文本（Text）节点为例：\ndocument.createElement() document.createTextNode() exp：\n```html \u0026lt;script\u0026gt; // 创建一个元素节点div var new_div=document.createElement(\u0026quot;div\u0026quot;); document.write(new_div.nodeType+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出1 // 创建一个文本节点 var new_text=document.createTextNode(\u0026quot;Hello World!\u0026quot;); document.write(new_text.nodeType+\u0026quot;\u0026lt;br /\u0026gt;\u0026quot;); // 输出3 \u0026lt;/script\u0026gt; ``` 插入节点对象 创建好节点对象后，我们就可以将其插入到 DOM 树中，让其成为 HTML 文档的一部分。\nappendChild() insertBefore() exp：\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello,\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var new_text=document.createTextNode(\u0026quot;World!\u0026quot;); // 添加新文本节点到P元素节点的子节点序列的末尾 var p_obj=document.querySelector(\u0026quot;p\u0026quot;); p_obj.appendChild(new_text); \u0026lt;/script\u0026gt; ``` 上述示例可以看到，\u0026lt;p\u0026gt; 标签内的字符串变为 \u0026ldquo;Hello,World!\u0026quot;，新创建的文本（Text）节点对象被添加在了 p 元素节点的子节点（Child Nodes）序列末尾。**所以 appendChild() 方法的作用就是将新节点对象插入到目标节点的子节点序列末尾。**如果目标节点没有子节点，新的节点则作为其首个子节点插入。\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;World!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; var new_text=document.createTextNode(\u0026quot;Hello,\u0026quot;); // 添加新文本节点到目标节点的前面 var p_obj=document.querySelector(\u0026quot;p\u0026quot;); p_obj.insertBefore(new_text,p_obj.firstChild); \u0026lt;/script\u0026gt; ``` 上述示例可以看到，\u0026lt;p\u0026gt; 标签内的字符串变为 \u0026ldquo;Hello,World!\u0026quot;，新创建的文本（Text）节点对象被添加在了 p 元素节点的首个子节点前面。**所以 insertBefore() 方法的作用就是将新节点对象插入到目标节点的某个子节点位置前面。**如果没有给定第二个参数（插入子节点位置），则和 appendChild() 效果是一样的。\n移除与替换节点对象 有时候我们需要去改变原来的 HTML 文档内容，而不是插入新节点，因此我们要在 DOM 树中某一节点上进行移除、替换操作。\nremoveChild() replaceChild() exp：\n```html \u0026lt;body\u0026gt; \u0026lt;p id=\u0026quot;p1\u0026quot;\u0026gt;Welcome to China!\u0026lt;/p\u0026gt; \u0026lt;p id=\u0026quot;p2\u0026quot;\u0026gt;Hello,World!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 先找到要移除的子节点 var p1_obj=document.getElementById(\u0026quot;p1\u0026quot;); // 在父节点上删除该子节点 p1_obj.parentNode.removeChild(p1_obj); \u0026lt;/script\u0026gt; ``` 上述示例可以看到，第一个 \u0026lt;p\u0026gt; 标签不见了。从 DOM 树中要移除一个节点，我们通常先找到要移除的节点，然后通过它的 parentNode 属性获取父节点，在父节点上利用 removeChild() 移除该子节点。\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Hello,World!\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 创建新的文本节点 var new_text=document.createTextNode(\u0026quot;Welcome to China!\u0026quot;); // 先找到要替换的节点 var strong_obj=document.querySelector(\u0026quot;strong\u0026quot;); // 在父节点上替换该子节点 strong_obj.parentNode.replaceChild(new_text,strong_obj); \u0026lt;/script\u0026gt; ``` 上述示例可以看到，\u0026lt;p\u0026gt; 标签内的字符串变为了 \u0026ldquo;Welcome to China!\u0026quot;，并且没有加粗。**从 DOM 树中要替换一个节点，我们通常先创建一个新节点，接下来找到要替换的节点，然后通过它的 parentNode 属性获取父节点，在父节点上利用 replaceChild() 替换该子节点。**该方法的第一个参数为新节点，第二个参数为被替换节点。\n要值得注意的是，removeChild() 与 replaceChild() 这两个方法会分别返回被替换和被移除的相应节点。这些节点只是从 DOM 树中移出，而并没有消失，在内存中仍然持有它的引用。\n复制节点对象 当然，我们有时候要创建一个 DOM 树中存在的节点时，最方便的办法就是直接复制一份。\ncloneNode() exp：\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Hello,World!\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 复制节点 var p_obj=document.querySelector(\u0026quot;p\u0026quot;).cloneNode(true); // 插入到\u0026lt;Body\u0026gt;的子节点序列末尾 document.body.appendChild(p_obj); \u0026lt;/script\u0026gt; ``` 上述示例可以看到，不仅复制了 p 元素节点，而且其子节点也被全部复制了。cloneNode() 有一个参数，为布尔值，false 代表仅仅复制节点自身，true 代表复制节点及其所有子节点。\n元素（Element）节点的 DOM 操作 上面了解的是所有节点类型的 DOM 操作，由于我们通常打交道的都是元素（Element）节点，所以有必要了解一些 HTML 元素节点特有的属性、方法，如何利用它们进行 DOM 操作，完成一些重要的功能。\n获取元素节点内容 其实我们可以通过 JavaScript 获取某个元素节点的内容，也就是所谓的源代码。\ninnerHTML outerHTML textContent innerText outerText exp：\n```typescript // 我们随便打开一个页面，在控制台进行下列操作 // 下面这句会弹出\u0026amp;lt;html\u0026amp;gt;元素内的源代码，但不包括\u0026amp;lt;html\u0026amp;gt;标签 alert(document.documentElement.innerHTML); // 下面这句会弹出\u0026amp;lt;html\u0026amp;gt;元素内的源代码，包括\u0026amp;lt;html\u0026amp;gt;标签 alert(document.documentElement.outerHTML); // 下面两句会弹出\u0026amp;lt;html\u0026amp;gt;元素内的所有文本节点的字符串 alert(document.documentElement.innerText); alert(document.documentElement.outerText); // 下面这句也会弹出\u0026amp;lt;html\u0026amp;gt;元素内的所有文本节点的字符串，但稍不一样 alert(document.documentElement.textContent); ``` 上述示例可以看出，innerHTML 与 outerHTML 这两个属性都可以获取一个元素节点的内容（源代码）；不同的是前者不包括该节点的标签，而后者包括该节点的标签。\n其次，innerText、outerText 与 textContent 这三个属性均可以获取一个元素节点内的所有文本节点；不同的是前者只会获取所有样式设置为显示的文本节点；而后者不仅会获取样式设置为隐藏的文本节点，还会获取该节点内 style 与 script 标签内的全部内容（源代码）。\n用字符串创建节点并插入 DOM 树 在常用 DOM 操作的学习过程中，我们学会了如何创建一个节点，并将该节点插入到 DOM 树中。但对于元素（Element）节点来说，我们其实可以一步完成创建与插入操作。\ninnerHTML textContent innerText insertAdjacentHTML() insertAdjacentText() exp：\n```html \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 创建\u0026lt;strong\u0026gt;元素节点和文本节点并插入DOM树 document.querySelector(\u0026quot;p\u0026quot;).innerHTML=\u0026quot;\u0026lt;strong\u0026gt;Hello\u0026lt;/strong\u0026gt; World!\u0026quot;; // 创建文本节点并插入DOM树,下面两句效果一样 document.querySelector(\u0026quot;h1\u0026quot;).textContent=\u0026quot;China\u0026quot;; document.querySelector(\u0026quot;h1\u0026quot;).innerText=\u0026quot;China\u0026quot;; \u0026lt;/script\u0026gt; ``` 上述示例可以看到，通过给 innerHTML 与 textContent、innerText 属性赋值，可以替换掉一个元素节点内的节点结构（源代码），也就是创建新节点并插入到 DOM 树中，覆盖掉该元素节点原来的所有子节点。\n不过，innerHTML 属性会检测字符串中的元素标签，并将其转换成实际的 DOM 节点插入到 DOM 树中；而 textContent、innerText 属性会将整个字符串当作一个文本节点直接插入到 DOM 树中，字符串中的元素标签将会失效。\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;World!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // insertAdjacentHTML()与insertAdjacentText()方法均有两个参数 // 第一个参数可选项为： // \u0026quot;beforebegin\u0026quot; （开始标签前） // \u0026quot;afterbegin\u0026quot; （开始标签后） // \u0026quot;beforeend\u0026quot; （关闭标签前） // \u0026quot;afterend\u0026quot; （关闭标签后） // 创建\u0026lt;strong\u0026gt;元素节点和文本节点并插入到p节点开始标签后面 document.querySelector(\u0026quot;p\u0026quot;).insertAdjacentHTML(\u0026quot;afterbegin\u0026quot;,\u0026quot;\u0026lt;strong\u0026gt;Hello\u0026lt;/strong\u0026gt;\u0026quot;); \u0026lt;/script\u0026gt; ``` insertAdjacentHTML() 方法与 innerHTML 属性功能一样，而 insertAdjacentText() 方法与 textContent、innerText 属性功能一样。上述示例可以看出，这两个方法根据第一个参数可以实现精准插入。需要注意的是，这两个方法并不会覆盖掉节点内原来的所有子节点，而是将新的节点插入到子节点序列中的相应位置。\n移除与替换元素节点 当然，我们也可以一步完成元素（Element）节点的移除与替换。\nouterHTML exp：\n```html \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello,World!\u0026lt;/p\u0026gt; \u0026lt;span\u0026gt;你好!\u0026lt;/span\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 移除\u0026lt;span\u0026gt;元素节点 document.querySelector('span').outerHTML = ''; // 替换\u0026lt;p\u0026gt;元素为\u0026lt;h1\u0026gt;元素,并替换文本节点 document.querySelector('p').outerHTML = '\u0026lt;h1\u0026gt;Hello,China!\u0026lt;/h1\u0026gt;'; \u0026lt;/script\u0026gt; ``` 遍历元素节点对象 在进行常用 DOM 操作学习时，我们遍历节点对象时会包含所有节点对象（元素节点、文本节点、注释节点等），但是我们通常只关心元素（Element）节点。\nfirstElementChild lastElementChild nextElementSibling previousElementSibling 以上这些属性与前面所介绍的属性相类似，只不过这些属性会忽略掉其他类型的节点对象，只返回元素节点对象。当然，利用这些属性完成 DOM 树的元素节点遍历也是类似的，我们不再详细举例讨论。\n利用 childElementCount 可以获取目标节点直属子元素节点的数目。\n结语 DOM 是一个很复杂的体系，要理解的就是它是一个树形结构，HTML 文档解析时创建了许多节点，而我们所有的 DOM 操作都是依靠访问这些节点对象实现的。DOM 树中的节点其实就是一个个接口，提供了我们使用 JavaScript 操作 HTML 文档的编程接口。\n参考 《DOM 启蒙》，Cody Lindley，陈养剑 译 "},{"section":"Blog","slug":"/blog/computer-technology/web/dom/dom-bom/","title":"浏览器对象模型（BOM）","description":"在网页开发中，我们通常专注于内容的设计，而有些时候我们需要进行不同窗口之间的交互，这时候我们就需要学习如何运用 BOM 中的许多核心对象，及其属性、方法。","date":"May 15, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, Web, Web 前端, DOM, BOM","tags":"","content":"在网页开发中，我们通常专注于内容的设计，而有些时候我们需要进行不同窗口之间的交互，这时候我们就需要学习如何运用 BOM 中的许多核心对象，及其属性、方法。\n浏览器对象模型 BOM（Browser Object Model）即浏览器对象模型，我们熟知的另一个对象模型为 DOM（Document Object Model），也就是文档对象模型。这两个都是网页设计中非常重要的概念，我们可以简单的理解为 BOM 注重的是不同网页（框架、窗口）之间的交互（浏览器层面），而 DOM 注重的是同一网页下的内容设计（网页层面）。\nBOM 中的对象 我们首先要了解的就是 BOM 中的对象，然后再对各个对象中的属性、方法进行探究。BOM 中有以下几个对象：\nWindow Navigator Screen History Location Document（DOM） 其中最核心就是 Document 对象，也就是我们所说的 DOM，它本身很复杂，在此我们对它不做过多讨论。剩下的几个对象中，我们常用的并且比较重要的就是 Window 和 Location 对象了，后面将会详细讨论。\nWindow Window 对象表示的就是我们的浏览器窗口。如果 html 文档中包含框架（frame/iframe 标签），那么每一个框架也都对应一个 Window 对象，frames[] 数组存放不同窗口的 Window 对象。Window 对象是我们很常用也很重要的 BOM 对象。\n常用属性 frames[] // 窗口数组 length // 获取frame个数 name // 获取/设置窗口名称 opener // 获取窗口的打开/创建者 parent // 获取窗口的父窗口 top // 获取顶级窗口 closed // 测试窗口是否已关闭 上面这些属性大多都是与框架有关的，并且也是比较常用的，主要作用就如注释所写都简单易懂。**除此之外，我们还需要知道的是，其他的 BOM 对象的引用均需要 window 才能获取，所以 Window 对象的属性中包括其他 BOM 对象的引用属性。**如下所示：\nnavigator // Navigator对象引用 screen // Screen对象引用 history // History对象引用 location // Location对象引用 document // Document对象引用 // 例如 window.document.title; window.location; 常用方法 Window 对象有很多常用的内建方法，下面我们来分类介绍。首先介绍两个方法：\nopen(); // 打开一个窗口 close(); // 关闭一个窗口 需要说明的是，目前这两个方法基本不会用到，而且各个浏览器对 open() 方法的支持是越来越差了，打开新的网页我们通常用 \u0026lt;a\u0026gt; 去完成。\nalert() // 警告对话框 prompt() // 输入对话框 confirm() // 确认对话框 // 例如 window.alert(location); window.prompt(\u0026quot;验证码\u0026quot;,\u0026quot;默认文本\u0026quot;); window.confirm(\u0026quot;要关闭当前页面吗？\u0026quot;); 以上三个方法均实现的是弹出式的对话框。\nsetInterval() // 创建计时器 clearInterval() // 清除计时器 setTimeout() // 创建超时器 clearTimeout() // 清除计时器 // 例如 setInterval(\u0026quot;update()\u0026quot;,1000); 以上方法通常用来实现一些特效，均接受两个参数：执行代码（回调函数）和时间(ms)。计时器就是按指定时间间隔反复执行代码，超时器则是按指定时间到时后执行一次代码即可完成。\nmoveBy() // 相对于浏览器原左上角坐标的移动坐标 moveTo() // 直接设置浏览器左上角坐标 resizeBy() // 相对于浏览器原窗口大小的调整像素 resizeTo() // 直接设置浏览器窗口大小 scrollBy() // 相对于浏览器原窗口滚动位置的滚动距离 scrollTo() // 直接设置窗口滚动距离 以上方法，都是对浏览器窗口进行的一些操作，By() 方法设置的都是相对参数，而 To() 方法设置的是绝对参数。\n**最后，我们需要知道的是 Window 对象在 javascript 中是全局对象（浏览器环境），所以在使用的时候我们通常可以不写 window。**如下所示：\n// 下面三种用法等价 window.document.title; self.document.title; document.title; Navigator Navigator 对象包含浏览器有关的信息，如浏览器版本号、内核等等。这个对象我们通常用来精准（直接）判断浏览器为 IE、FireFox、Chrome 等等。\n常用属性 Navigator 对象中我们需要注意的属性有三个。\nappName // 浏览器名称 appVersion // 使用浏览器的平台系统和版本信息 userAgent // 浏览器客户端代理 这里需要注意的是 appName 属性返回的并不是真正的浏览器名称，FireFox、Chrome 等非 IE 浏览器返回的均是 Netscape(网景)，网景浏览器是第一代浏览器。我们想要获知浏览器的真正名称则需要用到 userAgent 属性。\n// 直接（精准）判断浏览器名称 var ua = window.navigator.userAgent; if (ua.search(/msie/i) \u0026gt;= 0){ alert(\u0026quot;你使用的是IE浏览器！\u0026quot;); } else { if (ua.search(/chrome/i) \u0026gt;= 0){ alert(\u0026quot;你使用的是谷歌浏览器！\u0026quot;); } else { if (ua.search(/firefox/i) \u0026gt;= 0){ alert(\u0026quot;你使用的是火狐浏览器！\u0026quot;); } } } Screen Screen 对象包含客户端显示器屏幕的一些信息，例如分辨率、颜色深度、刷新率等等。\n常用属性 我们通常关心的是分辨率和浏览器窗口大小的问题，与之有关的 Screen 对象属性有四个。\nwidth // 显示器分辨率的宽 height // 显示器分辨率的高 availWidth // 显示屏幕除任务栏以外的有效宽 availHeight // 显示屏幕除任务栏以外的有效高 History History 对象包含浏览器的访问历史信息。\n属性 length // 访问历史记录列表的URL数量 方法 History 对象有三个方法，是用来控制页面前进、后退、跳转的。\nback() // 后退一个网页 forward() // 前进一个网页 go() // 按参数进行跳转 // 下面两个等价 back(); go(-1); 这些我们通常不会用到，浏览器自身已经具备这些能力。\nLocation Location 对象包含有关页面 URL 的信息。\n常用属性 hash // 页面的锚(#) href // 设置/获取完整URL search // 设置/获取？后的URL部分 // 下面两个等价 location.href = \u0026quot;http://LeeZChuan.github.io/\u0026quot;; location = \u0026quot;http://LeeZChuan.github.io/\u0026quot;; 方法 Location 对象也仅仅只有三个方法，但很重要。\nassign() // 加载新页面 reload() // 页面重载/刷新 replace() // 替换当前页面，但不留历史记录 // 例如，导航栏没有历史记录 location.replace(\u0026quot;http://LeeZChuan.github.io/\u0026quot;); 结语 至此，我们对 BOM 对象有了一个简单全面的认识，了解了各个对象中一些常用的属性、方法。在这里我们没有探讨 Document 对象，这是因为它其实就是 DOM，是一个比 BOM 还庞大的体系，需要单独去讨论。\n"},{"section":"Blog","slug":"/blog/computer-technology/computer/computer-cpu-addressing-mode/","title":"CPU 的七种寻址方式","description":"CPU 获取数据的方式不仅仅一种，多种方式也为不同数据的获取提供了不同的效率考量，保证了寻址效率与指令的灵活性。","date":"May 5, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, CPU","tags":"","content":"CPU 获取数据的方式不仅仅一种，多种方式也为不同数据的获取提供了不同的效率考量，保证了寻址效率与指令的灵活性。\nCPU 寻址方式 数据一般均存储在外存(硬盘)中，在需要的时候，会将数据先从外存读入内存(存储器)中，然后 CPU 再直接从内存(缓存)中获取。获取的数据有时候会直接使用；而有时候会先存入 CPU 内部寄存器，稍后再从寄存器中获取。所以，CPU 获取数据的方式是多样化的。\n在为了保证寻址效率和指令灵活性的基础上，设计有 7 种寻址方式，他们分别是：\n立即(数)寻址 (存储器)直接寻址 寄存器（直接）寻址 寄存器间接寻址 寄存器相对寻址 基址、变址寻址 基址、变址、相对寻址 下面结合早期 Inter 的微处理器 8088(8086) 以及汇编指令来举例说明这七种寻址方式的判断方法和原理。\n立即(数)寻址 源操作数直接包含在指令中，与操作码一起放在代码段区域中。CPU 读出指令操作码后，在其下面的地址中可立即读出源操作数。\n立即寻址方式的操作也称为立即数。立即数可以是 8 位，也可以是 16 位。\nMOV AL, 05H （8位立即数） MOV DX, 8000H （16位立即数） 注意：源操作数才可以是立即数，目的操作数为立即数是违法操作。\nMOV 05H, AL （违法指令） 原因：这就和高级语言中变量赋值一样，=号左边必须是变量名，而不能是常数。\n立即数寻址方式通常用来给寄存器赋初值。\n(存储器)直接寻址 操作数存放在存储器(内存)中，在指令给出的是该操作数的有效地址(段内偏移地址)。操作数通常存放在数据段中，默认的段地址存放在 D 段寄存器中。\n操作数的内存地址：DS 段地址 ×16(左移 4 位)+16 位偏移地址=20 位内存地址。\nMOV BX, [2000H] (假设段地址 DS=1000H) 内存地址：1000H×16+2000H=12000H 注意：段地址也有可能不在 DS 中，此时指令中会给出存放段地址的寄存器号(段超越前缀不可省略)。\nMOV ES:[2000H], AX （段地址存放在ES寄存器中） 寄存器(直接)寻址 操作数存放在 CPU 内部寄存器中，例如 AX、BX、CX、DX 等。\nMOV DS, AX MOV AL, BL 注意：由于 AX 是累加器，如果将结果存放在 AX 中，即将 AX 作为目的操作数存放位置，通常指令的执行时间要短一些。\n寄存器寻址方式，减少了读/写存储器单元的次数，所以，使用寄存器寻址方式的指令一般执行速度比较快。\n寄存器间接寻址 操作数存放在存储器(内存)中，有效地址(段内偏移地址)存放在内部寄存器 SI、DI、BX、BP 之一中，由于段地址可存放在 DS 和 SS 中又分为两种：\n若段内偏移地址存放于 SI、DI、BX 之一中，默认段地址存放在 DS 寄存器中。 exp：\nMOV AX, [SI] MOV AX, [DI] MOV AX, [BX] 操作数的内存地址：DS 段地址 ×16(左移 4 位)+[SI][di][BX]偏移地址=20 位内存地址。\n若段内偏移地址存放于 BP 中，默认段地址存放在寄存器 SS(堆栈段)中。 exp：\nMOV BX, [BP] 操作数的内存地址：SS 段地址 ×16(左移 4 位)+[BP]偏移地址=20 位内存地址。\n寄存器相对寻址 操作数存放在存储器(内存)中，有效地址(段内偏移地址)存放在内部寄存器 SI、DI、BX、BP 之一中，由于段地址存放在 DS、SS 之一中，所以也可分为两类，不再细说，类比寄存器间接寻址方式即可。\n相比于寄存器间接寻址方式，寄存器相对寻址的不同之处在于多了一个 8 位或 16 位的带符号常数偏移量。\nMOV AL, [SI-200H] 操作数的内存地址：SS 或 DS 段地址 ×16(左移 4 位)+[BP]或[SI][di][BX]偏移地址+常数偏移量=20 位内存地址。\nMOV AL, [SI-2] (假设 DS=3000H,SI=1000H) 内存地址：3000H×16+1000H-2=30FFEH 基址、变址寻址 操作数存放在存储器(内存)中，基址存放在内部寄存器 BX、BP 之一中，变址存放在内部寄存器 SI、DI 之一中，由于段地址存放在内部寄存器 SS、DS 之一中，所以也可分为两类，类比寄存器间接寻址方式即可。\n操作数内存地址：SS 或 DS 段地址 ×16(左移 4 位)+[BP]或[BX]基址+[SI][di]变址=20 位内存地址\nMOV AL, [BP][DI] (假设 SS=8000H,BP=1000H,DI=0500H) 内存地址：8000H×16+1000H+0500H=81500H 基址、变址、相对寻址 操作数存放在存储器(内存)中，基址存放在内部寄存器 BX、BP 之一中，变址存放在内部寄存器 SI、DI 之一中，由于段地址存放在内部寄存器 SS、DS 之一中，所以也可分为两类，类比寄存器间接寻址方式即可。\n相比于基址、变址寻址方式，基址、变址、相对寻址的不同之处在于多了一个 8 位或 16 位的带符号常数偏移量。\nMOV AL, 1000H[BP][DI] 操作数内存地址：SS 或 DS 段地址 ×16(左移 4 位)+[BP]或[BX]基址+[SI][di]变址+常数偏移量=20 位内存地址\nMOV AL, 0010H[BX][SI] (假设 DS=6000H,BX=5000H,SI=0300H) 内存地址：6000H×16+5000H+0300H+0010H=65310H 寻址类别 这七种 CPU 寻址方式中，可以根据操作数是否在存储器(内存)中分为两类：内存寻址方式和非内存寻址方式。其中内存寻址方式包含：\n(存储器)直接寻址 寄存器间接寻址 寄存器相对寻址 基址、变址寻址 基址、变址、相对寻址 结语 通常来说，要根据汇编指令判断寻址方式，需要知道目标 CPU 是什么，以及 CPU 内部寄存器的设计布局是什么，这样才能正确判断出寻址方式。以上的七种寻址方式说明全部是基于 Inter 的 8086(8088)处理器的。\n"},{"section":"Blog","slug":"/blog/computer-technology/computer/computer-memory-refresh/","title":"内存的 3 种刷新方式","description":"内存为我们提供了一个数据快速交换的缓冲区，但同时会在掉电的情况下数据丢失，来看看内存是如何在带电情况下刷新数据的。","date":"May 3, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 内存","tags":"","content":"众所周知，内存（Memory）是带电存储的，掉电就会丢失数据，所以需要刷新来保持数据。\n原因 由于内存（Memory）以及缓存（Cache）都由相应的存储单元芯片DRAM和SRAM构成存储阵列，是一种半导体存储器件。并且，所有的数据都是逻辑 1 和 0 的组合。\n至于 1 与 0 的输出，这源于存储单元芯片的基本结构：晶体管（场效应管）。其中，高低电平（1 和 0）的输出取决于源极电容上保存的电荷量，而电容上电荷的保持是需要一定电压维持的。所以一断电，电容上的电荷会全部消失，相应的数据也就会消失。\n解决方案：刷新 解决的方法策略就是，在电容上电荷消失之前，对其刷新一次，让其保持原状态，即保证数据的正确存储。\n一般有三种方式：\n集中刷新 （单次耗费时间） 分散刷新 （刷新太过频繁） 异步刷新 （高效率，低时间消耗） 一般情况下，电容上的电荷可保持2ms，数据读写周期为0.5us，并且存储阵列的刷新均是按行刷新的。同时，内存刷新相当于一次数据的读写，消耗时间基本和读写周期相同。下面以128 行 ×128 行 ×8bit的存储阵列，即就是 16KB*8bit 的内存（Memory）为例，进行说明：\n集中刷新 集中刷新的原理就是，快到 2ms 的时候，也就是电容上电荷即将消失时，停止一切读写状态，对内存进行所有行刷新，那么这样耗费的时间就是：\n**刷新消耗时间：**128 行 ×0.5us=64us\n这就相当于，在每过 2ms，就有 64us 刷新时间，这 64us 期间内存停止与外界的一切交互，这对数据读写效率的影响是巨大的。\n特点：单次时间耗费巨大。\n分散刷新 分散刷新的原理就是，每次读写操作完成之后，就刷新一行，这样相当于每次读写操作的时间翻倍0.5us(读写)+0.5us(刷新)。\n**每行刷新间隔：**128 行 ×1us=128us\n电容上的电荷可保持 2ms，但是分散刷新每隔 128us 就会刷新一次，这样显得太过频繁，在一定程度上影响了读写操作的效率。\n特点：刷新太过频繁。\n异步刷新 异步刷新的原理就是，既然电容上电荷可保持 2ms，那么就在几乎快到 2ms 的时候刷新。这样相当于每行只刷新一次，对读写操作的影响是最小的。\n**行间刷新间隔：**2ms÷128 行=15.625us （取 15.5us） \u0026gt; **每行刷新间隔：**15.5us×128 行=1.984ms\n可以看出，异步刷新事实上是改进了的分散刷新，分散刷新太过频繁，异步刷新将分散刷新的每行刷新间隔延长到几乎 2ms，保证数据不会丢失即可，极大的降低了刷新操作对读写过程的影响。\n特点：刷新一次，保证数据正确性，同时最小化对读写操作的影响。\n结语 这就是内存（Memory）以及缓存（Cache）需要带电存储数据的原因，以及保证数据存储正确性的解决策略：刷新操作，其 3 种方式的详细解释。\n"},{"section":"Blog","slug":"/blog/computer-technology/computer/computer-microprocessor-addressing-range/","title":"微处理器寻址范围","description":"为什么内存不是越大越好，内存的大小受限于处理器的寻址范围。","date":"April 28, 2016","image":null,"imageSM":null,"searchKeyword":"","categories":"计算机技术, 计算机, MPU","tags":"","content":"在此之前，让我们带着下面这个问题来看这篇文章：64 位处理器所支持的最大内存(寻址范围)为多少？\n处理器 处理器（CPU）担负着整个计算机系统的核心任务执行责任，所以我们经常关心它的运算处理能力，也就是 CPU 的性能。\n微处理器 我们经常所说的 Inter、AMD 两大常见品牌厂商出售的桌面端的处理器称为处理器（CPU），而把移动端嵌入式系统中 ARM 架构的处理器称为微处理器（MPU）。事实上，几乎电子设备上均有微型处理器，例如路由器、智能家电等等，只不过以上所提到的离我们最近而且我们也最熟悉。\nCPU 的性能涉及到多个方面，我们常人最关心的一般就是主频，也就是 CPU 的时钟频率；L1、L2 缓存，这个可能部分人还不是很了解，事实上缓存非常关键，稍后会讲到；工艺，CPU 的工艺不仅可以降低功耗与成本，对性能的提高也是非常重要的；架构，这个对非专业的人来说很难理解，我们暂且可以理解为 CPU 内部各个协同工作器件的设计布局；还有很多，我们不一一列举，来具体探讨一下与今天的主题相关的方面：缓存。\n缓存（Cache） 你可能无法想象，你经常关注的 CPU 主频对其性能的重要性小于缓存。缓存就如同它的名字，它的存在就是为了起缓冲作用。它缓冲的是 CPU 与内存之间的数据交互。由于目前 CPU 的时钟频率（主频）远超内存(memory)的工作频率，所以内存的数据传输速度根本跟不上 CPU 的请求速度，这对 CPU 来说是一种浪费。所以采用一种技术，即缓存技术，将缓存工作频率设计在 CPU 时钟与内存频率之间，极大地提高了数据传输速度。\n数据交互有两种途径： \u0026gt; [10%，慢] 处理器(CPU) \u0026lt;\u0026ndash;\u0026gt; 内存(memory) \u0026gt; [90%，快] 处理器(CPU) \u0026lt;\u0026ndash;\u0026gt; 缓存(Cache) \u0026lt;\u0026ndash;\u0026gt; 内存(memory)\n微处理器内存寻址 既然 CPU 与内存之间有数据交互，那么就要确认每次数据读/写时的内存物理地址，如同游戏中在背包中存取东西时，首先要找到目标背包格子，才能进行正确的存取操作。\n内存条的组成 一根 1G 的内存条是由许多内存颗粒(DRAM 芯片)，例如 16K*8bit 的芯片，即存储单元构成的，这个过程需要字扩展、位扩展构成逻辑存储阵列。\n按这样的想法，我们很容易拼成几十 G 的内存条，暂且不去说性能如何，CPU 能正确寻址吗？从而完成数据读写吗？\n内存条构成： (DRAM)16K8bit \u0026mdash;字/位扩展\u0026mdash;\u0026gt; (Memory)1G32bit\nCPU 的地址线和数据线 每个 CPU 都有固定条数的数据线(Data)和地址线(Address)，顾名思义，很容易理解数据线就是用来传输数据的，地址线就是用来寻址的。这样的理解其实是相当正确的，只不过你稍加深入的学习，就很容易混淆概念甚至怀疑自己，从而建立错误的认知。\n记住：地址位宽决定了 CPU 的寻址范围。\n我们现在来讨论：64 处理器的寻址范围或者说支持的最大内存是多少？\n这个问题的出现缘于 64 位处理器的诞生，宣传中不乏 32 位处理器最高可支持 4G 内存，64 位处理器可支持更大内存(这是官方话)。\n百度上大多数答案都是 2^64 次方，像 CSDN、知乎等等的专业性较强的论坛上也会有少部分人这样回答。而他们有的会给出理由：64 根数据线，所以是 2^64 次方，换算下来应该有 16GT。\n是的，如今所谓的 32 位或者 64 位处理器，32 和 64 指的就是 CPU 的字长，即数据(Data)位宽。\n这是错误的概念！有很多人会觉得很正常，而且有自己的证明理由。例如：64 根数据线，可表示数据的范围就是 2^64，所以寻址范围理所当然就是如此。\n首先，很多人这么理解是有原因的。学习微机原理时，我们都是以 Inter 的 8086/8088 为例来学习的，而恰好：**8086 数据位宽 16bit，8088 数据位宽 8bit，它们的地址位宽均为 20bit。**这样导致的结果就是，Data 位宽小于 Address 位宽的情况下，我们总以为由于数据线表示的范围不足以表示每一个地址，所以寻址范围由 Data 决定了。\n**有趣的是，8086/8088 采用了段基地址和段偏移地址的方式，让 8086 只有 16 根数据线(2^16=64KB)的情况下，可以寻址到 1MB(也就是 20 根地址线)。**很多人觉得这仅仅是为了增大寻址范围(这是个错误的说法)，却未曾想过这是务必要做的。\n段基地址+段偏移地址： 16bit 的 Data 可表示 2^16=64KB 的地址范围 16 块 64KB 内存条 \u0026mdash;(16bit 的 Data + 片选信号)\u0026mdash;\u0026gt; 1MB 地址范围\n假如不这样做，那么 16bit 的 Data 只能表示 64KB 地址范围，20bit 的 Address 其中就有 4 根闲置下来，既然多余了还要它干什么？但是，针脚的工艺那么难，无聊的加 4 根针脚闹着玩？所以说，用段基地址+段偏移地址来增加寻址范围(这么说是不对的，应该是弥补)是务必要做的，即就是：事实上，数据位宽并没有决定寻址范围。\n那可以说，数据位宽与地址位宽同时决定了寻址范围吗？\n我的答案是不可以这么说。你可以这么想，地址位宽大于数据位宽时，可以采用段基地址+段偏移地址方式来表示；那么当地址位宽=数据位宽时，刚好足够表示；至于数据位宽再增加时，虽然表示的数大了，但是地址位宽不足，无法表示超出部分的物理地址。所以说，无论数据位宽怎么变，最终寻址方式和范围都是相对于地址位宽来说的。\n**数据(Data)位宽：**即字长，CPU 同一时刻所能传输最大数据位 \u0026gt; **地址(Address)位宽：**单独决定 CPU 的寻址范围\n结语 由于工艺难度，CPU 上针脚数目的增加是非常难的，而且 CPU 针脚过多时，也需要主板能支持，就目前的工艺来看，最高可支持(2^37 次方)128G 内存条。\n因此，64 位处理器指的是数据位宽 64bit，并不是地址位宽，那么最大可支持内存(寻址范围)也就不可能是 2^64 次方，并且远小于此。\n"}]